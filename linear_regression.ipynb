{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0      1     0\n",
      "0  23.98  6.459  11.8\n",
      "1  21.52  6.193  11.0\n",
      "2   7.74  6.750  23.7\n",
      "3   4.81  7.249  35.4\n",
      "4  18.06  5.454  15.2\n",
      "5   5.90  6.487  24.4\n",
      "6   2.94  6.998  33.4\n",
      "7   6.36  7.163  31.6\n",
      "8  17.44  6.749  13.4\n",
      "9   4.56  6.975  34.9\n",
      "Shape of train features: (354, 2)\n",
      "Shape of train targets: (354, 1)\n"
     ]
    }
   ],
   "source": [
    "# Step 2. Parse and visualize data\n",
    "# parse train data: read CSV files with train features (train_x) and train targets (train_y)\n",
    "x_train = pd.read_csv(\"D:\\\\Dataset\\\\train\\\\train_x.csv\", header=None)\n",
    "y_train = pd.read_csv(\"D:\\\\Dataset\\\\train\\\\train_y.csv\", header=None)\n",
    "\n",
    "# show first 10 samples\n",
    "print(pd.concat([x_train, y_train], axis=1).head(10))\n",
    "\n",
    "x_train = x_train.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "print(\"Shape of train features:\", x_train.shape)\n",
    "print(\"Shape of train targets:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3. Prototypes.\n",
    "\n",
    "# In this demo we will use linear regression to predict targets from features.\n",
    "# In linear regression model with parameters thetas \n",
    "# the prediction y is calculated from features x using linear combination of x and thetas.\n",
    "# For example, for the case of 2 features: \n",
    "# y = theta_0 * x_o + theta_1 * x_1\n",
    "\n",
    "# Let's define some helper functions\n",
    "\n",
    "def predict_fn(x, thetas):\n",
    "    '''\n",
    "    Predict target from features x using parameters thetas and linear regression\n",
    "    \n",
    "    param x: input features, shape NxM, N - number of samples to predict, M - number of features\n",
    "    param thetas: vector of linear regression parameters, shape Mx1\n",
    "    return y_hat: predicted scalar value for each input samples, shape Nx1\n",
    "    '''    \n",
    "    # TODO: calculate y_hat using linear regression\n",
    "    y_hat = np.zeros((x.shape[0], 1))\n",
    "    for i in range(len(x)):\n",
    "        y_hat[i] = thetas[0] * x[i][0] + thetas[1] * x[i][1]\n",
    "    return y_hat\n",
    "\n",
    "\n",
    "def loss_fn(x_train, y_train, thetas):\n",
    "    '''\n",
    "    Calculate average loss value for train dataset (x_train, y_train).\n",
    "    \n",
    "    param x_train: input features, shape NxM, N - number of samples to predict, M - number of features\n",
    "    param y_train: input tagrets, shape Nx1\n",
    "    param thetas: vector of linear regression parameters, shape Mx1\n",
    "    return loss: predicted scalar value for each input samples, shape Mx1\n",
    "    '''\n",
    "    y_predicted = predict_fn(x_train, thetas)    \n",
    "    loss = np.mean(np.power(y_train - y_predicted, 2))   \n",
    "    return loss\n",
    "\n",
    "\n",
    "def gradient_fn(x_train, y_train, thetas):\n",
    "    '''\n",
    "    Calculate gradient value for linear regression.\n",
    "    \n",
    "    param x_train: input features, shape NxM, N - number of samples to predict, M - number of features\n",
    "    param y_train: input tagrets, shape Nx1\n",
    "    param thetas: vector of linear regression parameters, shape Mx1\n",
    "    return g: predicted scalar value for each input samples, shape Mx1\n",
    "    '''  \n",
    "    # TODO: calculate vector gradient\n",
    "    g = np.zeros_like(thetas)\n",
    "    for i in range(len(x_train)):\n",
    "        g[0] += -2 * x_train[i][0] * (y_train[i] - x_train[i][0] * thetas[0] - x_train[i][1] * thetas[1])\n",
    "        g[1] += -2 * x_train[i][1] * (y_train[i] - x_train[i][0] * thetas[0] - x_train[i][1] * thetas[1])\n",
    "    g[0] = g[0] / len(x_train)\n",
    "    g[1] = g[1] / len(x_train)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  40%|███████████▎                | 404/1000 [00:04<00:06, 89.44it/s, loss_val=27.9984, thetas=-0.6557 4.8848]\n",
      "Stop condition detected\n",
      "Final loss: 27.998428705433113\n"
     ]
    }
   ],
   "source": [
    "# Step 4. Gradient descent.\n",
    "\n",
    "# now let's find optimal parameters using gradient descent\n",
    "MAX_ITER = 1000\n",
    "thetas = np.random.randn(2, 1)\n",
    "alpha = 1e-3\n",
    "\n",
    "progress = tqdm.tqdm(range(MAX_ITER), \"Training\", file=sys.stdout)\n",
    "loss_val = loss_fn(x_train, y_train, thetas)\n",
    "progress.set_postfix(loss_val=loss_val)\n",
    "\n",
    "for iter in progress:\n",
    "    gradient = gradient_fn(x_train, y_train, thetas)\n",
    "    thetas_2 = thetas - alpha * gradient\n",
    "    \n",
    "    # TODO: add stop conditions\n",
    "    if (abs(thetas_2[0] - thetas[0]) < 0.00001) and (abs(thetas_2[1] -thetas[1]) < 0.00001):\n",
    "        progress.close()\n",
    "        loss_val = loss_fn(x_train, y_train, thetas)\n",
    "        print(\"Stop condition detected\")\n",
    "        print(\"Final loss:\", loss_val)\n",
    "        break\n",
    "    \n",
    "    if iter % 100 == 0:\n",
    "        loss_val = loss_fn(x_train, y_train, thetas_2)\n",
    "        progress.set_postfix(loss_val=f\"{loss_val:8.4f}\", thetas=f\"{thetas_2[0][0]:5.4f} {thetas_2[1][0]:5.4f}\")\n",
    "    thetas = thetas_2\n",
    "    \n",
    "progress.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target:  11.8 , predicted: 15.825663061797137\n",
      "Target:  11.0 , predicted: 16.139711609970796\n",
      "Target:  23.7 , predicted: 27.899383727052204\n",
      "Target:  35.4 , predicted: 32.259012900433305\n",
      "Target:  15.2 , predicted: 14.798901476444952\n",
      "Target:  24.4 , predicted: 27.821420233616394\n",
      "Target:  33.4 , predicted: 32.259351209667344\n",
      "Target:  31.6 , predicted: 30.822201690957264\n",
      "Target:  13.4 , predicted: 21.53211004080499\n",
      "Target:  34.9 , predicted: 31.084403500872533\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    y_hat = predict_fn(x_train, thetas)\n",
    "    print(\"Target: \", y_train[i][0], \", predicted:\", y_hat[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
