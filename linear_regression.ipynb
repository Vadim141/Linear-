{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0      1     0\n",
      "0  23.98  6.459  11.8\n",
      "1  21.52  6.193  11.0\n",
      "2   7.74  6.750  23.7\n",
      "3   4.81  7.249  35.4\n",
      "4  18.06  5.454  15.2\n",
      "5   5.90  6.487  24.4\n",
      "6   2.94  6.998  33.4\n",
      "7   6.36  7.163  31.6\n",
      "8  17.44  6.749  13.4\n",
      "9   4.56  6.975  34.9\n",
      "Shape of train features: (354, 2)\n",
      "Shape of train targets: (354, 1)\n"
     ]
    }
   ],
   "source": [
    "# Step 2. Parse and visualize data\n",
    "# parse train data: read CSV files with train features (train_x) and train targets (train_y)\n",
    "x_train = pd.read_csv(\"D:\\\\Dataset\\\\train\\\\train_x.csv\", header=None)\n",
    "y_train = pd.read_csv(\"D:\\\\Dataset\\\\train\\\\train_y.csv\", header=None)\n",
    "\n",
    "# show first 10 samples\n",
    "print(pd.concat([x_train, y_train], axis=1).head(10))\n",
    "\n",
    "x_train = x_train.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "print(\"Shape of train features:\", x_train.shape)\n",
    "print(\"Shape of train targets:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3. Prototypes.\n",
    "\n",
    "# In this demo we will use linear regression to predict targets from features.\n",
    "# In linear regression model with parameters thetas \n",
    "# the prediction y is calculated from features x using linear combination of x and thetas.\n",
    "# For example, for the case of 2 features: \n",
    "# y = theta_0 * x_o + theta_1 * x_1\n",
    "\n",
    "# Let's define some helper functions\n",
    "\n",
    "def predict_fn(x, thetas):\n",
    "    '''\n",
    "    Predict target from features x using parameters thetas and linear regression\n",
    "    \n",
    "    param x: input features, shape NxM, N - number of samples to predict, M - number of features\n",
    "    param thetas: vector of linear regression parameters, shape Mx1\n",
    "    return y_hat: predicted scalar value for each input samples, shape Nx1\n",
    "    '''    \n",
    "    # TODO: calculate y_hat using linear regression\n",
    "    y_hat = np.zeros((x.shape[0], 1))\n",
    "    for i in range(len(x)):\n",
    "        y_hat[i] = thetas[0] * x[i][0] + thetas[1] * x[i][1]\n",
    "    return y_hat\n",
    "\n",
    "\n",
    "def loss_fn(x_train, y_train, thetas):\n",
    "    '''\n",
    "    Calculate average loss value for train dataset (x_train, y_train).\n",
    "    \n",
    "    param x_train: input features, shape NxM, N - number of samples to predict, M - number of features\n",
    "    param y_train: input tagrets, shape Nx1\n",
    "    param thetas: vector of linear regression parameters, shape Mx1\n",
    "    return loss: predicted scalar value for each input samples, shape Mx1\n",
    "    '''\n",
    "    y_predicted = predict_fn(x_train, thetas)    \n",
    "    loss = np.mean(np.power(y_train - y_predicted, 2))   \n",
    "    return loss\n",
    "\n",
    "\n",
    "def gradient_fn(x_train, y_train, thetas):\n",
    "    '''\n",
    "    Calculate gradient value for linear regression.\n",
    "    \n",
    "    param x_train: input features, shape NxM, N - number of samples to predict, M - number of features\n",
    "    param y_train: input tagrets, shape Nx1\n",
    "    param thetas: vector of linear regression parameters, shape Mx1\n",
    "    return g: predicted scalar value for each input samples, shape Mx1\n",
    "    '''  \n",
    "    # TODO: calculate vector gradient\n",
    "    g = np.zeros_like(thetas)\n",
    "    for i in range(len(x_train)):\n",
    "        g[0] += -2 * x_train[i][0] * (y_train[i] - x_train[i][0] * thetas[0] - x_train[i][1] * thetas[1])\n",
    "        g[1] += -2 * x_train[i][1] * (y_train[i] - x_train[i][0] * thetas[0] - x_train[i][1] * thetas[1])\n",
    "    g[0] = g[0] / len(x_train)\n",
    "    g[1] = g[1] / len(x_train)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                          | 0/1000000 [00:00<?, ?it/s, loss_val=1.27e+3][[-827.64405959]\n",
      " [-446.58327978]]\n",
      "Training:   0%|                                  | 0/1000000 [00:00<?, ?it/s, loss_val=1208.8392, thetas=2.9688 0.9562][[906.04602541]\n",
      " [234.77671013]]\n",
      "[[-829.11926445]\n",
      " [-425.058166  ]]\n",
      "[[893.36451643]\n",
      " [249.95592526]]\n",
      "[[-829.34129779]\n",
      " [-406.8979044 ]]\n",
      "[[881.8993738 ]\n",
      " [262.10735005]]\n",
      "[[-828.53527778]\n",
      " [-391.51896387]]\n",
      "[[871.44549438]\n",
      " [271.76105434]]\n",
      "Training:   0%|                        | 8/1000000 [00:00<3:33:31, 78.06it/s, loss_val=1208.8392, thetas=2.9688 0.9562][[-826.88706002]\n",
      " [-378.43944746]]\n",
      "[[861.8334579 ]\n",
      " [279.35475087]]\n",
      "[[-824.55007743]\n",
      " [-367.2613877 ]]\n",
      "[[852.92331133]\n",
      " [285.24988424]]\n",
      "[[-821.65098866]\n",
      " [-357.65612599]]\n",
      "[[844.59943586]\n",
      " [289.74491703]]\n",
      "[[-818.29434257]\n",
      " [-349.35223902]]\n",
      "[[836.76630823]\n",
      " [293.08630151]]\n",
      "[[-814.56643007]\n",
      " [-342.12556842]]\n",
      "Training:   0%|                       | 17/1000000 [00:00<3:26:39, 80.65it/s, loss_val=1208.8392, thetas=2.9688 0.9562][[829.3450003 ]\n",
      " [295.47754008]]\n",
      "[[-810.53846498]\n",
      " [-335.79098721]]\n",
      "[[822.2702885 ]\n",
      " [297.08666729]]\n",
      "[[-806.26921087]\n",
      " [-330.19560057]]\n",
      "[[815.48826673]\n",
      " [298.05242858]]\n",
      "[[-801.80715013]\n",
      " [-325.21313112]]\n",
      "[[808.95437519]\n",
      " [298.48938255]]\n",
      "[[-797.19227536]\n",
      " [-320.73928214]]\n",
      "[[802.63177252]\n",
      " [298.49211451]]\n",
      "Training:   0%|                       | 26/1000000 [00:00<3:21:50, 82.57it/s, loss_val=1208.8392, thetas=2.9688 0.9562][[-792.45756853]\n",
      " [-316.68790871]]\n",
      "[[796.48999152]\n",
      " [298.13871599]]\n",
      "[[-787.6302226 ]\n",
      " [-312.98785565]]\n",
      "[[790.50382907]\n",
      " [297.49365806]]\n",
      "[[-782.73265025]\n",
      " [-309.5803465 ]]\n",
      "[[784.65242944]\n",
      " [296.61016417]]\n",
      "[[-777.78331693]\n",
      " [-306.41682716]]\n",
      "[[778.9185272 ]\n",
      " [295.53216965]]\n",
      "[[-772.79742872]\n",
      " [-303.45718527]]\n",
      "Training:   0%|                       | 35/1000000 [00:00<3:18:28, 83.97it/s, loss_val=1208.8392, thetas=2.9688 0.9562][[773.28782215]\n",
      " [294.29593978]]\n",
      "[[-767.78750048]\n",
      " [-300.66827978]]\n",
      "[[767.748463  ]\n",
      " [292.93140608]]\n",
      "[[-762.76382488]\n",
      " [-298.02272661]]\n",
      "[[762.29062108]\n",
      " [291.46326975]]\n",
      "[[-757.73485985]\n",
      " [-295.49789593]]\n",
      "[[756.90613829]\n",
      " [289.91191293]]\n",
      "[[-752.70754848]\n",
      " [-293.07508401]]\n",
      "[[751.58823636]\n",
      " [288.29415117]]\n",
      "Training:   0%|                       | 44/1000000 [00:00<3:17:46, 84.27it/s, loss_val=1208.8392, thetas=2.9688 0.9562][[-747.68758316]\n",
      " [-290.73882948]]\n",
      "[[746.33127675]\n",
      " [286.62385489]]\n",
      "[[-742.67962374]\n",
      " [-288.47634853]]\n",
      "[[741.13056241]\n",
      " [284.91246248]]\n",
      "[[-737.68747772]\n",
      " [-286.27706863]]\n",
      "[[735.98217405]\n",
      " [283.16940413]]\n",
      "[[-732.71424896]\n",
      " [-284.13224341]]\n",
      "[[730.8828349 ]\n",
      " [281.40245171]]\n",
      "[[-727.76246056]\n",
      " [-282.03463468]]\n",
      "[[725.82979909]\n",
      " [279.61800782]]\n",
      "Training:   0%|                       | 54/1000000 [00:00<3:13:24, 86.17it/s, loss_val=1208.8392, thetas=2.9688 0.9562][[-722.83415629]\n",
      " [-279.97824974]]\n",
      "[[720.82075942]\n",
      " [277.82134437]]\n",
      "[[-717.93098438]\n",
      " [-277.9581246 ]]\n",
      "[[715.85377122]\n",
      " [276.01679969]]\n",
      "[[-713.05426667]\n",
      " [-275.97014481]]\n",
      "[[710.92718947]\n",
      " [274.20794124]]\n",
      "[[-708.20505575]\n",
      " [-274.01089762]]\n",
      "[[706.03961687]\n",
      " [272.39770003]]\n",
      "[[-703.38418214]\n",
      " [-272.07754982]]\n",
      "Training:   0%|                       | 63/1000000 [00:00<3:12:00, 86.80it/s, loss_val=1208.8392, thetas=2.9688 0.9562][[701.18986094]\n",
      " [270.58848156]]\n",
      "[[-698.59229321]\n",
      " [-270.16774692]]\n",
      "[[696.3768986 ]\n",
      " [268.78225748]]\n",
      "[[-693.82988539]\n",
      " [-268.27952979]]\n",
      "[[691.59984695]\n",
      " [266.98064129]]\n",
      "[[-689.09733067]\n",
      " [-266.41126597]]\n",
      "[[686.85793908]\n",
      " [265.1849508 ]]\n",
      "[[-684.39489861]\n",
      " [-264.56159279]]\n",
      "[[682.15050416]\n",
      " [263.39625976]]\n",
      "Training:   0%|                       | 72/1000000 [00:00<3:13:15, 86.24it/s, loss_val=1208.8392, thetas=2.9688 0.9562][[-679.72277436]\n",
      " [-262.72937054]]\n",
      "[[677.4769509 ]\n",
      " [261.61544044]]\n",
      "[[-675.08107368]\n",
      " [-260.91364367]]\n",
      "[[672.83675402]\n",
      " [259.84319889]]\n",
      "[[-670.46985527]\n",
      " [-259.11360884]]\n",
      "[[668.22944295]\n",
      " [258.08010394]]\n",
      "[[-665.88913094]\n",
      " [-257.32858849]]\n",
      "[[663.65459256]\n",
      " [256.32661121]]\n",
      "[[-661.33887405]\n",
      " [-255.55800905]]\n",
      "Training:   0%|                       | 81/1000000 [00:00<3:14:41, 85.60it/s, loss_val=1208.8392, thetas=2.9688 0.9562][[659.11181553]\n",
      " [254.58308296]]\n",
      "[[-656.81902645]\n",
      " [-253.80138287]]\n",
      "[[654.60075598]\n",
      " [252.84980439]]\n",
      "[[-652.32950421]\n",
      " [-252.0582934 ]]\n",
      "[[650.12108422]\n",
      " [251.12699723]]\n",
      "[[-647.87020238]\n",
      " [-250.32838288]]\n",
      "[[645.67249249]\n",
      " [249.41483084]]\n",
      "[[-643.44099886]\n",
      " [-248.61134217]]\n",
      "[[641.25469133]\n",
      " [247.71343144]]\n",
      "Training:   0%|                       | 90/1000000 [00:01<3:15:50, 85.09it/s, loss_val=1208.8392, thetas=2.9688 0.9562][[-639.04175766]\n",
      " [-246.90690242]]\n",
      "[[636.86740666]\n",
      " [246.02288973]]\n",
      "[[-634.67233156]\n",
      " [-245.2148281 ]]\n",
      "[[632.51037733]\n",
      " [244.34326715]]\n",
      "[[-630.33256426]\n",
      " [-243.53491132]]\n",
      "[[628.18335313]\n",
      " [242.67460109]]\n",
      "[[-626.02229228]\n",
      " [-241.86696709]]\n",
      "[[623.88609307]\n",
      " [241.01690915]]\n",
      "[[-621.74134635]\n",
      " [-240.21082942]]\n",
      "Training:   0%|                       | 99/1000000 [00:01<3:14:49, 85.54it/s, loss_val=1208.8392, thetas=2.9688 0.9562][[619.61836406]\n",
      " [239.37019271]]\n",
      "[[-617.48955274]\n",
      " [-238.56634812]]\n",
      "Training:   0%|                        | 99/1000000 [00:01<3:14:49, 85.54it/s, loss_val=487.9329, thetas=0.6449 5.3875][[615.37993974]\n",
      " [237.7344398 ]]\n",
      "[[-613.26673423]\n",
      " [-236.9333861 ]]\n",
      "[[611.17059954]\n",
      " [236.10962756]]\n",
      "[[-609.07271091]\n",
      " [-235.31181723]]\n",
      "[[606.99012793]\n",
      " [234.4957242 ]]\n",
      "[[-604.90730098]\n",
      " [-233.70152446]]\n",
      "[[602.83831371]\n",
      " [232.89269064]]\n",
      "Training:   0%|                       | 108/1000000 [00:01<3:15:46, 85.12it/s, loss_val=487.9329, thetas=0.6449 5.3875][[-600.77032119]\n",
      " [-232.10239839]]\n",
      "[[598.71494956]\n",
      " [231.30048189]]\n",
      "[[-596.66158741]\n",
      " [-230.51433596]]\n",
      "[[594.61983152]\n",
      " [229.71904815]]\n",
      "[[-592.58091495]\n",
      " [-228.93723949]]\n",
      "[[590.55275867]\n",
      " [228.14833574]]\n",
      "[[-588.52811893]\n",
      " [-227.37101577]]\n",
      "[[586.51353282]\n",
      " [226.58828786]]\n",
      "[[-584.50301447]\n",
      " [-225.81557543]]\n",
      "Training:   0%|                       | 117/1000000 [00:01<3:14:46, 85.56it/s, loss_val=487.9329, thetas=0.6449 5.3875][[582.50195822]\n",
      " [225.03884522]]\n",
      "[[-580.50541698]\n",
      " [-224.27083232]]\n",
      "[[578.51784141]\n",
      " [223.49994655]]\n",
      "[[-576.53514227]\n",
      " [-222.73670302]]\n",
      "[[574.56099099]\n",
      " [221.97152905]]\n",
      "[[-572.59200675]\n",
      " [-221.21310648]]\n",
      "[[570.6312175 ]\n",
      " [220.45352872]]\n",
      "[[-568.67582749]\n",
      " [-219.69996369]]\n",
      "[[566.7283333 ]\n",
      " [218.94588065]]\n",
      "Training:   0%|                       | 126/1000000 [00:01<3:13:31, 86.11it/s, loss_val=487.9329, thetas=0.6449 5.3875][[-564.78642235]\n",
      " [-218.19719737]]\n",
      "[[562.85215246]\n",
      " [217.44851928]]\n",
      "[[-560.92361005]\n",
      " [-216.70473179]]\n",
      "[[559.00249066]\n",
      " [215.96137859]]\n",
      "[[-557.08721024]\n",
      " [-215.22249257]]\n",
      "[[555.17916515]\n",
      " [214.48439225]]\n",
      "[[-553.27704351]\n",
      " [-213.75040651]]\n",
      "[[551.38199466]\n",
      " [213.01749375]]\n",
      "[[-549.49293148]\n",
      " [-212.2884015 ]]\n",
      "Training:   0%|                       | 135/1000000 [00:01<3:14:18, 85.76it/s, loss_val=487.9329, thetas=0.6449 5.3875][[547.61079936]\n",
      " [211.56061655]]\n",
      "[[-545.73469681]\n",
      " [-210.83640636]]\n",
      "[[543.86540081]\n",
      " [210.1136941 ]]\n",
      "[[-542.00216321]\n",
      " [-209.3943508 ]]\n",
      "[[540.14562194]\n",
      " [208.67665999]]\n",
      "[[-538.2951555 ]\n",
      " [-207.96216534]]\n",
      "[[536.451287  ]\n",
      " [207.24944796]]\n",
      "[[-534.61349955]\n",
      " [-206.53978121]]\n",
      "[[532.78222151]\n",
      " [205.83199197]]\n",
      "Training:   0%|                       | 144/1000000 [00:01<3:13:44, 86.01it/s, loss_val=487.9329, thetas=0.6449 5.3875][[-530.95702239]\n",
      " [-205.12713036]]\n",
      "[[529.13825229]\n",
      " [204.42422622]]\n",
      "[[-527.32555212]\n",
      " [-203.72414536]]\n",
      "[[525.51920739]\n",
      " [203.02608522]]\n",
      "[[-523.71891799]\n",
      " [-202.33075939]]\n",
      "[[521.92491611]\n",
      " [201.63750376]]\n",
      "[[-520.13695035]\n",
      " [-200.94690623]]\n",
      "[[518.35520892]\n",
      " [200.258417  ]]\n",
      "[[-516.57948068]\n",
      " [-199.5725202 ]]\n",
      "Training:   0%|                       | 153/1000000 [00:01<3:15:01, 85.45it/s, loss_val=487.9329, thetas=0.6449 5.3875][[514.80991752]\n",
      " [198.88876044]]\n",
      "[[-513.04634158]\n",
      " [-198.20753615]]\n",
      "[[511.28887478]\n",
      " [197.52846993]]\n",
      "[[-509.53736676]\n",
      " [-196.85188945]]\n",
      "[[507.79191474]\n",
      " [196.17748171]]\n",
      "[[-506.05239107]\n",
      " [-195.50551596]]\n",
      "[[504.31887259]\n",
      " [194.8357324 ]]\n",
      "[[-502.59125044]\n",
      " [-194.16835205]]\n",
      "[[500.86958466]\n",
      " [193.50315903]]\n",
      "Training:   0%|                       | 162/1000000 [00:01<3:13:41, 86.03it/s, loss_val=487.9329, thetas=0.6449 5.3875][[-499.15378193]\n",
      " [-192.84033453]]\n",
      "[[497.44388842]\n",
      " [192.17969898]]\n",
      "[[-495.73982368]\n",
      " [-191.52140071]]\n",
      "[[494.04162246]\n",
      " [190.86529009]]\n",
      "[[-492.34921496]\n",
      " [-190.21148831]]\n",
      "[[490.6626265 ]\n",
      " [189.55987054]]\n",
      "[[-488.98179609]\n",
      " [-188.91053555]]\n",
      "[[487.30674133]\n",
      " [188.26337896]]\n",
      "[[-485.63740851]\n",
      " [-187.61848105]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:   0%|                       | 171/1000000 [00:01<3:13:52, 85.95it/s, loss_val=487.9329, thetas=0.6449 5.3875][[483.97380886]\n",
      " [186.97575435]]\n",
      "[[-482.31589473]\n",
      " [-186.33526389]]\n",
      "[[480.66367208]\n",
      " [185.69693615]]\n",
      "[[-479.01709831]\n",
      " [-185.06082356]]\n",
      "[[477.37617506]\n",
      " [184.42686416]]\n",
      "[[-475.7408639 ]\n",
      " [-183.79509998]]\n",
      "[[474.11116294]\n",
      " [183.16547861]]\n",
      "[[-472.48703721]\n",
      " [-182.53803351]]\n",
      "[[470.86848192]\n",
      " [181.91272013]]\n",
      "Training:   0%|                       | 180/1000000 [00:02<3:13:59, 85.90it/s, loss_val=487.9329, thetas=0.6449 5.3875][[-469.25546498]\n",
      " [-181.28956489]]\n",
      "[[467.64797925]\n",
      " [180.66852975]]\n",
      "[[-466.04599503]\n",
      " [-180.04963529]]\n",
      "[[464.44950324]\n",
      " [179.43284888]]\n",
      "[[-462.85847619]\n",
      " [-178.81818629]]\n",
      "[[461.27290323]\n",
      " [178.20561935]]\n",
      "[[-459.69275833]\n",
      " [-177.59515987]]\n",
      "[[458.11802958]\n",
      " [176.98678337]]\n",
      "[[-456.54869236]\n",
      " [-176.3804984 ]]\n",
      "Training:   0%|                       | 189/1000000 [00:02<3:12:58, 86.35it/s, loss_val=487.9329, thetas=0.6449 5.3875][[454.9847337 ]\n",
      " [175.77628354]]\n",
      "[[-453.42613018]\n",
      " [-175.17414466]]\n",
      "[[451.872868  ]\n",
      " [174.57406287]]\n",
      "[[-450.32492473]\n",
      " [-173.97604182]]\n",
      "[[448.78228591]\n",
      " [173.38006473]]\n",
      "[[-447.24492995]\n",
      " [-172.78613344]]\n",
      "[[445.71284185]\n",
      " [172.19423291]]\n",
      "[[-444.18600075]\n",
      " [-171.60436346]]\n",
      "[[442.66439125]\n",
      " [171.01651154]]\n",
      "Training:   0%|                       | 198/1000000 [00:02<3:11:08, 87.18it/s, loss_val=487.9329, thetas=0.6449 5.3875][[-441.14799308]\n",
      " [-170.43067623]]\n",
      "[[439.63679052]\n",
      " [169.84684516]]\n",
      "[[-438.13076383]\n",
      " [-169.26501644]]\n",
      "Training:   0%|                       | 198/1000000 [00:02<3:11:08, 87.18it/s, loss_val=259.5459, thetas=0.2670 5.2419][[436.62989705]\n",
      " [168.68517869]]\n",
      "[[-435.1341709 ]\n",
      " [-168.10732919]]\n",
      "[[433.64356923]\n",
      " [167.53145741]]\n",
      "[[-432.15807315]\n",
      " [-166.95755996]]\n",
      "[[430.67766638]\n",
      " [166.38562699]]\n",
      "[[-429.20233039]\n",
      " [-165.81565458]]\n",
      "Training:   0%|                       | 207/1000000 [00:02<3:14:51, 85.51it/s, loss_val=259.5459, thetas=0.2670 5.2419][[427.73204881]\n",
      " [165.24763346]]\n",
      "[[-426.26680342]\n",
      " [-164.68155927]]\n",
      "[[424.80657778]\n",
      " [164.11742322]]\n",
      "[[-423.35135396]\n",
      " [-163.5552206 ]]\n",
      "[[421.9011155 ]\n",
      " [162.99494304]]\n",
      "[[-420.45584471]\n",
      " [-162.43658553]]\n",
      "[[419.01552512]\n",
      " [161.88014005]]\n",
      "[[-417.58013927]\n",
      " [-161.32560136]]\n",
      "[[416.14967071]\n",
      " [160.77296174]]\n",
      "Training:   0%|                       | 216/1000000 [00:02<3:14:07, 85.83it/s, loss_val=259.5459, thetas=0.2670 5.2419][[-414.72410219]\n",
      " [-160.22221577]]\n",
      "[[413.30341731]\n",
      " [159.67335597]]\n",
      "[[-411.88759897]\n",
      " [-159.12637678]]\n",
      "[[410.47663083]\n",
      " [158.58127094]]\n",
      "[[-409.070496  ]\n",
      " [-158.03803278]]\n",
      "[[407.66917816]\n",
      " [157.49665522]]\n",
      "[[-406.27266058]\n",
      " [-156.95713251]]\n",
      "[[404.88092704]\n",
      " [156.41945772]]\n",
      "[[-403.49396094]\n",
      " [-155.88362504]]\n",
      "Training:   0%|                       | 225/1000000 [00:02<3:13:32, 86.10it/s, loss_val=259.5459, thetas=0.2670 5.2419][[402.11174614]\n",
      " [155.34962771]]\n",
      "[[-400.73426621]\n",
      " [-154.81745983]]\n",
      "[[399.36150505]\n",
      " [154.28711479]]\n",
      "[[-397.99344638]\n",
      " [-153.75858666]]\n",
      "[[396.63007422]\n",
      " [153.23186891]]\n",
      "[[-395.27137239]\n",
      " [-152.70695564]]\n",
      "[[393.91732499]\n",
      " [152.18384039]]\n",
      "[[-392.567916  ]\n",
      " [-151.66251724]]\n",
      "[[391.2231296 ]\n",
      " [151.14297985]]\n",
      "Training:   0%|                       | 234/1000000 [00:02<3:12:38, 86.49it/s, loss_val=259.5459, thetas=0.2670 5.2419][[-389.88294988]\n",
      " [-150.62522228]]\n",
      "[[388.54736114]\n",
      " [150.10923827]]\n",
      "[[-387.21634758]\n",
      " [-149.59502189]]\n",
      "[[385.88989359]\n",
      " [149.08256696]]\n",
      "[[-384.56798349]\n",
      " [-148.57186756]]\n",
      "[[383.25060177]\n",
      " [148.06291756]]\n",
      "[[-381.93773287]\n",
      " [-147.55571108]]\n",
      "[[380.62936137]\n",
      " [147.05024204]]\n",
      "[[-379.32547183]\n",
      " [-146.5465046 ]]\n",
      "Training:   0%|                       | 243/1000000 [00:02<3:14:14, 85.78it/s, loss_val=259.5459, thetas=0.2670 5.2419][[378.02604893]\n",
      " [146.04449272]]\n",
      "[[-376.73107734]\n",
      " [-145.54420058]]\n",
      "[[375.44054184]\n",
      " [145.04562221]]\n",
      "[[-374.1544272 ]\n",
      " [-144.54875181]]\n",
      "[[372.8727183 ]\n",
      " [144.05358347]]\n",
      "[[-371.59540004]\n",
      " [-143.56011141]]\n",
      "[[370.32245738]\n",
      " [143.06832978]]\n",
      "[[-369.05387533]\n",
      " [-142.57823281]]\n",
      "[[367.78963896]\n",
      " [142.08981472]]\n",
      "Training:   0%|                       | 252/1000000 [00:02<3:13:41, 86.02it/s, loss_val=259.5459, thetas=0.2670 5.2419][[-366.52973337]\n",
      " [-141.60306977]]\n",
      "[[365.27414373]\n",
      " [141.11799221]]\n",
      "[[-364.02285526]\n",
      " [-140.63457635]]\n",
      "[[362.77585322]\n",
      " [140.15281647]]\n",
      "[[-361.53312293]\n",
      " [-139.67270693]]\n",
      "[[360.29464976]\n",
      " [139.19424205]]\n",
      "[[-359.06041911]\n",
      " [-138.71741621]]\n",
      "[[357.83041647]\n",
      " [138.24222379]]\n",
      "[[-356.60462734]\n",
      " [-137.7686592 ]]\n",
      "Training:   0%|                       | 261/1000000 [00:03<3:13:52, 85.95it/s, loss_val=259.5459, thetas=0.2670 5.2419][[355.38303729]\n",
      " [137.29671686]]\n",
      "[[-354.16563194]\n",
      " [-136.82639121]]\n",
      "[[352.95239695]\n",
      " [136.35767671]]\n",
      "[[-351.74331804]\n",
      " [-135.89056786]]\n",
      "[[350.53838096]\n",
      " [135.42505913]]\n",
      "[[-349.33757153]\n",
      " [-134.96114506]]\n",
      "[[348.14087562]\n",
      " [134.49882018]]\n",
      "[[-346.94827912]\n",
      " [-134.03807905]]\n",
      "[[345.759768  ]\n",
      " [133.57891623]]\n",
      "Training:   0%|                       | 270/1000000 [00:03<3:17:19, 84.44it/s, loss_val=259.5459, thetas=0.2670 5.2419][[-344.57532826]\n",
      " [-133.12132634]]\n",
      "[[343.39494596]\n",
      " [132.66530397]]\n",
      "[[-342.21860719]\n",
      " [-132.21084375]]\n",
      "[[341.0462981 ]\n",
      " [131.75794034]]\n",
      "[[-339.8780049 ]\n",
      " [-131.30658841]]\n",
      "[[338.71371381]\n",
      " [130.85678263]]\n",
      "[[-337.55341114]\n",
      " [-130.40851772]]\n",
      "[[336.39708322]\n",
      " [129.96178838]]\n",
      "[[-335.24471643]\n",
      " [-129.51658937]]\n",
      "Training:   0%|                       | 279/1000000 [00:03<3:20:17, 83.19it/s, loss_val=259.5459, thetas=0.2670 5.2419][[334.09629721]\n",
      " [129.07291544]]\n",
      "[[-332.95181202]\n",
      " [-128.63076137]]\n",
      "[[331.81124741]\n",
      " [128.19012194]]\n",
      "[[-330.67458993]\n",
      " [-127.75099198]]\n",
      "[[329.54182619]\n",
      " [127.3133663 ]]\n",
      "[[-328.41294288]\n",
      " [-126.87723977]]\n",
      "[[327.28792668]\n",
      " [126.44260723]]\n",
      "[[-326.16676435]\n",
      " [-126.00946358]]\n",
      "[[325.04944269]\n",
      " [125.57780371]]\n",
      "Training:   0%|                       | 288/1000000 [00:03<3:20:08, 83.25it/s, loss_val=259.5459, thetas=0.2670 5.2419][[-323.93594855]\n",
      " [-125.14762254]]\n",
      "[[322.8262688 ]\n",
      " [124.71891501]]\n",
      "[[-321.7203904 ]\n",
      " [-124.29167606]]\n",
      "[[320.6183003 ]\n",
      " [123.86590067]]\n",
      "[[-319.51998554]\n",
      " [-123.44158382]]\n",
      "[[318.42543319]\n",
      " [123.01872052]]\n",
      "[[-317.33463035]\n",
      " [-122.59730578]]\n",
      "[[316.24756418]\n",
      " [122.17733465]]\n",
      "[[-315.16422188]\n",
      " [-121.75880218]]\n",
      "Training:   0%|                       | 297/1000000 [00:03<3:18:56, 83.75it/s, loss_val=259.5459, thetas=0.2670 5.2419][[314.08459069]\n",
      " [121.34170344]]\n",
      "[[-313.00865791]\n",
      " [-120.92603352]]\n",
      "[[311.93641085]\n",
      " [120.51178752]]\n",
      "[[-310.8678369 ]\n",
      " [-120.09896057]]\n",
      "Training:   0%|                      | 297/1000000 [00:03<3:18:56, 83.75it/s, loss_val=144.5677, thetas=-0.0011 5.1383][[309.80292347]\n",
      " [119.68754781]]\n",
      "[[-308.74165803]\n",
      " [-119.27754439]]\n",
      "[[307.68402807]\n",
      " [118.86894548]]\n",
      "[[-306.63002115]\n",
      " [-118.46174628]]\n",
      "[[305.57962484]\n",
      " [118.05594198]]\n",
      "Training:   0%|                      | 306/1000000 [00:03<3:20:51, 82.95it/s, loss_val=144.5677, thetas=-0.0011 5.1383][[-304.53282679]\n",
      " [-117.65152781]]\n",
      "[[303.48961467]\n",
      " [117.24849901]]\n",
      "[[-302.44997619]\n",
      " [-116.84685083]]\n",
      "[[301.41389911]\n",
      " [116.44657854]]\n",
      "[[-300.38137123]\n",
      " [-116.04767743]]\n",
      "[[299.35238039]\n",
      " [115.6501428 ]]\n",
      "[[-298.32691448]\n",
      " [-115.25396998]]\n",
      "[[297.30496142]\n",
      " [114.85915428]]\n",
      "[[-296.28650918]\n",
      " [-114.46569108]]\n",
      "Training:   0%|                      | 315/1000000 [00:03<3:17:46, 84.25it/s, loss_val=144.5677, thetas=-0.0011 5.1383][[295.27154577]\n",
      " [114.07357573]]\n",
      "[[-294.26005922]\n",
      " [-113.68280361]]\n",
      "[[293.25203764]\n",
      " [113.29337013]]\n",
      "[[-292.24746916]\n",
      " [-112.9052707 ]]\n",
      "[[291.24634193]\n",
      " [112.51850074]]\n",
      "[[-290.24864419]\n",
      " [-112.13305571]]\n",
      "[[289.25436417]\n",
      " [111.74893107]]\n",
      "[[-288.26349017]\n",
      " [-111.36612229]]\n",
      "[[287.27601053]\n",
      " [110.98462487]]\n",
      "Training:   0%|                      | 324/1000000 [00:03<3:17:16, 84.46it/s, loss_val=144.5677, thetas=-0.0011 5.1383][[-286.29191361]\n",
      " [-110.60443431]]\n",
      "[[285.31118782]\n",
      " [110.22554613]]\n",
      "[[-284.33382163]\n",
      " [-109.84795588]]\n",
      "[[283.35980351]\n",
      " [109.47165911]]\n",
      "[[-282.38912201]\n",
      " [-109.09665139]]\n",
      "[[281.42176569]\n",
      " [108.7229283 ]]\n",
      "[[-280.45772315]\n",
      " [-108.35048544]]\n",
      "[[279.49698306]\n",
      " [107.97931842]]\n",
      "[[-278.53953409]\n",
      " [-107.60942289]]\n",
      "Training:   0%|                      | 333/1000000 [00:03<3:16:55, 84.61it/s, loss_val=144.5677, thetas=-0.0011 5.1383][[277.58536497]\n",
      " [107.24079447]]\n",
      "[[-276.63446447]\n",
      " [-106.87342883]]\n",
      "[[275.68682138]\n",
      " [106.50732164]]\n",
      "[[-274.74242456]\n",
      " [-106.14246859]]\n",
      "[[273.80126288]\n",
      " [105.77886539]]\n",
      "[[-272.86332525]\n",
      " [-105.41650776]]\n",
      "[[271.92860063]\n",
      " [105.05539142]]\n",
      "[[-270.99707803]\n",
      " [-104.69551213]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[270.06874646]\n",
      " [104.33686565]]\n",
      "Training:   0%|                      | 342/1000000 [00:04<3:16:07, 84.95it/s, loss_val=144.5677, thetas=-0.0011 5.1383][[-269.14359499]\n",
      " [-103.97944775]]\n",
      "[[268.22161274]\n",
      " [103.62325422]]\n",
      "[[-267.30278885]\n",
      " [-103.26828088]]\n",
      "[[266.38711249]\n",
      " [102.91452354]]\n",
      "[[-265.47457288]\n",
      " [-102.56197804]]\n",
      "[[264.56515929]\n",
      " [102.21064022]]\n",
      "[[-263.65886099]\n",
      " [-101.86050595]]\n",
      "[[262.75566733]\n",
      " [101.51157111]]\n",
      "[[-261.85556765]\n",
      " [-101.16383158]]\n",
      "Training:   0%|                      | 351/1000000 [00:04<3:18:20, 84.00it/s, loss_val=144.5677, thetas=-0.0011 5.1383][[260.95855138]\n",
      " [100.81728327]]\n",
      "[[-260.06460793]\n",
      " [-100.47192211]]\n",
      "[[259.17372679]\n",
      " [100.12774401]]\n",
      "[[-258.28589747]\n",
      " [ -99.78474494]]\n",
      "[[257.4011095 ]\n",
      " [ 99.44292086]]\n",
      "[[-256.51935248]\n",
      " [ -99.10226773]]\n",
      "[[255.64061602]\n",
      " [ 98.76278154]]\n",
      "[[-254.76488977]\n",
      " [ -98.42445831]]\n",
      "[[253.89216342]\n",
      " [ 98.08729404]]\n",
      "Training:   0%|                      | 360/1000000 [00:04<3:18:35, 83.89it/s, loss_val=144.5677, thetas=-0.0011 5.1383][[-253.0224267 ]\n",
      " [ -97.75128476]]\n",
      "[[252.15566936]\n",
      " [ 97.41642653]]\n",
      "[[-251.2918812 ]\n",
      " [ -97.08271538]]\n",
      "[[250.43105204]\n",
      " [ 96.75014741]]\n",
      "[[-249.57317175]\n",
      " [ -96.41871868]]\n",
      "[[248.71823023]\n",
      " [ 96.0884253 ]]\n",
      "[[-247.8662174 ]\n",
      " [ -95.75926338]]\n",
      "[[247.01712325]\n",
      " [ 95.43122905]]\n",
      "[[-246.17093777]\n",
      " [ -95.10431843]]\n",
      "Training:   0%|                      | 369/1000000 [00:04<3:17:50, 84.21it/s, loss_val=144.5677, thetas=-0.0011 5.1383][[245.32765099]\n",
      " [ 94.77852768]]\n",
      "[[-244.48725298]\n",
      " [ -94.45385296]]\n",
      "[[243.64973386]\n",
      " [ 94.13029045]]\n",
      "[[-242.81508375]\n",
      " [ -93.80783635]]\n",
      "[[241.98329284]\n",
      " [ 93.48648685]]\n",
      "[[-241.15435131]\n",
      " [ -93.16623816]]\n",
      "[[240.32824943]\n",
      " [ 92.84708653]]\n",
      "[[-239.50497745]\n",
      " [ -92.52902819]]\n",
      "[[238.68452568]\n",
      " [ 92.21205939]]\n",
      "Training:   0%|                      | 378/1000000 [00:04<3:15:39, 85.15it/s, loss_val=144.5677, thetas=-0.0011 5.1383][[-237.86688446]\n",
      " [ -91.89617641]]\n",
      "[[237.05204417]\n",
      " [ 91.58137551]]\n",
      "[[-236.23999521]\n",
      " [ -91.26765301]]\n",
      "[[235.43072801]\n",
      " [ 90.9550052 ]]\n",
      "[[-234.62423305]\n",
      " [ -90.6434284 ]]\n",
      "[[233.82050083]\n",
      " [ 90.33291894]]\n",
      "[[-233.01952189]\n",
      " [ -90.02347316]]\n",
      "[[232.22128679]\n",
      " [ 89.71508743]]\n",
      "[[-231.42578614]\n",
      " [ -89.40775811]]\n",
      "Training:   0%|                      | 387/1000000 [00:04<3:15:47, 85.09it/s, loss_val=144.5677, thetas=-0.0011 5.1383][[230.63301057]\n",
      " [ 89.10148158]]\n",
      "[[-229.84295074]\n",
      " [ -88.79625424]]\n",
      "[[229.05559736]\n",
      " [ 88.49207248]]\n",
      "[[-228.27094114]\n",
      " [ -88.18893274]]\n",
      "[[227.48897285]\n",
      " [ 87.88683144]]\n",
      "[[-226.70968328]\n",
      " [ -87.58576502]]\n",
      "[[225.93306326]\n",
      " [ 87.28572993]]\n",
      "[[-225.15910364]\n",
      " [ -86.98672266]]\n",
      "[[224.38779531]\n",
      " [ 86.68873966]]\n",
      "Training:   0%|                      | 396/1000000 [00:04<3:16:05, 84.96it/s, loss_val=144.5677, thetas=-0.0011 5.1383][[-223.61912919]\n",
      " [ -86.39177744]]\n",
      "[[222.85309621]\n",
      " [ 86.0958325 ]]\n",
      "[[-222.08968737]\n",
      " [ -85.80090135]]\n",
      "[[221.32889368]\n",
      " [ 85.50698052]]\n",
      "[[-220.57070617]\n",
      " [ -85.21406656]]\n",
      "Training:   0%|                       | 396/1000000 [00:04<3:16:05, 84.96it/s, loss_val=86.6836, thetas=-0.1913 5.0649][[219.81511592]\n",
      " [ 84.922156  ]]\n",
      "[[-219.06211403]\n",
      " [ -84.63124541]]\n",
      "[[218.31169164]\n",
      " [ 84.34133138]]\n",
      "[[-217.5638399 ]\n",
      " [ -84.05241047]]\n",
      "Training:   0%|                       | 405/1000000 [00:04<3:16:38, 84.72it/s, loss_val=86.6836, thetas=-0.1913 5.0649][[216.81855002]\n",
      " [ 83.7644793 ]]\n",
      "[[-216.07581321]\n",
      " [ -83.47753447]]\n",
      "[[215.33562073]\n",
      " [ 83.1915726 ]]\n",
      "[[-214.59796386]\n",
      " [ -82.90659033]]\n",
      "[[213.86283393]\n",
      " [ 82.6225843 ]]\n",
      "[[-213.13022226]\n",
      " [ -82.33955116]]\n",
      "[[212.40012024]\n",
      " [ 82.05748758]]\n",
      "[[-211.67251927]\n",
      " [ -81.77639025]]\n",
      "[[210.94741078]\n",
      " [ 81.49625585]]\n",
      "Training:   0%|                       | 414/1000000 [00:04<3:14:48, 85.52it/s, loss_val=86.6836, thetas=-0.1913 5.0649][[-210.22478623]\n",
      " [ -81.21708108]]\n",
      "[[209.50463712]\n",
      " [ 80.93886265]]\n",
      "[[-208.78695496]\n",
      " [ -80.66159729]]\n",
      "[[208.0717313 ]\n",
      " [ 80.38528174]]\n",
      "[[-207.35895772]\n",
      " [ -80.10991274]]\n",
      "[[206.64862583]\n",
      " [ 79.83548705]]\n",
      "[[-205.94072726]\n",
      " [ -79.56200143]]\n",
      "[[205.23525368]\n",
      " [ 79.28945267]]\n",
      "[[-204.53219678]\n",
      " [ -79.01783756]]\n",
      "Training:   0%|                       | 423/1000000 [00:04<3:14:38, 85.59it/s, loss_val=86.6836, thetas=-0.1913 5.0649][[203.83154829]\n",
      " [ 78.74715289]]\n",
      "[[-203.13329994]\n",
      " [ -78.47739549]]\n",
      "[[202.43744353]\n",
      " [ 78.20856217]]\n",
      "[[-201.74397085]\n",
      " [ -77.94064977]]\n",
      "[[201.05287374]\n",
      " [ 77.67365514]]\n",
      "[[-200.36414406]\n",
      " [ -77.40757512]]\n",
      "[[199.67777371]\n",
      " [ 77.1424066 ]]\n",
      "[[-198.99375459]\n",
      " [ -76.87814643]]\n",
      "[[198.31207866]\n",
      " [ 76.61479153]]\n",
      "Training:   0%|                       | 432/1000000 [00:05<3:15:37, 85.16it/s, loss_val=86.6836, thetas=-0.1913 5.0649][[-197.6327379 ]\n",
      " [ -76.35233877]]\n",
      "[[196.95572429]\n",
      " [ 76.09078508]]\n",
      "[[-196.28102986]\n",
      " [ -75.83012737]]\n",
      "[[195.60864669]\n",
      " [ 75.57036257]]\n",
      "[[-194.93856683]\n",
      " [ -75.31148763]]\n",
      "[[194.27078242]\n",
      " [ 75.05349949]]\n",
      "[[-193.60528557]\n",
      " [ -74.79639512]]\n",
      "[[192.94206846]\n",
      " [ 74.54017149]]\n",
      "[[-192.28112328]\n",
      " [ -74.28482558]]\n",
      "Training:   0%|                       | 441/1000000 [00:05<3:15:45, 85.10it/s, loss_val=86.6836, thetas=-0.1913 5.0649][[191.62244224]\n",
      " [ 74.03035439]]\n",
      "[[-190.96601759]\n",
      " [ -73.77675492]]\n",
      "[[190.31184159]\n",
      " [ 73.52402419]]\n",
      "[[-189.65990655]\n",
      " [ -73.27215921]]\n",
      "[[189.01020479]\n",
      " [ 73.02115703]]\n",
      "[[-188.36272866]\n",
      " [ -72.77101468]]\n",
      "[[187.71747053]\n",
      " [ 72.52172922]]\n",
      "[[-187.07442281]\n",
      " [ -72.27329772]]\n",
      "[[186.43357792]\n",
      " [ 72.02571725]]\n",
      "Training:   0%|                       | 450/1000000 [00:05<3:15:18, 85.30it/s, loss_val=86.6836, thetas=-0.1913 5.0649][[-185.79492831]\n",
      " [ -71.7789849 ]]\n",
      "[[185.15846648]\n",
      " [ 71.53309775]]\n",
      "[[-184.52418492]\n",
      " [ -71.28805292]]\n",
      "[[183.89207616]\n",
      " [ 71.04384752]]\n",
      "[[-183.26213276]\n",
      " [ -70.80047867]]\n",
      "[[182.63434731]\n",
      " [ 70.55794352]]\n",
      "[[-182.00871241]\n",
      " [ -70.31623919]]\n",
      "[[181.38522069]\n",
      " [ 70.07536285]]\n",
      "[[-180.76386481]\n",
      " [ -69.83531165]]\n",
      "Training:   0%|                       | 459/1000000 [00:05<3:17:12, 84.48it/s, loss_val=86.6836, thetas=-0.1913 5.0649][[180.14463746]\n",
      " [ 69.59608279]]\n",
      "[[-179.52753135]\n",
      " [ -69.35767342]]\n",
      "[[178.9125392 ]\n",
      " [ 69.12008076]]\n",
      "[[-178.29965378]\n",
      " [ -68.88330199]]\n",
      "[[177.68886787]\n",
      " [ 68.64733434]]\n",
      "[[-177.08017427]\n",
      " [ -68.41217503]]\n",
      "[[176.47356583]\n",
      " [ 68.17782127]]\n",
      "[[-175.86903539]\n",
      " [ -67.94427033]]\n",
      "[[175.26657584]\n",
      " [ 67.71151944]]\n",
      "Training:   0%|                       | 468/1000000 [00:05<3:17:00, 84.56it/s, loss_val=86.6836, thetas=-0.1913 5.0649][[-174.66618008]\n",
      " [ -67.47956586]]\n",
      "[[174.06784105]\n",
      " [ 67.24840687]]\n",
      "[[-173.4715517 ]\n",
      " [ -67.01803974]]\n",
      "[[172.877305  ]\n",
      " [ 66.78846176]]\n",
      "[[-172.28509397]\n",
      " [ -66.55967023]]\n",
      "[[171.69491162]\n",
      " [ 66.33166244]]\n",
      "[[-171.10675101]\n",
      " [ -66.10443572]]\n",
      "[[170.52060521]\n",
      " [ 65.8779874 ]]\n",
      "[[-169.93646732]\n",
      " [ -65.6523148 ]]\n",
      "Training:   0%|                       | 477/1000000 [00:05<3:16:43, 84.68it/s, loss_val=86.6836, thetas=-0.1913 5.0649][[169.35433046]\n",
      " [ 65.42741526]]\n",
      "[[-168.77418778]\n",
      " [ -65.20328615]]\n",
      "[[168.19603245]\n",
      " [ 64.97992481]]\n",
      "[[-167.61985765]\n",
      " [ -64.75732863]]\n",
      "[[167.0456566 ]\n",
      " [ 64.53549497]]\n",
      "[[-166.47342255]\n",
      " [ -64.31442123]]\n",
      "[[165.90314875]\n",
      " [ 64.09410481]]\n",
      "[[-165.33482848]\n",
      " [ -63.8745431 ]]\n",
      "[[164.76845507]\n",
      " [ 63.65573353]]\n",
      "Training:   0%|                       | 486/1000000 [00:05<3:14:18, 85.73it/s, loss_val=86.6836, thetas=-0.1913 5.0649][[-164.20402183]\n",
      " [ -63.43767351]]\n",
      "[[163.64152212]\n",
      " [ 63.22036049]]\n",
      "[[-163.08094932]\n",
      " [ -63.00379189]]\n",
      "[[162.52229682]\n",
      " [ 62.78796518]]\n",
      "[[-161.96555806]\n",
      " [ -62.5728778 ]]\n",
      "[[161.41072646]\n",
      " [ 62.35852723]]\n",
      "[[-160.85779551]\n",
      " [ -62.14491095]]\n",
      "[[160.30675868]\n",
      " [ 61.93202643]]\n",
      "[[-159.75760949]\n",
      " [ -61.71987117]]\n",
      "Training:   0%|                       | 495/1000000 [00:05<3:13:10, 86.24it/s, loss_val=86.6836, thetas=-0.1913 5.0649][[159.21034148]\n",
      " [ 61.50844267]]\n",
      "[[-158.6649482 ]\n",
      " [ -61.29773845]]\n",
      "[[158.12142322]\n",
      " [ 61.08775601]]\n",
      "[[-157.57976015]\n",
      " [ -60.8784929 ]]\n",
      "[[157.03995261]\n",
      " [ 60.66994664]]\n",
      "[[-156.50199424]\n",
      " [ -60.46211478]]\n",
      "Training:   0%|                       | 495/1000000 [00:05<3:13:10, 86.24it/s, loss_val=57.5426, thetas=-0.3263 5.0127][[155.96587871]\n",
      " [ 60.25499487]]\n",
      "[[-155.43159971]\n",
      " [ -60.04858448]]\n",
      "[[154.89915094]\n",
      " [ 59.84288116]]\n",
      "Training:   0%|                       | 504/1000000 [00:05<3:17:22, 84.40it/s, loss_val=57.5426, thetas=-0.3263 5.0127][[-154.36852613]\n",
      " [ -59.63788251]]\n",
      "[[153.83971904]\n",
      " [ 59.4335861 ]]\n",
      "[[-153.31272344]\n",
      " [ -59.22998954]]\n",
      "[[152.78753312]\n",
      " [ 59.02709042]]\n",
      "[[-152.26414191]\n",
      " [ -58.82488635]]\n",
      "[[151.74254363]\n",
      " [ 58.62337496]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-151.22273214]\n",
      " [ -58.42255386]]\n",
      "[[150.70470133]\n",
      " [ 58.2224207 ]]\n",
      "[[-150.18844509]\n",
      " [ -58.02297312]]\n",
      "Training:   0%|                       | 513/1000000 [00:06<3:15:52, 85.05it/s, loss_val=57.5426, thetas=-0.3263 5.0127][[149.67395735]\n",
      " [ 57.82420877]]\n",
      "[[-149.16123204]\n",
      " [ -57.62612532]]\n",
      "[[148.65026313]\n",
      " [ 57.42872041]]\n",
      "[[-148.14104461]\n",
      " [ -57.23199175]]\n",
      "[[147.63357047]\n",
      " [ 57.035937  ]]\n",
      "[[-147.12783474]\n",
      " [ -56.84055385]]\n",
      "[[146.62383147]\n",
      " [ 56.64584002]]\n",
      "[[-146.12155472]\n",
      " [ -56.45179319]]\n",
      "[[145.62099858]\n",
      " [ 56.2584111 ]]\n",
      "Training:   0%|                       | 522/1000000 [00:06<3:16:29, 84.78it/s, loss_val=57.5426, thetas=-0.3263 5.0127][[-145.12215715]\n",
      " [ -56.06569146]]\n",
      "[[144.62502456]\n",
      " [ 55.87363201]]\n",
      "[[-144.12959495]\n",
      " [ -55.68223047]]\n",
      "[[143.63586249]\n",
      " [ 55.49148461]]\n",
      "[[-143.14382137]\n",
      " [ -55.30139216]]\n",
      "[[142.65346579]\n",
      " [ 55.1119509 ]]\n",
      "[[-142.16478999]\n",
      " [ -54.92315859]]\n",
      "[[141.67778819]\n",
      " [ 54.73501301]]\n",
      "[[-141.19245468]\n",
      " [ -54.54751195]]\n",
      "Training:   0%|                       | 531/1000000 [00:06<3:15:15, 85.31it/s, loss_val=57.5426, thetas=-0.3263 5.0127][[140.70878374]\n",
      " [ 54.36065319]]\n",
      "[[-140.22676966]\n",
      " [ -54.17443454]]\n",
      "[[139.74640678]\n",
      " [ 53.9888538 ]]\n",
      "[[-139.26768944]\n",
      " [ -53.80390879]]\n",
      "[[138.79061199]\n",
      " [ 53.61959733]]\n",
      "[[-138.31516884]\n",
      " [ -53.43591725]]\n",
      "[[137.84135436]\n",
      " [ 53.25286639]]\n",
      "[[-137.36916299]\n",
      " [ -53.07044259]]\n",
      "[[136.89858917]\n",
      " [ 52.8886437 ]]\n",
      "Training:   0%|                       | 540/1000000 [00:06<3:15:29, 85.21it/s, loss_val=57.5426, thetas=-0.3263 5.0127][[-136.42962735]\n",
      " [ -52.70746758]]\n",
      "[[135.96227202]\n",
      " [ 52.52691211]]\n",
      "[[-135.49651766]\n",
      " [ -52.34697515]]\n",
      "[[135.0323588 ]\n",
      " [ 52.16765458]]\n",
      "[[-134.56978997]\n",
      " [ -51.9889483 ]]\n",
      "[[134.10880572]\n",
      " [ 51.81085419]]\n",
      "[[-133.64940063]\n",
      " [ -51.63337017]]\n",
      "[[133.19156928]\n",
      " [ 51.45649414]]\n",
      "[[-132.73530628]\n",
      " [ -51.28022402]]\n",
      "Training:   0%|                       | 549/1000000 [00:06<3:15:39, 85.13it/s, loss_val=57.5426, thetas=-0.3263 5.0127][[132.28060627]\n",
      " [ 51.10455773]]\n",
      "[[-131.82746388]\n",
      " [ -50.92949321]]\n",
      "[[131.37587379]\n",
      " [ 50.75502839]]\n",
      "[[-130.92583066]\n",
      " [ -50.58116121]]\n",
      "[[130.47732922]\n",
      " [ 50.40788965]]\n",
      "[[-130.03036416]\n",
      " [ -50.23521164]]\n",
      "[[129.58493024]\n",
      " [ 50.06312516]]\n",
      "[[-129.1410222 ]\n",
      " [ -49.89162818]]\n",
      "[[128.69863481]\n",
      " [ 49.72071869]]\n",
      "Training:   0%|                       | 558/1000000 [00:06<3:16:02, 84.97it/s, loss_val=57.5426, thetas=-0.3263 5.0127][[-128.25776288]\n",
      " [ -49.55039467]]\n",
      "[[127.8184012 ]\n",
      " [ 49.38065411]]\n",
      "[[-127.38054461]\n",
      " [ -49.21149501]]\n",
      "[[126.94418795]\n",
      " [ 49.04291539]]\n",
      "[[-126.50932607]\n",
      " [ -48.87491326]]\n",
      "[[126.07595387]\n",
      " [ 48.70748664]]\n",
      "[[-125.64406623]\n",
      " [ -48.54063356]]\n",
      "[[125.21365807]\n",
      " [ 48.37435205]]\n",
      "[[-124.78472432]\n",
      " [ -48.20864016]]\n",
      "Training:   0%|                       | 567/1000000 [00:06<3:16:36, 84.72it/s, loss_val=57.5426, thetas=-0.3263 5.0127][[124.35725994]\n",
      " [ 48.04349594]]\n",
      "[[-123.93125988]\n",
      " [ -47.87891743]]\n",
      "[[123.50671914]\n",
      " [ 47.71490271]]\n",
      "[[-123.08363271]\n",
      " [ -47.55144984]]\n",
      "[[122.66199561]\n",
      " [ 47.38855689]]\n",
      "[[-122.24180288]\n",
      " [ -47.22622195]]\n",
      "[[121.82304956]\n",
      " [ 47.06444312]]\n",
      "[[-121.40573073]\n",
      " [ -46.90321847]]\n",
      "[[120.98984148]\n",
      " [ 46.74254611]]\n",
      "Training:   0%|                       | 576/1000000 [00:06<3:14:13, 85.76it/s, loss_val=57.5426, thetas=-0.3263 5.0127][[-120.5753769 ]\n",
      " [ -46.58242416]]\n",
      "[[120.16233212]\n",
      " [ 46.42285073]]\n",
      "[[-119.75070227]\n",
      " [ -46.26382393]]\n",
      "[[119.34048251]\n",
      " [ 46.10534189]]\n",
      "[[-118.931668  ]\n",
      " [ -45.94740276]]\n",
      "[[118.52425393]\n",
      " [ 45.79000466]]\n",
      "[[-118.1182355 ]\n",
      " [ -45.63314575]]\n",
      "[[117.71360794]\n",
      " [ 45.47682417]]\n",
      "[[-117.31036648]\n",
      " [ -45.32103809]]\n",
      "Training:   0%|                       | 585/1000000 [00:06<3:16:59, 84.56it/s, loss_val=57.5426, thetas=-0.3263 5.0127][[116.90850636]\n",
      " [ 45.16578568]]\n",
      "[[-116.50802287]\n",
      " [ -45.0110651 ]]\n",
      "[[116.10891127]\n",
      " [ 44.85687454]]\n",
      "[[-115.71116688]\n",
      " [ -44.70321217]]\n",
      "[[115.31478501]\n",
      " [ 44.55007619]]\n",
      "[[-114.91976099]\n",
      " [ -44.39746479]]\n",
      "[[114.52609017]\n",
      " [ 44.24537619]]\n",
      "[[-114.13376791]\n",
      " [ -44.09380857]]\n",
      "[[113.7427896 ]\n",
      " [ 43.94276018]]\n",
      "Training:   0%|                       | 594/1000000 [00:06<3:16:09, 84.92it/s, loss_val=57.5426, thetas=-0.3263 5.0127][[-113.35315063]\n",
      " [ -43.79222921]]\n",
      "[[112.96484641]\n",
      " [ 43.64221391]]\n",
      "[[-112.57787238]\n",
      " [ -43.4927125 ]]\n",
      "[[112.19222396]\n",
      " [ 43.34372323]]\n",
      "[[-111.80789663]\n",
      " [ -43.19524433]]\n",
      "[[111.42488586]\n",
      " [ 43.04727407]]\n",
      "[[-111.04318713]\n",
      " [ -42.89981069]]\n",
      "Training:   0%|                       | 594/1000000 [00:07<3:16:09, 84.92it/s, loss_val=42.8720, thetas=-0.4220 4.9757][[110.66279596]\n",
      " [ 42.75285247]]\n",
      "[[-110.28370786]\n",
      " [ -42.60639767]]\n",
      "Training:   0%|                       | 603/1000000 [00:07<3:17:47, 84.21it/s, loss_val=42.8720, thetas=-0.4220 4.9757][[109.90591837]\n",
      " [ 42.46044457]]\n",
      "[[-109.52942305]\n",
      " [ -42.31499145]]\n",
      "[[109.15421745]\n",
      " [ 42.17003659]]\n",
      "[[-108.78029716]\n",
      " [ -42.0255783 ]]\n",
      "[[108.40765777]\n",
      " [ 41.88161486]]\n",
      "[[-108.03629491]\n",
      " [ -41.73814458]]\n",
      "[[107.66620419]\n",
      " [ 41.59516578]]\n",
      "[[-107.29738126]\n",
      " [ -41.45267677]]\n",
      "[[106.92982177]\n",
      " [ 41.31067587]]\n",
      "Training:   0%|                       | 612/1000000 [00:07<3:16:16, 84.86it/s, loss_val=42.8720, thetas=-0.4220 4.9757][[-106.56352141]\n",
      " [ -41.16916141]]\n",
      "[[106.19847584]\n",
      " [ 41.02813173]]\n",
      "[[-105.83468078]\n",
      " [ -40.88758516]]\n",
      "[[105.47213195]\n",
      " [ 40.74752005]]\n",
      "[[-105.11082506]\n",
      " [ -40.60793474]]\n",
      "[[104.75075588]\n",
      " [ 40.46882761]]\n",
      "[[-104.39192015]\n",
      " [ -40.330197  ]]\n",
      "[[104.03431366]\n",
      " [ 40.19204128]]\n",
      "[[-103.67793218]\n",
      " [ -40.05435884]]\n",
      "Training:   0%|                       | 621/1000000 [00:07<3:14:32, 85.62it/s, loss_val=42.8720, thetas=-0.4220 4.9757][[103.32277154]\n",
      " [ 39.91714804]]\n",
      "[[-102.96882753]\n",
      " [ -39.78040727]]\n",
      "[[102.616096  ]\n",
      " [ 39.64413492]]\n",
      "[[-102.2645728 ]\n",
      " [ -39.50832939]]\n",
      "[[101.91425378]\n",
      " [ 39.37298908]]\n",
      "[[-101.56513481]\n",
      " [ -39.23811239]]\n",
      "[[101.2172118 ]\n",
      " [ 39.10369773]]\n",
      "[[-100.87048063]\n",
      " [ -38.96974353]]\n",
      "[[100.52493723]\n",
      " [ 38.8362482 ]]\n",
      "Training:   0%|                       | 630/1000000 [00:07<3:13:19, 86.16it/s, loss_val=42.8720, thetas=-0.4220 4.9757][[-100.18057753]\n",
      " [ -38.70321018]]\n",
      "[[99.83739747]\n",
      " [38.5706279 ]]\n",
      "[[-99.49539301]\n",
      " [-38.43849979]]\n",
      "[[99.15456014]\n",
      " [38.3068243 ]]\n",
      "[[-98.81489482]\n",
      " [-38.17559988]]\n",
      "[[98.47639306]\n",
      " [38.04482498]]\n",
      "[[-98.13905088]\n",
      " [-37.91449807]]\n",
      "[[97.80286431]\n",
      " [37.78461761]]\n",
      "[[-97.46782938]\n",
      " [-37.65518207]]\n",
      "Training:   0%|                       | 639/1000000 [00:07<3:11:55, 86.79it/s, loss_val=42.8720, thetas=-0.4220 4.9757][[97.13394216]\n",
      " [37.52618993]]\n",
      "[[-96.8011987 ]\n",
      " [-37.39763966]]\n",
      "[[96.46959509]\n",
      " [37.26952975]]\n",
      "[[-96.13912743]\n",
      " [-37.14185871]]\n",
      "[[95.80979182]\n",
      " [37.01462501]]\n",
      "[[-95.48158439]\n",
      " [-36.88782717]]\n",
      "[[95.15450127]\n",
      " [36.76146368]]\n",
      "[[-94.82853862]\n",
      " [-36.63553307]]\n",
      "[[94.50369258]\n",
      " [36.51003385]]\n",
      "Training:   0%|                       | 648/1000000 [00:07<3:12:36, 86.48it/s, loss_val=42.8720, thetas=-0.4220 4.9757][[-94.17995934]\n",
      " [-36.38496455]]\n",
      "[[93.85733509]\n",
      " [36.26032368]]\n",
      "[[-93.53581603]\n",
      " [-36.13610978]]\n",
      "[[93.21539836]\n",
      " [36.01232139]]\n",
      "[[-92.89607832]\n",
      " [-35.88895705]]\n",
      "[[92.57785215]\n",
      " [35.76601532]]\n",
      "[[-92.2607161 ]\n",
      " [-35.64349473]]\n",
      "[[91.94466644]\n",
      " [35.52139385]]\n",
      "[[-91.62969944]\n",
      " [-35.39971124]]\n",
      "Training:   0%|                       | 657/1000000 [00:07<3:12:31, 86.51it/s, loss_val=42.8720, thetas=-0.4220 4.9757][[91.3158114 ]\n",
      " [35.27844547]]\n",
      "[[-91.00299861]\n",
      " [-35.15759511]]\n",
      "[[90.6912574 ]\n",
      " [35.03715874]]\n",
      "[[-90.3805841 ]\n",
      " [-34.91713493]]\n",
      "[[90.07097504]\n",
      " [34.79752228]]\n",
      "[[-89.76242659]\n",
      " [-34.67831938]]\n",
      "[[89.4549351 ]\n",
      " [34.55952482]]\n",
      "[[-89.14849696]\n",
      " [-34.4411372 ]]\n",
      "[[88.84310856]\n",
      " [34.32315514]]\n",
      "[[-88.53876631]\n",
      " [-34.20557723]]\n",
      "Training:   0%|                       | 667/1000000 [00:07<3:10:11, 87.57it/s, loss_val=42.8720, thetas=-0.4220 4.9757][[88.23546661]\n",
      " [34.0884021 ]]\n",
      "[[-87.9332059 ]\n",
      " [-33.97162837]]\n",
      "[[87.63198062]\n",
      " [33.85525466]]\n",
      "[[-87.33178722]\n",
      " [-33.73927961]]\n",
      "[[87.03262216]\n",
      " [33.62370183]]\n",
      "[[-86.73448194]\n",
      " [-33.50851999]]\n",
      "[[86.43736302]\n",
      " [33.39373271]]\n",
      "[[-86.14126192]\n",
      " [-33.27933865]]\n",
      "[[85.84617515]\n",
      " [33.16533646]]\n",
      "Training:   0%|                       | 676/1000000 [00:07<3:12:30, 86.52it/s, loss_val=42.8720, thetas=-0.4220 4.9757][[-85.55209923]\n",
      " [-33.05172479]]\n",
      "[[85.2590307 ]\n",
      " [32.93850232]]\n",
      "[[-84.96696612]\n",
      " [-32.8256677 ]]\n",
      "[[84.67590203]\n",
      " [32.71321961]]\n",
      "[[-84.38583501]\n",
      " [-32.60115673]]\n",
      "[[84.09676166]\n",
      " [32.48947773]]\n",
      "[[-83.80867856]\n",
      " [-32.37818129]]\n",
      "[[83.52158232]\n",
      " [32.26726612]]\n",
      "[[-83.23546956]\n",
      " [-32.1567309 ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:   0%|                       | 685/1000000 [00:08<3:12:27, 86.54it/s, loss_val=42.8720, thetas=-0.4220 4.9757][[82.95033691]\n",
      " [32.04657433]]\n",
      "[[-82.66618102]\n",
      " [-31.93679512]]\n",
      "[[82.38299854]\n",
      " [31.82739196]]\n",
      "[[-82.10078613]\n",
      " [-31.71836358]]\n",
      "[[81.81954047]\n",
      " [31.60970869]]\n",
      "[[-81.53925825]\n",
      " [-31.50142601]]\n",
      "[[81.25993617]\n",
      " [31.39351426]]\n",
      "[[-80.98157094]\n",
      " [-31.28597217]]\n",
      "[[80.70415928]\n",
      " [31.17879849]]\n",
      "Training:   0%|                       | 694/1000000 [00:08<3:13:22, 86.13it/s, loss_val=42.8720, thetas=-0.4220 4.9757][[-80.42769793]\n",
      " [-31.07199194]]\n",
      "[[80.15218362]\n",
      " [30.96555127]]\n",
      "[[-79.87761313]\n",
      " [-30.85947522]]\n",
      "[[79.6039832 ]\n",
      " [30.75376255]]\n",
      "[[-79.33129063]\n",
      " [-30.64841201]]\n",
      "[[79.05953219]\n",
      " [30.54342236]]\n",
      "[[-78.7887047 ]\n",
      " [-30.43879236]]\n",
      "Training:   0%|                       | 694/1000000 [00:08<3:13:22, 86.13it/s, loss_val=35.4863, thetas=-0.4900 4.9495][[78.51880495]\n",
      " [30.33452079]]\n",
      "[[-78.24982978]\n",
      " [-30.23060641]]\n",
      "Training:   0%|                       | 703/1000000 [00:08<3:16:57, 84.56it/s, loss_val=35.4863, thetas=-0.4900 4.9495][[77.98177602]\n",
      " [30.127048  ]]\n",
      "[[-77.7146405 ]\n",
      " [-30.02384434]]\n",
      "[[77.44842009]\n",
      " [29.92099422]]\n",
      "[[-77.18311164]\n",
      " [-29.81849642]]\n",
      "[[76.91871204]\n",
      " [29.71634974]]\n",
      "[[-76.65521817]\n",
      " [-29.61455298]]\n",
      "[[76.39262693]\n",
      " [29.51310493]]\n",
      "[[-76.13093522]\n",
      " [-29.4120044 ]]\n",
      "[[75.87013998]\n",
      " [29.31125021]]\n",
      "Training:   0%|                       | 712/1000000 [00:08<3:17:47, 84.21it/s, loss_val=35.4863, thetas=-0.4900 4.9495][[-75.61023811]\n",
      " [-29.21084116]]\n",
      "[[75.35122657]\n",
      " [29.11077607]]\n",
      "[[-75.0931023 ]\n",
      " [-29.01105377]]\n",
      "[[74.83586227]\n",
      " [28.91167308]]\n",
      "[[-74.57950344]\n",
      " [-28.81263283]]\n",
      "[[74.32402279]\n",
      " [28.71393185]]\n",
      "[[-74.06941733]\n",
      " [-28.61556898]]\n",
      "[[73.81568405]\n",
      " [28.51754307]]\n",
      "[[-73.56281996]\n",
      " [-28.41985296]]\n",
      "Training:   0%|                       | 721/1000000 [00:08<3:17:48, 84.19it/s, loss_val=35.4863, thetas=-0.4900 4.9495][[73.31082208]\n",
      " [28.32249749]]\n",
      "[[-73.05968745]\n",
      " [-28.22547553]]\n",
      "[[72.80941311]\n",
      " [28.12878592]]\n",
      "[[-72.55999612]\n",
      " [-28.03242754]]\n",
      "[[72.31143353]\n",
      " [27.93639925]]\n",
      "[[-72.06372242]\n",
      " [-27.84069991]]\n",
      "[[71.81685987]\n",
      " [27.7453284 ]]\n",
      "[[-71.57084298]\n",
      " [-27.65028359]]\n",
      "[[71.32566885]\n",
      " [27.55556437]]\n",
      "Training:   0%|                       | 730/1000000 [00:08<3:14:51, 85.47it/s, loss_val=35.4863, thetas=-0.4900 4.9495][[-71.0813346 ]\n",
      " [-27.46116963]]\n",
      "[[70.83783733]\n",
      " [27.36709824]]\n",
      "[[-70.5951742 ]\n",
      " [-27.27334911]]\n",
      "[[70.35334233]\n",
      " [27.17992112]]\n",
      "[[-70.11233889]\n",
      " [-27.08681319]]\n",
      "[[69.87216103]\n",
      " [26.9940242 ]]\n",
      "[[-69.63280593]\n",
      " [-26.90155308]]\n",
      "[[69.39427077]\n",
      " [26.80939872]]\n",
      "[[-69.15655273]\n",
      " [-26.71756005]]\n",
      "Training:   0%|                       | 739/1000000 [00:08<3:14:39, 85.56it/s, loss_val=35.4863, thetas=-0.4900 4.9495][[68.91964903]\n",
      " [26.62603598]]\n",
      "[[-68.68355687]\n",
      " [-26.53482544]]\n",
      "[[68.44827347]\n",
      " [26.44392736]]\n",
      "[[-68.21379606]\n",
      " [-26.35334065]]\n",
      "[[67.98012188]\n",
      " [26.26306426]]\n",
      "[[-67.74724817]\n",
      " [-26.17309712]]\n",
      "[[67.5151722 ]\n",
      " [26.08343818]]\n",
      "[[-67.28389124]\n",
      " [-25.99408637]]\n",
      "[[67.05340255]\n",
      " [25.90504064]]\n",
      "Training:   0%|                       | 748/1000000 [00:08<3:13:57, 85.86it/s, loss_val=35.4863, thetas=-0.4900 4.9495][[-66.82370343]\n",
      " [-25.81629996]]\n",
      "[[66.59479117]\n",
      " [25.72786326]]\n",
      "[[-66.36666308]\n",
      " [-25.63972951]]\n",
      "[[66.13931646]\n",
      " [25.55189768]]\n",
      "[[-65.91274865]\n",
      " [-25.46436672]]\n",
      "[[65.68695697]\n",
      " [25.37713561]]\n",
      "[[-65.46193876]\n",
      " [-25.29020333]]\n",
      "[[65.23769139]\n",
      " [25.20356883]]\n",
      "[[-65.01421219]\n",
      " [-25.11723112]]\n",
      "[[64.79149855]\n",
      " [25.03118916]]\n",
      "Training:   0%|                       | 758/1000000 [00:08<3:10:41, 87.33it/s, loss_val=35.4863, thetas=-0.4900 4.9495][[-64.56954784]\n",
      " [-24.94544195]]\n",
      "[[64.34835745]\n",
      " [24.85998848]]\n",
      "[[-64.12792477]\n",
      " [-24.77482774]]\n",
      "[[63.90824721]\n",
      " [24.68995873]]\n",
      "[[-63.68932218]\n",
      " [-24.60538044]]\n",
      "[[63.47114711]\n",
      " [24.52109189]]\n",
      "[[-63.25371941]\n",
      " [-24.43709208]]\n",
      "[[63.03703654]\n",
      " [24.35338001]]\n",
      "[[-62.82109594]\n",
      " [-24.26995472]]\n",
      "Training:   0%|                       | 767/1000000 [00:08<3:11:10, 87.11it/s, loss_val=35.4863, thetas=-0.4900 4.9495][[62.60589507]\n",
      " [24.1868152 ]]\n",
      "[[-62.3914314]\n",
      " [-24.1039605]]\n",
      "[[62.1777024 ]\n",
      " [24.02138961]]\n",
      "[[-61.96470555]\n",
      " [-23.93910159]]\n",
      "[[61.75243834]\n",
      " [23.85709545]]\n",
      "[[-61.54089828]\n",
      " [-23.77537023]]\n",
      "[[61.33008288]\n",
      " [23.69392498]]\n",
      "[[-61.11998964]\n",
      " [-23.61275872]]\n",
      "[[60.91061611]\n",
      " [23.53187051]]\n",
      "Training:   0%|                       | 776/1000000 [00:09<3:12:04, 86.70it/s, loss_val=35.4863, thetas=-0.4900 4.9495][[-60.70195981]\n",
      " [-23.45125939]]\n",
      "[[60.49401828]\n",
      " [23.37092441]]\n",
      "[[-60.28678909]\n",
      " [-23.29086463]]\n",
      "[[60.08026978]\n",
      " [23.2110791 ]]\n",
      "[[-59.87445792]\n",
      " [-23.13156688]]\n",
      "[[59.6693511 ]\n",
      " [23.05232705]]\n",
      "[[-59.4649469 ]\n",
      " [-22.97335866]]\n",
      "[[59.2612429 ]\n",
      " [22.89466078]]\n",
      "[[-59.05823672]\n",
      " [-22.8162325 ]]\n",
      "Training:   0%|                       | 785/1000000 [00:09<3:14:55, 85.44it/s, loss_val=35.4863, thetas=-0.4900 4.9495][[58.85592595]\n",
      " [22.73807288]]\n",
      "[[-58.65430823]\n",
      " [-22.660181  ]]\n",
      "[[58.45338117]\n",
      " [22.58255595]]\n",
      "[[-58.25314241]\n",
      " [-22.50519682]]\n",
      "[[58.05358959]\n",
      " [22.42810268]]\n",
      "[[-57.85472036]\n",
      " [-22.35127265]]\n",
      "[[57.65653238]\n",
      " [22.2747058 ]]\n",
      "[[-57.45902332]\n",
      " [-22.19840124]]\n",
      "[[57.26219084]\n",
      " [22.12235807]]\n",
      "Training:   0%|                       | 794/1000000 [00:09<3:17:28, 84.33it/s, loss_val=35.4863, thetas=-0.4900 4.9495][[-57.06603264]\n",
      " [-22.04657539]]\n",
      "[[56.8705464 ]\n",
      " [21.97105232]]\n",
      "[[-56.67572982]\n",
      " [-21.89578796]]\n",
      "[[56.48158061]\n",
      " [21.82078143]]\n",
      "[[-56.28809648]\n",
      " [-21.74603184]]\n",
      "[[56.09527515]\n",
      " [21.67153831]]\n",
      "[[-55.90311435]\n",
      " [-21.59729997]]\n",
      "Training:   0%|                       | 794/1000000 [00:09<3:17:28, 84.33it/s, loss_val=31.7681, thetas=-0.5382 4.9309][[55.71161182]\n",
      " [21.52331595]]\n",
      "[[-55.5207653 ]\n",
      " [-21.44958536]]\n",
      "Training:   0%|                       | 803/1000000 [00:09<3:17:45, 84.21it/s, loss_val=31.7681, thetas=-0.5382 4.9309][[55.33057255]\n",
      " [21.37610734]]\n",
      "[[-55.14103133]\n",
      " [-21.30288104]]\n",
      "[[54.95213941]\n",
      " [21.22990558]]\n",
      "[[-54.76389455]\n",
      " [-21.1571801 ]]\n",
      "[[54.57629455]\n",
      " [21.08470375]]\n",
      "[[-54.38933719]\n",
      " [-21.01247568]]\n",
      "[[54.20302028]\n",
      " [20.94049504]]\n",
      "[[-54.01734162]\n",
      " [-20.86876097]]\n",
      "[[53.83229902]\n",
      " [20.79727264]]\n",
      "Training:   0%|                       | 812/1000000 [00:09<3:15:34, 85.15it/s, loss_val=31.7681, thetas=-0.5382 4.9309][[-53.64789031]\n",
      " [-20.72602919]]\n",
      "[[53.4641133]\n",
      " [20.6550298]]\n",
      "[[-53.28096585]\n",
      " [-20.58427363]]\n",
      "[[53.09844579]\n",
      " [20.51375984]]\n",
      "[[-52.91655098]\n",
      " [-20.4434876 ]]\n",
      "[[52.73527926]\n",
      " [20.37345609]]\n",
      "[[-52.55462852]\n",
      " [-20.30366448]]\n",
      "[[52.37459661]\n",
      " [20.23411195]]\n",
      "[[-52.19518142]\n",
      " [-20.16479768]]\n",
      "Training:   0%|                       | 821/1000000 [00:09<3:16:10, 84.89it/s, loss_val=31.7681, thetas=-0.5382 4.9309][[52.01638084]\n",
      " [20.09572085]]\n",
      "[[-51.83819276]\n",
      " [-20.02688065]]\n",
      "[[51.66061509]\n",
      " [19.95827628]]\n",
      "[[-51.48364573]\n",
      " [-19.88990691]]\n",
      "[[51.3072826 ]\n",
      " [19.82177176]]\n",
      "[[-51.13152361]\n",
      " [-19.75387   ]]\n",
      "[[50.95636672]\n",
      " [19.68620086]]\n",
      "[[-50.78180984]\n",
      " [-19.61876352]]\n",
      "[[50.60785092]\n",
      " [19.55155719]]\n",
      "Training:   0%|                       | 830/1000000 [00:09<3:15:01, 85.39it/s, loss_val=31.7681, thetas=-0.5382 4.9309][[-50.43448793]\n",
      " [-19.48458109]]\n",
      "[[50.26171881]\n",
      " [19.41783443]]\n",
      "[[-50.08954152]\n",
      " [-19.35131641]]\n",
      "[[49.91795405]\n",
      " [19.28502625]]\n",
      "[[-49.74695438]\n",
      " [-19.21896318]]\n",
      "[[49.57654048]\n",
      " [19.15312642]]\n",
      "[[-49.40671036]\n",
      " [-19.08751519]]\n",
      "[[49.237462  ]\n",
      " [19.02212872]]\n",
      "[[-49.06879343]\n",
      " [-18.95696623]]\n",
      "Training:   0%|                       | 839/1000000 [00:09<3:14:00, 85.83it/s, loss_val=31.7681, thetas=-0.5382 4.9309][[48.90070265]\n",
      " [18.89202697]]\n",
      "[[-48.73318769]\n",
      " [-18.82731017]]\n",
      "[[48.56624656]\n",
      " [18.76281506]]\n",
      "[[-48.39987731]\n",
      " [-18.69854088]]\n",
      "[[48.23407798]\n",
      " [18.63448689]]\n",
      "[[-48.06884662]\n",
      " [-18.57065231]]\n",
      "[[47.90418127]\n",
      " [18.50703641]]\n",
      "[[-47.74008   ]\n",
      " [-18.44363844]]\n",
      "[[47.57654089]\n",
      " [18.38045764]]\n",
      "Training:   0%|                       | 848/1000000 [00:09<3:15:09, 85.33it/s, loss_val=31.7681, thetas=-0.5382 4.9309][[-47.41356199]\n",
      " [-18.31749327]]\n",
      "[[47.25114139]\n",
      " [18.2547446 ]]\n",
      "[[-47.08927719]\n",
      " [-18.19221088]]\n",
      "[[46.92796747]\n",
      " [18.12989138]]\n",
      "[[-46.76721034]\n",
      " [-18.06778535]]\n",
      "[[46.60700389]\n",
      " [18.00589208]]\n",
      "[[-46.44734626]\n",
      " [-17.94421083]]\n",
      "[[46.28823555]\n",
      " [17.88274088]]\n",
      "[[-46.12966989]\n",
      " [-17.8214815 ]]\n",
      "Training:   0%|                       | 857/1000000 [00:10<3:15:24, 85.22it/s, loss_val=31.7681, thetas=-0.5382 4.9309][[45.97164741]\n",
      " [17.76043197]]\n",
      "[[-45.81416626]\n",
      " [-17.69959158]]\n",
      "[[45.65722458]\n",
      " [17.6389596 ]]\n",
      "[[-45.50082052]\n",
      " [-17.57853532]]\n",
      "[[45.34495224]\n",
      " [17.51831803]]\n",
      "[[-45.18961791]\n",
      " [-17.45830702]]\n",
      "[[45.03481569]\n",
      " [17.39850159]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-44.88054376]\n",
      " [-17.33890102]]\n",
      "[[44.72680031]\n",
      " [17.27950463]]\n",
      "Training:   0%|                       | 866/1000000 [00:10<3:16:08, 84.90it/s, loss_val=31.7681, thetas=-0.5382 4.9309][[-44.57358353]\n",
      " [-17.22031171]]\n",
      "[[44.42089161]\n",
      " [17.16132155]]\n",
      "[[-44.26872275]\n",
      " [-17.10253348]]\n",
      "[[44.11707516]\n",
      " [17.04394679]]\n",
      "[[-43.96594706]\n",
      " [-16.98556079]]\n",
      "[[43.81533667]\n",
      " [16.92737481]]\n",
      "[[-43.66524221]\n",
      " [-16.86938814]]\n",
      "[[43.51566191]\n",
      " [16.81160012]]\n",
      "[[-43.36659402]\n",
      " [-16.75401006]]\n",
      "Training:   0%|                       | 875/1000000 [00:10<3:18:19, 83.96it/s, loss_val=31.7681, thetas=-0.5382 4.9309][[43.21803678]\n",
      " [16.69661727]]\n",
      "[[-43.06998844]\n",
      " [-16.6394211 ]]\n",
      "[[42.92244725]\n",
      " [16.58242085]]\n",
      "[[-42.77541149]\n",
      " [-16.52561587]]\n",
      "[[42.62887941]\n",
      " [16.46900547]]\n",
      "[[-42.48284929]\n",
      " [-16.41258901]]\n",
      "[[42.33731942]\n",
      " [16.3563658 ]]\n",
      "[[-42.19228808]\n",
      " [-16.30033519]]\n",
      "[[42.04775356]\n",
      " [16.24449653]]\n",
      "Training:   0%|                       | 884/1000000 [00:10<3:16:31, 84.73it/s, loss_val=31.7681, thetas=-0.5382 4.9309][[-41.90371416]\n",
      " [-16.18884914]]\n",
      "[[41.76016818]\n",
      " [16.13339238]]\n",
      "[[-41.61711393]\n",
      " [-16.0781256 ]]\n",
      "[[41.47454973]\n",
      " [16.02304813]]\n",
      "[[-41.33247391]\n",
      " [-15.96815934]]\n",
      "[[41.19088478]\n",
      " [15.91345858]]\n",
      "[[-41.04978068]\n",
      " [-15.8589452 ]]\n",
      "[[40.90915995]\n",
      " [15.80461857]]\n",
      "[[-40.76902093]\n",
      " [-15.75047804]]\n",
      "Training:   0%|                       | 893/1000000 [00:10<3:15:14, 85.29it/s, loss_val=31.7681, thetas=-0.5382 4.9309][[40.62936197]\n",
      " [15.69652297]]\n",
      "[[-40.49018143]\n",
      " [-15.64275273]]\n",
      "[[40.35147767]\n",
      " [15.58916668]]\n",
      "[[-40.21324906]\n",
      " [-15.53576421]]\n",
      "[[40.07549396]\n",
      " [15.48254466]]\n",
      "[[-39.93821076]\n",
      " [-15.42950743]]\n",
      "[[39.80139784]\n",
      " [15.37665188]]\n",
      "[[-39.66505359]\n",
      " [-15.3239774 ]]\n",
      "Training:   0%|                       | 893/1000000 [00:10<3:15:14, 85.29it/s, loss_val=29.8962, thetas=-0.5724 4.9176][[39.5291764 ]\n",
      " [15.27148336]]\n",
      "Training:   0%|                       | 902/1000000 [00:10<3:15:28, 85.19it/s, loss_val=29.8962, thetas=-0.5724 4.9176][[-39.39376467]\n",
      " [-15.21916914]]\n",
      "[[39.25881681]\n",
      " [15.16703413]]\n",
      "[[-39.12433123]\n",
      " [-15.11507772]]\n",
      "[[38.99030635]\n",
      " [15.06329928]]\n",
      "[[-38.85674058]\n",
      " [-15.01169822]]\n",
      "[[38.72363236]\n",
      " [14.96027393]]\n",
      "[[-38.59098012]\n",
      " [-14.9090258 ]]\n",
      "[[38.45878229]\n",
      " [14.85795322]]\n",
      "[[-38.32703732]\n",
      " [-14.8070556 ]]\n",
      "Training:   0%|                       | 911/1000000 [00:10<3:14:31, 85.60it/s, loss_val=29.8962, thetas=-0.5724 4.9176][[38.19574366]\n",
      " [14.75633233]]\n",
      "[[-38.06489976]\n",
      " [-14.70578282]]\n",
      "[[37.93450408]\n",
      " [14.65540647]]\n",
      "[[-37.80455508]\n",
      " [-14.6052027 ]]\n",
      "[[37.67505124]\n",
      " [14.5551709 ]]\n",
      "[[-37.54599104]\n",
      " [-14.50531049]]\n",
      "[[37.41737294]\n",
      " [14.45562089]]\n",
      "[[-37.28919543]\n",
      " [-14.4061015 ]]\n",
      "[[37.16145702]\n",
      " [14.35675175]]\n",
      "Training:   0%|                       | 920/1000000 [00:10<3:13:17, 86.14it/s, loss_val=29.8962, thetas=-0.5724 4.9176][[-37.03415619]\n",
      " [-14.30757105]]\n",
      "[[36.90729144]\n",
      " [14.25855882]]\n",
      "[[-36.78086128]\n",
      " [-14.2097145 ]]\n",
      "[[36.65486422]\n",
      " [14.16103749]]\n",
      "[[-36.52929878]\n",
      " [-14.11252723]]\n",
      "[[36.40416348]\n",
      " [14.06418315]]\n",
      "[[-36.27945684]\n",
      " [-14.01600468]]\n",
      "[[36.1551774 ]\n",
      " [13.96799125]]\n",
      "[[-36.03132369]\n",
      " [-13.92014229]]\n",
      "Training:   0%|                       | 929/1000000 [00:10<3:11:53, 86.78it/s, loss_val=29.8962, thetas=-0.5724 4.9176][[35.90789426]\n",
      " [13.87245725]]\n",
      "[[-35.78488765]\n",
      " [-13.82493555]]\n",
      "[[35.66230241]\n",
      " [13.77757665]]\n",
      "[[-35.54013711]\n",
      " [-13.73037998]]\n",
      "[[35.41839029]\n",
      " [13.68334499]]\n",
      "[[-35.29706053]\n",
      " [-13.63647112]]\n",
      "[[35.1761464 ]\n",
      " [13.58975783]]\n",
      "[[-35.05564648]\n",
      " [-13.54320455]]\n",
      "[[34.93555934]\n",
      " [13.49681075]]\n",
      "Training:   0%|                       | 938/1000000 [00:10<3:13:40, 85.98it/s, loss_val=29.8962, thetas=-0.5724 4.9176][[-34.81588358]\n",
      " [-13.45057588]]\n",
      "[[34.69661778]\n",
      " [13.40449939]]\n",
      "[[-34.57776053]\n",
      " [-13.35858074]]\n",
      "[[34.45931045]\n",
      " [13.31281939]]\n",
      "[[-34.34126613]\n",
      " [-13.2672148 ]]\n",
      "[[34.22362618]\n",
      " [13.22176643]]\n",
      "[[-34.10638923]\n",
      " [-13.17647376]]\n",
      "[[33.98955388]\n",
      " [13.13133624]]\n",
      "[[-33.87311876]\n",
      " [-13.08635334]]\n",
      "Training:   0%|                       | 947/1000000 [00:11<3:14:21, 85.67it/s, loss_val=29.8962, thetas=-0.5724 4.9176][[33.75708251]\n",
      " [13.04152453]]\n",
      "[[-33.64144375]\n",
      " [-12.9968493 ]]\n",
      "[[33.52620113]\n",
      " [12.9523271 ]]\n",
      "[[-33.41135328]\n",
      " [-12.90795742]]\n",
      "[[33.29689886]\n",
      " [12.86373973]]\n",
      "[[-33.18283651]\n",
      " [-12.81967351]]\n",
      "[[33.0691649 ]\n",
      " [12.77575825]]\n",
      "[[-32.95588269]\n",
      " [-12.73199342]]\n",
      "[[32.84298853]\n",
      " [12.68837852]]\n",
      "Training:   0%|                       | 956/1000000 [00:11<3:15:57, 84.97it/s, loss_val=29.8962, thetas=-0.5724 4.9176][[-32.73048111]\n",
      " [-12.64491302]]\n",
      "[[32.61835909]\n",
      " [12.60159643]]\n",
      "[[-32.50662116]\n",
      " [-12.55842821]]\n",
      "[[32.395266  ]\n",
      " [12.51540788]]\n",
      "[[-32.2842923 ]\n",
      " [-12.47253491]]\n",
      "[[32.17369876]\n",
      " [12.42980881]]\n",
      "[[-32.06348406]\n",
      " [-12.38722908]]\n",
      "[[31.95364692]\n",
      " [12.3447952 ]]\n",
      "[[-31.84418604]\n",
      " [-12.30250669]]\n",
      "Training:   0%|                       | 965/1000000 [00:11<3:14:18, 85.69it/s, loss_val=29.8962, thetas=-0.5724 4.9176][[31.73510013]\n",
      " [12.26036304]]\n",
      "[[-31.6263879 ]\n",
      " [-12.21836376]]\n",
      "[[31.51804808]\n",
      " [12.17650836]]\n",
      "[[-31.41007939]\n",
      " [-12.13479633]]\n",
      "[[31.30248056]\n",
      " [12.09322719]]\n",
      "[[-31.19525033]\n",
      " [-12.05180046]]\n",
      "[[31.08838742]\n",
      " [12.01051563]]\n",
      "[[-30.98189058]\n",
      " [-11.96937223]]\n",
      "[[30.87575856]\n",
      " [11.92836978]]\n",
      "Training:   0%|                       | 974/1000000 [00:11<3:13:41, 85.96it/s, loss_val=29.8962, thetas=-0.5724 4.9176][[-30.76999011]\n",
      " [-11.88750778]]\n",
      "[[30.66458398]\n",
      " [11.84678576]]\n",
      "[[-30.55953893]\n",
      " [-11.80620323]]\n",
      "[[30.45485373]\n",
      " [11.76575973]]\n",
      "[[-30.35052713]\n",
      " [-11.72545477]]\n",
      "[[30.24655792]\n",
      " [11.68528788]]\n",
      "[[-30.14294487]\n",
      " [-11.64525859]]\n",
      "[[30.03968675]\n",
      " [11.60536642]]\n",
      "[[-29.93678236]\n",
      " [-11.56561091]]\n",
      "Training:   0%|                       | 983/1000000 [00:11<3:14:22, 85.66it/s, loss_val=29.8962, thetas=-0.5724 4.9176][[29.83423048]\n",
      " [11.52599158]]\n",
      "[[-29.7320299 ]\n",
      " [-11.48650797]]\n",
      "[[29.63017942]\n",
      " [11.44715962]]\n",
      "[[-29.52867785]\n",
      " [-11.40794606]]\n",
      "[[29.42752397]\n",
      " [11.36886684]]\n",
      "[[-29.32671662]\n",
      " [-11.32992148]]\n",
      "[[29.22625458]\n",
      " [11.29110953]]\n",
      "[[-29.1261367 ]\n",
      " [-11.25243054]]\n",
      "[[29.02636178]\n",
      " [11.21388405]]\n",
      "Training:   0%|                       | 992/1000000 [00:11<3:12:05, 86.68it/s, loss_val=29.8962, thetas=-0.5724 4.9176][[-28.92692864]\n",
      " [-11.17546961]]\n",
      "[[28.82783613]\n",
      " [11.13718675]]\n",
      "[[-28.72908307]\n",
      " [-11.09903504]]\n",
      "[[28.63066831]\n",
      " [11.06101403]]\n",
      "[[-28.53259067]\n",
      " [-11.02312325]]\n",
      "[[28.43484901]\n",
      " [10.98536228]]\n",
      "[[-28.33744217]\n",
      " [-10.94773066]]\n",
      "[[28.24036901]\n",
      " [10.91022796]]\n",
      "[[-28.14362839]\n",
      " [-10.87285372]]\n",
      "Training:   0%|                      | 1001/1000000 [00:11<3:14:55, 85.42it/s, loss_val=28.9538, thetas=-0.5966 4.9083][[28.04721916]\n",
      " [10.83560751]]\n",
      "[[-27.9511402 ]\n",
      " [-10.79848889]]\n",
      "[[27.85539036]\n",
      " [10.76149743]]\n",
      "[[-27.75996853]\n",
      " [-10.72463269]]\n",
      "[[27.66487357]\n",
      " [10.68789423]]\n",
      "[[-27.57010437]\n",
      " [-10.65128162]]\n",
      "[[27.47565982]\n",
      " [10.61479444]]\n",
      "[[-27.38153879]\n",
      " [-10.57843224]]\n",
      "[[27.28774019]\n",
      " [10.54219461]]\n",
      "Training:   0%|                      | 1010/1000000 [00:11<3:13:34, 86.01it/s, loss_val=28.9538, thetas=-0.5966 4.9083][[-27.19426291]\n",
      " [-10.50608111]]\n",
      "[[27.10110584]\n",
      " [10.47009132]]\n",
      "[[-27.0082679 ]\n",
      " [-10.43422483]]\n",
      "[[26.91574798]\n",
      " [10.39848119]]\n",
      "[[-26.823545]\n",
      " [-10.36286 ]]\n",
      "[[26.73165787]\n",
      " [10.32736084]]\n",
      "[[-26.64008551]\n",
      " [-10.29198328]]\n",
      "[[26.54882684]\n",
      " [10.25672691]]\n",
      "[[-26.45788079]\n",
      " [-10.22159131]]\n",
      "Training:   0%|                      | 1019/1000000 [00:11<3:13:44, 85.94it/s, loss_val=28.9538, thetas=-0.5966 4.9083][[26.36724628]\n",
      " [10.18657608]]\n",
      "[[-26.27692226]\n",
      " [-10.1516808 ]]\n",
      "[[26.18690765]\n",
      " [10.11690505]]\n",
      "[[-26.09720139]\n",
      " [-10.08224843]]\n",
      "[[26.00780243]\n",
      " [10.04771053]]\n",
      "[[-25.91870972]\n",
      " [-10.01329095]]\n",
      "[[25.82992221]\n",
      " [ 9.97898927]]\n",
      "[[-25.74143885]\n",
      " [ -9.9448051 ]]\n",
      "[[25.6532586 ]\n",
      " [ 9.91073803]]\n",
      "Training:   0%|                      | 1028/1000000 [00:12<3:14:24, 85.64it/s, loss_val=28.9538, thetas=-0.5966 4.9083][[-25.56538042]\n",
      " [ -9.87678766]]\n",
      "[[25.47780328]\n",
      " [ 9.84295359]]\n",
      "[[-25.39052614]\n",
      " [ -9.80923542]]\n",
      "[[25.30354798]\n",
      " [ 9.77563276]]\n",
      "[[-25.21686778]\n",
      " [ -9.74214521]]\n",
      "[[25.1304845 ]\n",
      " [ 9.70877238]]\n",
      "[[-25.04439715]\n",
      " [ -9.67551386]]\n",
      "[[24.95860469]\n",
      " [ 9.64236928]]\n",
      "[[-24.87310613]\n",
      " [ -9.60933824]]\n",
      "Training:   0%|                      | 1037/1000000 [00:12<3:15:59, 84.95it/s, loss_val=28.9538, thetas=-0.5966 4.9083][[24.78790045]\n",
      " [ 9.57642035]]\n",
      "[[-24.70298666]\n",
      " [ -9.54361522]]\n",
      "[[24.61836374]\n",
      " [ 9.51092247]]\n",
      "[[-24.53403071]\n",
      " [ -9.47834172]]\n",
      "[[24.44998658]\n",
      " [ 9.44587257]]\n",
      "[[-24.36623034]\n",
      " [ -9.41351465]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24.28276103]\n",
      " [ 9.38126758]]\n",
      "[[-24.19957765]\n",
      " [ -9.34913097]]\n",
      "[[24.11667922]\n",
      " [ 9.31710445]]\n",
      "Training:   0%|                      | 1046/1000000 [00:12<3:15:29, 85.17it/s, loss_val=28.9538, thetas=-0.5966 4.9083][[-24.03406477]\n",
      " [ -9.28518764]]\n",
      "[[23.95173332]\n",
      " [ 9.25338016]]\n",
      "[[-23.86968391]\n",
      " [ -9.22168165]]\n",
      "[[23.78791557]\n",
      " [ 9.19009172]]\n",
      "[[-23.70642734]\n",
      " [ -9.15861001]]\n",
      "[[23.62521825]\n",
      " [ 9.12723614]]\n",
      "[[-23.54428736]\n",
      " [ -9.09596975]]\n",
      "[[23.4636337 ]\n",
      " [ 9.06481046]]\n",
      "[[-23.38325633]\n",
      " [ -9.03375791]]\n",
      "Training:   0%|                      | 1055/1000000 [00:12<3:15:38, 85.10it/s, loss_val=28.9538, thetas=-0.5966 4.9083][[23.30315431]\n",
      " [ 9.00281174]]\n",
      "[[-23.22332668]\n",
      " [ -8.97197157]]\n",
      "[[23.14377251]\n",
      " [ 8.94123705]]\n",
      "[[-23.06449086]\n",
      " [ -8.91060782]]\n",
      "[[22.98548081]\n",
      " [ 8.88008351]]\n",
      "[[-22.90674141]\n",
      " [ -8.84966377]]\n",
      "[[22.82827174]\n",
      " [ 8.81934823]]\n",
      "[[-22.75007087]\n",
      " [ -8.78913654]]\n",
      "[[22.6721379 ]\n",
      " [ 8.75902835]]\n",
      "Training:   0%|                      | 1064/1000000 [00:12<3:15:10, 85.30it/s, loss_val=28.9538, thetas=-0.5966 4.9083][[-22.59447189]\n",
      " [ -8.72902329]]\n",
      "[[22.51707193]\n",
      " [ 8.69912102]]\n",
      "[[-22.43993712]\n",
      " [ -8.66932118]]\n",
      "[[22.36306654]\n",
      " [ 8.63962343]]\n",
      "[[-22.28645929]\n",
      " [ -8.61002741]]\n",
      "[[22.21011447]\n",
      " [ 8.58053277]]\n",
      "[[-22.13403118]\n",
      " [ -8.55113917]]\n",
      "[[22.05820851]\n",
      " [ 8.52184626]]\n",
      "[[-21.98264559]\n",
      " [ -8.4926537 ]]\n",
      "Training:   0%|                      | 1073/1000000 [00:12<3:14:18, 85.68it/s, loss_val=28.9538, thetas=-0.5966 4.9083][[21.90734152]\n",
      " [ 8.46356114]]\n",
      "[[-21.83229541]\n",
      " [ -8.43456824]]\n",
      "[[21.75750638]\n",
      " [ 8.40567466]]\n",
      "[[-21.68297354]\n",
      " [ -8.37688006]]\n",
      "[[21.60869603]\n",
      " [ 8.3481841 ]]\n",
      "[[-21.53467296]\n",
      " [ -8.31958644]]\n",
      "[[21.46090347]\n",
      " [ 8.29108674]]\n",
      "[[-21.38738668]\n",
      " [ -8.26268467]]\n",
      "[[21.31412174]\n",
      " [ 8.2343799 ]]\n",
      "Training:   0%|                      | 1082/1000000 [00:12<3:14:26, 85.62it/s, loss_val=28.9538, thetas=-0.5966 4.9083][[-21.24110777]\n",
      " [ -8.20617208]]\n",
      "[[21.16834392]\n",
      " [ 8.1780609 ]]\n",
      "[[-21.09582933]\n",
      " [ -8.15004601]]\n",
      "[[21.02356315]\n",
      " [ 8.1221271 ]]\n",
      "[[-20.95154452]\n",
      " [ -8.09430382]]\n",
      "[[20.8797726 ]\n",
      " [ 8.06657585]]\n",
      "[[-20.80824655]\n",
      " [ -8.03894287]]\n",
      "[[20.73696551]\n",
      " [ 8.01140455]]\n",
      "[[-20.66592866]\n",
      " [ -7.98396057]]\n",
      "Training:   0%|                      | 1091/1000000 [00:12<3:13:14, 86.16it/s, loss_val=28.9538, thetas=-0.5966 4.9083][[20.59513515]\n",
      " [ 7.95661059]]\n",
      "[[-20.52458415]\n",
      " [ -7.92935431]]\n",
      "[[20.45427483]\n",
      " [ 7.9021914 ]]\n",
      "[[-20.38420637]\n",
      " [ -7.87512154]]\n",
      "[[20.31437793]\n",
      " [ 7.8481444 ]]\n",
      "[[-20.2447887 ]\n",
      " [ -7.82125969]]\n",
      "[[20.17543786]\n",
      " [ 7.79446706]]\n",
      "[[-20.10632458]\n",
      " [ -7.76776622]]\n",
      "[[20.03744806]\n",
      " [ 7.74115685]]\n",
      "Training:   0%|                      | 1100/1000000 [00:12<3:12:23, 86.53it/s, loss_val=28.9538, thetas=-0.5966 4.9083][[-19.96880748]\n",
      " [ -7.71463863]]\n",
      "Training:   0%|                      | 1100/1000000 [00:12<3:12:23, 86.53it/s, loss_val=28.4794, thetas=-0.6139 4.9016][[19.90040204]\n",
      " [ 7.68821125]]\n",
      "[[-19.83223093]\n",
      " [ -7.6618744 ]]\n",
      "[[19.76429335]\n",
      " [ 7.63562777]]\n",
      "[[-19.6965885 ]\n",
      " [ -7.60947105]]\n",
      "[[19.62911558]\n",
      " [ 7.58340394]]\n",
      "[[-19.56187379]\n",
      " [ -7.55742612]]\n",
      "[[19.49486235]\n",
      " [ 7.53153729]]\n",
      "[[-19.42808046]\n",
      " [ -7.50573714]]\n",
      "Training:   0%|                      | 1109/1000000 [00:12<3:14:00, 85.81it/s, loss_val=28.4794, thetas=-0.6139 4.9016][[19.36152734]\n",
      " [ 7.48002538]]\n",
      "[[-19.29520221]\n",
      " [ -7.45440169]]\n",
      "[[19.22910428]\n",
      " [ 7.42886578]]\n",
      "[[-19.16323278]\n",
      " [ -7.40341735]]\n",
      "[[19.09758693]\n",
      " [ 7.3780561 ]]\n",
      "[[-19.03216595]\n",
      " [ -7.35278172]]\n",
      "[[18.96696909]\n",
      " [ 7.32759392]]\n",
      "[[-18.90199556]\n",
      " [ -7.30249241]]\n",
      "[[18.83724461]\n",
      " [ 7.27747688]]\n",
      "Training:   0%|                      | 1118/1000000 [00:13<3:14:02, 85.80it/s, loss_val=28.4794, thetas=-0.6139 4.9016][[-18.77271546]\n",
      " [ -7.25254705]]\n",
      "[[18.70840737]\n",
      " [ 7.22770262]]\n",
      "[[-18.64431958]\n",
      " [ -7.2029433 ]]\n",
      "[[18.58045132]\n",
      " [ 7.17826879]]\n",
      "[[-18.51680186]\n",
      " [ -7.15367881]]\n",
      "[[18.45337043]\n",
      " [ 7.12917306]]\n",
      "[[-18.39015629]\n",
      " [ -7.10475126]]\n",
      "[[18.3271587 ]\n",
      " [ 7.08041312]]\n",
      "[[-18.26437692]\n",
      " [ -7.05615835]]\n",
      "Training:   0%|                      | 1127/1000000 [00:13<3:13:30, 86.03it/s, loss_val=28.4794, thetas=-0.6139 4.9016][[18.2018102 ]\n",
      " [ 7.03198667]]\n",
      "[[-18.13945781]\n",
      " [ -7.00789779]]\n",
      "[[18.07731902]\n",
      " [ 6.98389144]]\n",
      "[[-18.01539309]\n",
      " [ -6.95996732]]\n",
      "[[17.9536793 ]\n",
      " [ 6.93612515]]\n",
      "[[-17.89217691]\n",
      " [ -6.91236466]]\n",
      "[[17.8308852 ]\n",
      " [ 6.88868556]]\n",
      "[[-17.76980346]\n",
      " [ -6.86508758]]\n",
      "[[17.70893096]\n",
      " [ 6.84157043]]\n",
      "Training:   0%|                      | 1136/1000000 [00:13<3:12:29, 86.48it/s, loss_val=28.4794, thetas=-0.6139 4.9016][[-17.64826699]\n",
      " [ -6.81813385]]\n",
      "[[17.58781083]\n",
      " [ 6.79477755]]\n",
      "[[-17.52756176]\n",
      " [ -6.77150126]]\n",
      "[[17.46751909]\n",
      " [ 6.74830471]]\n",
      "[[-17.4076821 ]\n",
      " [ -6.72518761]]\n",
      "[[17.34805009]\n",
      " [ 6.70214971]]\n",
      "[[-17.28862235]\n",
      " [ -6.67919073]]\n",
      "[[17.22939819]\n",
      " [ 6.6563104 ]]\n",
      "[[-17.17037691]\n",
      " [ -6.63350844]]\n",
      "Training:   0%|                      | 1145/1000000 [00:13<3:12:58, 86.27it/s, loss_val=28.4794, thetas=-0.6139 4.9016][[17.11155782]\n",
      " [ 6.6107846 ]]\n",
      "[[-17.05294022]\n",
      " [ -6.5881386 ]]\n",
      "[[16.99452341]\n",
      " [ 6.56557017]]\n",
      "[[-16.93630672]\n",
      " [ -6.54307906]]\n",
      "[[16.87828946]\n",
      " [ 6.52066499]]\n",
      "[[-16.82047095]\n",
      " [ -6.4983277 ]]\n",
      "[[16.76285049]\n",
      " [ 6.47606694]]\n",
      "[[-16.70542743]\n",
      " [ -6.45388243]]\n",
      "[[16.64820107]\n",
      " [ 6.43177391]]\n",
      "Training:   0%|                      | 1154/1000000 [00:13<3:13:18, 86.12it/s, loss_val=28.4794, thetas=-0.6139 4.9016][[-16.59117075]\n",
      " [ -6.40974113]]\n",
      "[[16.53433579]\n",
      " [ 6.38778383]]\n",
      "[[-16.47769553]\n",
      " [ -6.36590175]]\n",
      "[[16.42124929]\n",
      " [ 6.34409462]]\n",
      "[[-16.36499642]\n",
      " [ -6.32236219]]\n",
      "[[16.30893625]\n",
      " [ 6.30070422]]\n",
      "[[-16.25306811]\n",
      " [ -6.27912043]]\n",
      "[[16.19739137]\n",
      " [ 6.25761059]]\n",
      "[[-16.14190534]\n",
      " [ -6.23617442]]\n",
      "Training:   0%|                      | 1163/1000000 [00:13<3:15:12, 85.28it/s, loss_val=28.4794, thetas=-0.6139 4.9016][[16.0866094 ]\n",
      " [ 6.21481169]]\n",
      "[[-16.03150287]\n",
      " [ -6.19352214]]\n",
      "[[15.97658512]\n",
      " [ 6.17230552]]\n",
      "[[-15.92185549]\n",
      " [ -6.15116158]]\n",
      "[[15.86731335]\n",
      " [ 6.13009007]]\n",
      "[[-15.81295805]\n",
      " [ -6.10909075]]\n",
      "[[15.75878895]\n",
      " [ 6.08816335]]\n",
      "[[-15.70480541]\n",
      " [ -6.06730765]]\n",
      "[[15.6510068 ]\n",
      " [ 6.04652339]]\n",
      "Training:   0%|                      | 1172/1000000 [00:13<3:14:19, 85.67it/s, loss_val=28.4794, thetas=-0.6139 4.9016][[-15.59739248]\n",
      " [ -6.02581034]]\n",
      "[[15.54396182]\n",
      " [ 6.00516823]]\n",
      "[[-15.4907142 ]\n",
      " [ -5.98459684]]\n",
      "[[15.43764898]\n",
      " [ 5.96409592]]\n",
      "[[-15.38476554]\n",
      " [ -5.94366522]]\n",
      "[[15.33206327]\n",
      " [ 5.92330451]]\n",
      "[[-15.27954152]\n",
      " [ -5.90301356]]\n",
      "[[15.2271997 ]\n",
      " [ 5.88279211]]\n",
      "[[-15.17503718]\n",
      " [ -5.86263993]]\n",
      "Training:   0%|                      | 1181/1000000 [00:13<3:17:01, 84.49it/s, loss_val=28.4794, thetas=-0.6139 4.9016][[15.12305335]\n",
      " [ 5.84255678]]\n",
      "[[-15.0712476 ]\n",
      " [ -5.82254243]]\n",
      "[[15.01961931]\n",
      " [ 5.80259665]]\n",
      "[[-14.96816788]\n",
      " [ -5.78271919]]\n",
      "[[14.91689271]\n",
      " [ 5.76290982]]\n",
      "[[-14.86579318]\n",
      " [ -5.74316831]]\n",
      "[[14.8148687 ]\n",
      " [ 5.72349443]]\n",
      "[[-14.76411867]\n",
      " [ -5.70388794]]\n",
      "[[14.71354249]\n",
      " [ 5.68434862]]\n",
      "Training:   0%|                      | 1190/1000000 [00:13<3:14:28, 85.60it/s, loss_val=28.4794, thetas=-0.6139 4.9016][[-14.66313956]\n",
      " [ -5.66487623]]\n",
      "[[14.6129093 ]\n",
      " [ 5.64547055]]\n",
      "[[-14.5628511 ]\n",
      " [ -5.62613134]]\n",
      "[[14.51296438]\n",
      " [ 5.60685838]]\n",
      "[[-14.46324856]\n",
      " [ -5.58765145]]\n",
      "[[14.41370304]\n",
      " [ 5.56851031]]\n",
      "[[-14.36432725]\n",
      " [ -5.54943473]]\n",
      "[[14.3151206 ]\n",
      " [ 5.53042451]]\n",
      "[[-14.26608251]\n",
      " [ -5.51147941]]\n",
      "Training:   0%|                      | 1199/1000000 [00:14<3:13:32, 86.01it/s, loss_val=28.4794, thetas=-0.6139 4.9016][[14.21721241]\n",
      " [ 5.4925992 ]]\n",
      "[[-14.16850972]\n",
      " [ -5.47378367]]\n",
      "Training:   0%|                      | 1199/1000000 [00:14<3:13:32, 86.01it/s, loss_val=28.2406, thetas=-0.6261 4.8969][[14.11997386]\n",
      " [ 5.4550326 ]]\n",
      "[[-14.07160427]\n",
      " [ -5.43634576]]\n",
      "[[14.02340038]\n",
      " [ 5.41772293]]\n",
      "[[-13.97536161]\n",
      " [ -5.3991639 ]]\n",
      "[[13.92748741]\n",
      " [ 5.38066845]]\n",
      "[[-13.8797772 ]\n",
      " [ -5.36223635]]\n",
      "[[13.83223043]\n",
      " [ 5.34386739]]\n",
      "Training:   0%|                      | 1208/1000000 [00:14<3:18:08, 84.02it/s, loss_val=28.2406, thetas=-0.6261 4.8969][[-13.78484654]\n",
      " [ -5.32556136]]\n",
      "[[13.73762497]\n",
      " [ 5.30731804]]\n",
      "[[-13.69056516]\n",
      " [ -5.28913722]]\n",
      "[[13.64366656]\n",
      " [ 5.27101867]]\n",
      "[[-13.59692861]\n",
      " [ -5.25296219]]\n",
      "[[13.55035078]\n",
      " [ 5.23496757]]\n",
      "[[-13.5039325 ]\n",
      " [ -5.21703458]]\n",
      "[[13.45767323]\n",
      " [ 5.19916303]]\n",
      "[[-13.41157242]\n",
      " [ -5.18135271]]\n",
      "Training:   0%|                      | 1217/1000000 [00:14<3:17:33, 84.26it/s, loss_val=28.2406, thetas=-0.6261 4.8969][[13.36562954]\n",
      " [ 5.16360339]]\n",
      "[[-13.31984405]\n",
      " [ -5.14591487]]\n",
      "[[13.27421539]\n",
      " [ 5.12828695]]\n",
      "[[-13.22874305]\n",
      " [ -5.11071942]]\n",
      "[[13.18342647]\n",
      " [ 5.09321206]]\n",
      "[[-13.13826513]\n",
      " [ -5.07576468]]\n",
      "[[13.0932585 ]\n",
      " [ 5.05837706]]\n",
      "[[-13.04840604]\n",
      " [ -5.04104901]]\n",
      "[[13.00370723]\n",
      " [ 5.02378032]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:   0%|                      | 1226/1000000 [00:14<3:14:50, 85.43it/s, loss_val=28.2406, thetas=-0.6261 4.8969][[-12.95916154]\n",
      " [ -5.00657079]]\n",
      "[[12.91476844]\n",
      " [ 4.9894202 ]]\n",
      "[[-12.87052742]\n",
      " [ -4.97232837]]\n",
      "[[12.82643795]\n",
      " [ 4.95529509]]\n",
      "[[-12.78249952]\n",
      " [ -4.93832016]]\n",
      "[[12.7387116 ]\n",
      " [ 4.92140338]]\n",
      "[[-12.69507368]\n",
      " [ -4.90454455]]\n",
      "[[12.65158525]\n",
      " [ 4.88774347]]\n",
      "[[-12.6082458 ]\n",
      " [ -4.87099994]]\n",
      "Training:   0%|                      | 1235/1000000 [00:14<3:15:43, 85.05it/s, loss_val=28.2406, thetas=-0.6261 4.8969][[12.56505481]\n",
      " [ 4.85431377]]\n",
      "[[-12.52201177]\n",
      " [ -4.83768476]]\n",
      "[[12.47911618]\n",
      " [ 4.82111272]]\n",
      "[[-12.43636754]\n",
      " [ -4.80459744]]\n",
      "[[12.39376533]\n",
      " [ 4.78813874]]\n",
      "[[-12.35130907]\n",
      " [ -4.77173643]]\n",
      "[[12.30899824]\n",
      " [ 4.7553903 ]]\n",
      "[[-12.26683236]\n",
      " [ -4.73910016]]\n",
      "[[12.22481092]\n",
      " [ 4.72286583]]\n",
      "Training:   0%|                      | 1244/1000000 [00:14<3:14:07, 85.75it/s, loss_val=28.2406, thetas=-0.6261 4.8969][[-12.18293343]\n",
      " [ -4.70668711]]\n",
      "[[12.14119939]\n",
      " [ 4.69056381]]\n",
      "[[-12.09960832]\n",
      " [ -4.67449575]]\n",
      "[[12.05815972]\n",
      " [ 4.65848273]]\n",
      "[[-12.01685311]\n",
      " [ -4.64252456]]\n",
      "[[11.97568801]\n",
      " [ 4.62662106]]\n",
      "[[-11.93466391]\n",
      " [ -4.61077204]]\n",
      "[[11.89378035]\n",
      " [ 4.59497731]]\n",
      "[[-11.85303684]\n",
      " [ -4.57923669]]\n",
      "Training:   0%|                      | 1253/1000000 [00:14<3:14:06, 85.76it/s, loss_val=28.2406, thetas=-0.6261 4.8969][[11.81243291]\n",
      " [ 4.56354999]]\n",
      "[[-11.77196806]\n",
      " [ -4.54791703]]\n",
      "[[11.73164184]\n",
      " [ 4.53233762]]\n",
      "[[-11.69145375]\n",
      " [ -4.51681157]]\n",
      "[[11.65140334]\n",
      " [ 4.50133872]]\n",
      "[[-11.61149012]\n",
      " [ -4.48591886]]\n",
      "[[11.57171363]\n",
      " [ 4.47055184]]\n",
      "[[-11.5320734 ]\n",
      " [ -4.45523745]]\n",
      "[[11.49256896]\n",
      " [ 4.43997552]]\n",
      "Training:   0%|                      | 1262/1000000 [00:14<3:15:45, 85.03it/s, loss_val=28.2406, thetas=-0.6261 4.8969][[-11.45319984]\n",
      " [ -4.42476588]]\n",
      "[[11.41396559]\n",
      " [ 4.40960833]]\n",
      "[[-11.37486575]\n",
      " [ -4.39450271]]\n",
      "[[11.33589984]\n",
      " [ 4.37944884]]\n",
      "[[-11.29706741]\n",
      " [ -4.36444654]]\n",
      "[[11.25836801]\n",
      " [ 4.34949562]]\n",
      "[[-11.21980118]\n",
      " [ -4.33459593]]\n",
      "[[11.18136647]\n",
      " [ 4.31974727]]\n",
      "[[-11.14306341]\n",
      " [ -4.30494948]]\n",
      "Training:   0%|                      | 1271/1000000 [00:14<3:14:42, 85.49it/s, loss_val=28.2406, thetas=-0.6261 4.8969][[11.10489157]\n",
      " [ 4.29020238]]\n",
      "[[-11.06685049]\n",
      " [ -4.2755058 ]]\n",
      "[[11.02893973]\n",
      " [ 4.26085957]]\n",
      "[[-10.99115883]\n",
      " [ -4.24626351]]\n",
      "[[10.95350735]\n",
      " [ 4.23171744]]\n",
      "[[-10.91598486]\n",
      " [ -4.21722121]]\n",
      "[[10.8785909 ]\n",
      " [ 4.20277463]]\n",
      "[[-10.84132504]\n",
      " [ -4.18837755]]\n",
      "[[10.80418684]\n",
      " [ 4.17402978]]\n",
      "Training:   0%|                      | 1280/1000000 [00:14<3:14:30, 85.58it/s, loss_val=28.2406, thetas=-0.6261 4.8969][[-10.76717586]\n",
      " [ -4.15973116]]\n",
      "[[10.73029166]\n",
      " [ 4.14548153]]\n",
      "[[-10.69353382]\n",
      " [ -4.1312807 ]]\n",
      "[[10.65690189]\n",
      " [ 4.11712853]]\n",
      "[[-10.62039545]\n",
      " [ -4.10302483]]\n",
      "[[10.58401407]\n",
      " [ 4.08896945]]\n",
      "[[-10.54775731]\n",
      " [ -4.07496222]]\n",
      "[[10.51162476]\n",
      " [ 4.06100297]]\n",
      "[[-10.47561598]\n",
      " [ -4.04709153]]\n",
      "Training:   0%|                      | 1289/1000000 [00:15<3:14:56, 85.39it/s, loss_val=28.2406, thetas=-0.6261 4.8969][[10.43973056]\n",
      " [ 4.03322776]]\n",
      "[[-10.40396807]\n",
      " [ -4.01941147]]\n",
      "[[10.36832808]\n",
      " [ 4.00564252]]\n",
      "[[-10.33281018]\n",
      " [ -3.99192073]]\n",
      "[[10.29741396]\n",
      " [ 3.97824595]]\n",
      "[[-10.26213898]\n",
      " [ -3.96461801]]\n",
      "[[10.22698485]\n",
      " [ 3.95103676]]\n",
      "[[-10.19195114]\n",
      " [ -3.93750203]]\n",
      "[[10.15703744]\n",
      " [ 3.92401366]]\n",
      "Training:   0%|                      | 1298/1000000 [00:15<3:14:40, 85.50it/s, loss_val=28.2406, thetas=-0.6261 4.8969][[-10.12224335]\n",
      " [ -3.9105715 ]]\n",
      "[[10.08756844]\n",
      " [ 3.89717539]]\n",
      "[[-10.05301232]\n",
      " [ -3.88382517]]\n",
      "Training:   0%|                      | 1298/1000000 [00:15<3:14:40, 85.50it/s, loss_val=28.1203, thetas=-0.6347 4.8935][[10.01857457]\n",
      " [ 3.87052068]]\n",
      "[[-9.9842548 ]\n",
      " [-3.85726177]]\n",
      "[[9.95005259]\n",
      " [3.84404828]]\n",
      "[[-9.91596754]\n",
      " [-3.83088005]]\n",
      "[[9.88199926]\n",
      " [3.81775693]]\n",
      "[[-9.84814733]\n",
      " [-3.80467877]]\n",
      "Training:   0%|                      | 1307/1000000 [00:15<3:16:42, 84.62it/s, loss_val=28.1203, thetas=-0.6347 4.8935][[9.81441138]\n",
      " [3.7916454 ]]\n",
      "[[-9.78079098]\n",
      " [-3.77865669]]\n",
      "[[9.74728576]\n",
      " [3.76571247]]\n",
      "[[-9.71389532]\n",
      " [-3.75281259]]\n",
      "[[9.68061926]\n",
      " [3.7399569 ]]\n",
      "[[-9.64745718]\n",
      " [-3.72714524]]\n",
      "[[9.61440871]\n",
      " [3.71437748]]\n",
      "[[-9.58147345]\n",
      " [-3.70165345]]\n",
      "[[9.54865102]\n",
      " [3.68897302]]\n",
      "Training:   0%|                      | 1316/1000000 [00:15<3:14:15, 85.69it/s, loss_val=28.1203, thetas=-0.6347 4.8935][[-9.51594102]\n",
      " [-3.67633602]]\n",
      "[[9.48334307]\n",
      " [3.66374231]]\n",
      "[[-9.45085679]\n",
      " [-3.65119174]]\n",
      "[[9.4184818 ]\n",
      " [3.63868416]]\n",
      "[[-9.38621771]\n",
      " [-3.62621943]]\n",
      "[[9.35406414]\n",
      " [3.6137974 ]]\n",
      "[[-9.32202072]\n",
      " [-3.60141792]]\n",
      "[[9.29008707]\n",
      " [3.58908085]]\n",
      "[[-9.25826281]\n",
      " [-3.57678604]]\n",
      "[[9.22654757]\n",
      " [3.56453335]]\n",
      "Training:   0%|                      | 1326/1000000 [00:15<3:11:22, 86.98it/s, loss_val=28.1203, thetas=-0.6347 4.8935][[-9.19494098]\n",
      " [-3.55232264]]\n",
      "[[9.16344265]\n",
      " [3.54015375]]\n",
      "[[-9.13205223]\n",
      " [-3.52802654]]\n",
      "[[9.10076933]\n",
      " [3.51594088]]\n",
      "[[-9.06959361]\n",
      " [-3.50389663]]\n",
      "[[9.03852467]\n",
      " [3.49189363]]\n",
      "[[-9.00756217]\n",
      " [-3.47993174]]\n",
      "[[8.97670573]\n",
      " [3.46801084]]\n",
      "[[-8.945955  ]\n",
      " [-3.45613077]]\n",
      "Training:   0%|                      | 1335/1000000 [00:15<3:11:37, 86.86it/s, loss_val=28.1203, thetas=-0.6347 4.8935][[8.9153096]\n",
      " [3.4442914]]\n",
      "[[-8.88476919]\n",
      " [-3.43249258]]\n",
      "[[8.85433339]\n",
      " [3.42073419]]\n",
      "[[-8.82400186]\n",
      " [-3.40901607]]\n",
      "[[8.79377423]\n",
      " [3.39733809]]\n",
      "[[-8.76365014]\n",
      " [-3.38570012]]\n",
      "[[8.73362926]\n",
      " [3.37410202]]\n",
      "[[-8.70371121]\n",
      " [-3.36254364]]\n",
      "[[8.67389565]\n",
      " [3.35102487]]\n",
      "Training:   0%|                      | 1344/1000000 [00:15<3:12:54, 86.28it/s, loss_val=28.1203, thetas=-0.6347 4.8935][[-8.64418222]\n",
      " [-3.33954555]]\n",
      "[[8.61457058]\n",
      " [3.32810555]]\n",
      "[[-8.58506038]\n",
      " [-3.31670474]]\n",
      "[[8.55565128]\n",
      " [3.30534299]]\n",
      "[[-8.52634291]\n",
      " [-3.29402016]]\n",
      "[[8.49713495]\n",
      " [3.28273611]]\n",
      "[[-8.46802704]\n",
      " [-3.27149072]]\n",
      "[[8.43901884]\n",
      " [3.26028386]]\n",
      "[[-8.41011001]\n",
      " [-3.24911538]]\n",
      "Training:   0%|                      | 1353/1000000 [00:15<3:13:15, 86.13it/s, loss_val=28.1203, thetas=-0.6347 4.8935][[8.38130021]\n",
      " [3.23798516]]\n",
      "[[-8.35258911]\n",
      " [-3.22689307]]\n",
      "[[8.32397636]\n",
      " [3.21583898]]\n",
      "[[-8.29546162]\n",
      " [-3.20482276]]\n",
      "[[8.26704457]\n",
      " [3.19384427]]\n",
      "[[-8.23872486]\n",
      " [-3.18290339]]\n",
      "[[8.21050216]\n",
      " [3.17199999]]\n",
      "[[-8.18237614]\n",
      " [-3.16113394]]\n",
      "[[8.15434648]\n",
      " [3.15030511]]\n",
      "Training:   0%|                      | 1362/1000000 [00:15<3:13:51, 85.86it/s, loss_val=28.1203, thetas=-0.6347 4.8935][[-8.12641283]\n",
      " [-3.13951338]]\n",
      "[[8.09857487]\n",
      " [3.12875862]]\n",
      "[[-8.07083227]\n",
      " [-3.1180407 ]]\n",
      "[[8.04318471]\n",
      " [3.10735949]]\n",
      "[[-8.01563186]\n",
      " [-3.09671487]]\n",
      "[[7.98817339]\n",
      " [3.08610672]]\n",
      "[[-7.96080899]\n",
      " [-3.07553491]]\n",
      "[[7.93353832]\n",
      " [3.06499931]]\n",
      "[[-7.90636108]\n",
      " [-3.05449981]]\n",
      "Training:   0%|                      | 1371/1000000 [00:16<3:15:01, 85.34it/s, loss_val=28.1203, thetas=-0.6347 4.8935][[7.87927693]\n",
      " [3.04403627]]\n",
      "[[-7.85228556]\n",
      " [-3.03360857]]\n",
      "[[7.82538666]\n",
      " [3.0232166 ]]\n",
      "[[-7.7985799 ]\n",
      " [-3.01286022]]\n",
      "[[7.77186497]\n",
      " [3.00253932]]\n",
      "[[-7.74524156]\n",
      " [-2.99225378]]\n",
      "[[7.71870934]\n",
      " [2.98200347]]\n",
      "[[-7.69226802]\n",
      " [-2.97178828]]\n",
      "[[7.66591727]\n",
      " [2.96160808]]\n",
      "Training:   0%|                      | 1380/1000000 [00:16<3:14:43, 85.47it/s, loss_val=28.1203, thetas=-0.6347 4.8935][[-7.63965679]\n",
      " [-2.95146275]]\n",
      "[[7.61348627]\n",
      " [2.94135217]]\n",
      "[[-7.5874054 ]\n",
      " [-2.93127623]]\n",
      "[[7.56141387]\n",
      " [2.92123481]]\n",
      "[[-7.53551138]\n",
      " [-2.91122779]]\n",
      "[[7.50969763]\n",
      " [2.90125504]]\n",
      "[[-7.4839723 ]\n",
      " [-2.89131646]]\n",
      "[[7.45833509]\n",
      " [2.88141192]]\n",
      "[[-7.43278571]\n",
      " [-2.87154132]]\n",
      "Training:   0%|                      | 1389/1000000 [00:16<3:16:11, 84.83it/s, loss_val=28.1203, thetas=-0.6347 4.8935][[7.40732385]\n",
      " [2.86170452]]\n",
      "[[-7.38194921]\n",
      " [-2.85190143]]\n",
      "[[7.3566615 ]\n",
      " [2.84213191]]\n",
      "[[-7.33146041]\n",
      " [-2.83239586]]\n",
      "[[7.30634565]\n",
      " [2.82269316]]\n",
      "[[-7.28131693]\n",
      " [-2.81302371]]\n",
      "[[7.25637394]\n",
      " [2.80338737]]\n",
      "[[-7.2315164 ]\n",
      " [-2.79378405]]\n",
      "[[7.20674401]\n",
      " [2.78421362]]\n",
      "Training:   0%|                      | 1398/1000000 [00:16<3:17:12, 84.39it/s, loss_val=28.1203, thetas=-0.6347 4.8935][[-7.18205648]\n",
      " [-2.77467597]]\n",
      "[[7.15745352]\n",
      " [2.765171  ]]\n",
      "[[-7.13293485]\n",
      " [-2.75569859]]\n",
      "Training:   0%|                      | 1398/1000000 [00:16<3:17:12, 84.39it/s, loss_val=28.0598, thetas=-0.6409 4.8912][[7.10850016]\n",
      " [2.74625863]]\n",
      "[[-7.08414918]\n",
      " [-2.73685101]]\n",
      "[[7.05988161]\n",
      " [2.72747561]]\n",
      "[[-7.03569718]\n",
      " [-2.71813233]]\n",
      "[[7.01159559]\n",
      " [2.70882106]]\n",
      "[[-6.98757656]\n",
      " [-2.69954168]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:   0%|                      | 1407/1000000 [00:16<3:19:35, 83.39it/s, loss_val=28.0598, thetas=-0.6409 4.8912][[6.96363982]\n",
      " [2.69029409]]\n",
      "[[-6.93978507]\n",
      " [-2.68107818]]\n",
      "[[6.91601204]\n",
      " [2.67189384]]\n",
      "[[-6.89232045]\n",
      " [-2.66274096]]\n",
      "[[6.86871002]\n",
      " [2.65361943]]\n",
      "[[-6.84518046]\n",
      " [-2.64452916]]\n",
      "[[6.82173151]\n",
      " [2.63547002]]\n",
      "[[-6.79836289]\n",
      " [-2.62644191]]\n",
      "[[6.77507432]\n",
      " [2.61744474]]\n",
      "Training:   0%|                      | 1416/1000000 [00:16<3:17:22, 84.32it/s, loss_val=28.0598, thetas=-0.6409 4.8912][[-6.75186552]\n",
      " [-2.60847838]]\n",
      "[[6.72873623]\n",
      " [2.59954274]]\n",
      "[[-6.70568618]\n",
      " [-2.59063771]]\n",
      "[[6.68271508]\n",
      " [2.58176318]]\n",
      "[[-6.65982267]\n",
      " [-2.57291905]]\n",
      "[[6.63700869]\n",
      " [2.56410522]]\n",
      "[[-6.61427285]\n",
      " [-2.55532159]]\n",
      "[[6.5916149 ]\n",
      " [2.54656804]]\n",
      "[[-6.56903457]\n",
      " [-2.53784448]]\n",
      "Training:   0%|                      | 1425/1000000 [00:16<3:14:42, 85.48it/s, loss_val=28.0598, thetas=-0.6409 4.8912][[6.54653159]\n",
      " [2.5291508 ]]\n",
      "[[-6.52410569]\n",
      " [-2.52048691]]\n",
      "[[6.50175662]\n",
      " [2.51185269]]\n",
      "[[-6.47948411]\n",
      " [-2.50324805]]\n",
      "[[6.45728789]\n",
      " [2.49467289]]\n",
      "[[-6.43516771]\n",
      " [-2.4861271 ]]\n",
      "[[6.41312331]\n",
      " [2.47761058]]\n",
      "[[-6.39115442]\n",
      " [-2.46912325]]\n",
      "[[6.36926078]\n",
      " [2.46066498]]\n",
      "Training:   0%|                      | 1434/1000000 [00:16<3:15:37, 85.08it/s, loss_val=28.0598, thetas=-0.6409 4.8912][[-6.34744215]\n",
      " [-2.45223569]]\n",
      "[[6.32569826]\n",
      " [2.44383528]]\n",
      "[[-6.30402885]\n",
      " [-2.43546364]]\n",
      "[[6.28243368]\n",
      " [2.42712068]]\n",
      "[[-6.26091248]\n",
      " [-2.4188063 ]]\n",
      "[[6.23946501]\n",
      " [2.4105204 ]]\n",
      "[[-6.21809101]\n",
      " [-2.40226288]]\n",
      "[[6.19679022]\n",
      " [2.39403366]]\n",
      "[[-6.17556241]\n",
      " [-2.38583262]]\n",
      "Training:   0%|                      | 1443/1000000 [00:16<3:16:15, 84.80it/s, loss_val=28.0598, thetas=-0.6409 4.8912][[6.15440731]\n",
      " [2.37765968]]\n",
      "[[-6.13332468]\n",
      " [-2.36951473]]\n",
      "[[6.11231427]\n",
      " [2.36139769]]\n",
      "[[-6.09137584]\n",
      " [-2.35330845]]\n",
      "[[6.07050913]\n",
      " [2.34524692]]\n",
      "[[-6.04971391]\n",
      " [-2.33721301]]\n",
      "[[6.02898992]\n",
      " [2.32920662]]\n",
      "[[-6.00833692]\n",
      " [-2.32122765]]\n",
      "[[5.98775468]\n",
      " [2.31327602]]\n",
      "Training:   0%|                      | 1452/1000000 [00:17<3:16:41, 84.61it/s, loss_val=28.0598, thetas=-0.6409 4.8912][[-5.96724294]\n",
      " [-2.30535163]]\n",
      "[[5.94680146]\n",
      " [2.29745438]]\n",
      "[[-5.92643001]\n",
      " [-2.28958419]]\n",
      "[[5.90612835]\n",
      " [2.28174096]]\n",
      "[[-5.88589623]\n",
      " [-2.27392459]]\n",
      "[[5.86573341]\n",
      " [2.266135  ]]\n",
      "[[-5.84563967]\n",
      " [-2.2583721 ]]\n",
      "[[5.82561476]\n",
      " [2.25063578]]\n",
      "[[-5.80565845]\n",
      " [-2.24292597]]\n",
      "Training:   0%|                      | 1461/1000000 [00:17<3:17:00, 84.48it/s, loss_val=28.0598, thetas=-0.6409 4.8912][[5.7857705 ]\n",
      " [2.23524257]]\n",
      "[[-5.76595068]\n",
      " [-2.22758549]]\n",
      "[[5.74619876]\n",
      " [2.21995464]]\n",
      "[[-5.72651449]\n",
      " [-2.21234993]]\n",
      "[[5.70689766]\n",
      " [2.20477128]]\n",
      "[[-5.68734803]\n",
      " [-2.19721858]]\n",
      "[[5.66786537]\n",
      " [2.18969175]]\n",
      "[[-5.64844944]\n",
      " [-2.18219071]]\n",
      "[[5.62910003]\n",
      " [2.17471537]]\n",
      "Training:   0%|                      | 1470/1000000 [00:17<3:17:46, 84.15it/s, loss_val=28.0598, thetas=-0.6409 4.8912][[-5.6098169 ]\n",
      " [-2.16726563]]\n",
      "[[5.59059983]\n",
      " [2.15984142]]\n",
      "[[-5.57144859]\n",
      " [-2.15244263]]\n",
      "[[5.55236296]\n",
      " [2.14506919]]\n",
      "[[-5.5333427 ]\n",
      " [-2.13772101]]\n",
      "[[5.5143876]\n",
      " [2.130398 ]]\n",
      "[[-5.49549743]\n",
      " [-2.12310008]]\n",
      "[[5.47667198]\n",
      " [2.11582716]]\n",
      "[[-5.45791101]\n",
      " [-2.10857915]]\n",
      "Training:   0%|                      | 1479/1000000 [00:17<3:16:39, 84.63it/s, loss_val=28.0598, thetas=-0.6409 4.8912][[5.43921431]\n",
      " [2.10135597]]\n",
      "[[-5.42058165]\n",
      " [-2.09415753]]\n",
      "[[5.40201283]\n",
      " [2.08698376]]\n",
      "[[-5.38350762]\n",
      " [-2.07983455]]\n",
      "[[5.36506579]\n",
      " [2.07270984]]\n",
      "[[-5.34668715]\n",
      " [-2.06560954]]\n",
      "[[5.32837146]\n",
      " [2.05853355]]\n",
      "[[-5.31011851]\n",
      " [-2.05148181]]\n",
      "[[5.29192809]\n",
      " [2.04445423]]\n",
      "Training:   0%|                      | 1488/1000000 [00:17<3:16:25, 84.73it/s, loss_val=28.0598, thetas=-0.6409 4.8912][[-5.27379998]\n",
      " [-2.03745071]]\n",
      "[[5.25573397]\n",
      " [2.03047119]]\n",
      "[[-5.23772986]\n",
      " [-2.02351558]]\n",
      "[[5.21978741]\n",
      " [2.0165838 ]]\n",
      "[[-5.20190643]\n",
      " [-2.00967576]]\n",
      "[[5.1840867 ]\n",
      " [2.00279138]]\n",
      "[[-5.16632802]\n",
      " [-1.99593059]]\n",
      "[[5.14863017]\n",
      " [1.9890933 ]]\n",
      "[[-5.13099295]\n",
      " [-1.98227943]]\n",
      "Training:   0%|                      | 1497/1000000 [00:17<3:16:15, 84.79it/s, loss_val=28.0598, thetas=-0.6409 4.8912][[5.11341614]\n",
      " [1.97548891]]\n",
      "[[-5.09589955]\n",
      " [-1.96872164]]\n",
      "[[5.07844296]\n",
      " [1.96197756]]\n",
      "[[-5.06104617]\n",
      " [-1.95525658]]\n",
      "Training:   0%|                      | 1497/1000000 [00:17<3:16:15, 84.79it/s, loss_val=28.0293, thetas=-0.6453 4.8895][[5.04370898]\n",
      " [1.94855863]]\n",
      "[[-5.02643117]\n",
      " [-1.94188362]]\n",
      "[[5.00921256]\n",
      " [1.93523147]]\n",
      "[[-4.99205293]\n",
      " [-1.92860211]]\n",
      "[[4.97495208]\n",
      " [1.92199547]]\n",
      "Training:   0%|                      | 1506/1000000 [00:17<3:17:15, 84.37it/s, loss_val=28.0293, thetas=-0.6453 4.8895][[-4.95790981]\n",
      " [-1.91541145]]\n",
      "[[4.94092592]\n",
      " [1.90884999]]\n",
      "[[-4.92400021]\n",
      " [-1.902311  ]]\n",
      "[[4.90713248]\n",
      " [1.89579442]]\n",
      "[[-4.89032254]\n",
      " [-1.88930016]]\n",
      "[[4.87357018]\n",
      " [1.88282814]]\n",
      "[[-4.8568752]\n",
      " [-1.8763783]]\n",
      "[[4.84023742]\n",
      " [1.86995055]]\n",
      "[[-4.82365663]\n",
      " [-1.86354482]]\n",
      "Training:   0%|                      | 1515/1000000 [00:17<3:15:48, 84.99it/s, loss_val=28.0293, thetas=-0.6453 4.8895][[4.80713264]\n",
      " [1.85716104]]\n",
      "[[-4.79066526]\n",
      " [-1.85079912]]\n",
      "[[4.77425429]\n",
      " [1.84445899]]\n",
      "[[-4.75789953]\n",
      " [-1.83814059]]\n",
      "[[4.7416008 ]\n",
      " [1.83184383]]\n",
      "[[-4.7253579 ]\n",
      " [-1.82556863]]\n",
      "[[4.70917065]\n",
      " [1.81931494]]\n",
      "[[-4.69303884]\n",
      " [-1.81308267]]\n",
      "[[4.6769623 ]\n",
      " [1.80687174]]\n",
      "Training:   0%|                      | 1524/1000000 [00:17<3:16:56, 84.50it/s, loss_val=28.0293, thetas=-0.6453 4.8895][[-4.66094083]\n",
      " [-1.8006821 ]]\n",
      "[[4.64497424]\n",
      " [1.79451366]]\n",
      "[[-4.62906235]\n",
      " [-1.78836634]]\n",
      "[[4.61320497]\n",
      " [1.78224009]]\n",
      "[[-4.5974019 ]\n",
      " [-1.77613482]]\n",
      "[[4.58165298]\n",
      " [1.77005047]]\n",
      "[[-4.565958  ]\n",
      " [-1.76398696]]\n",
      "[[4.55031679]\n",
      " [1.75794422]]\n",
      "[[-4.53472915]\n",
      " [-1.75192218]]\n",
      "Training:   0%|                      | 1533/1000000 [00:17<3:19:23, 83.46it/s, loss_val=28.0293, thetas=-0.6453 4.8895][[4.51919492]\n",
      " [1.74592077]]\n",
      "[[-4.5037139 ]\n",
      " [-1.73993992]]\n",
      "[[4.48828591]\n",
      " [1.73397955]]\n",
      "[[-4.47291077]\n",
      " [-1.72803961]]\n",
      "[[4.4575883 ]\n",
      " [1.72212001]]\n",
      "[[-4.44231832]\n",
      " [-1.71622069]]\n",
      "[[4.42710065]\n",
      " [1.71034158]]\n",
      "[[-4.41193511]\n",
      " [-1.70448261]]\n",
      "[[4.39682152]\n",
      " [1.69864371]]\n",
      "Training:   0%|                      | 1542/1000000 [00:18<3:19:26, 83.44it/s, loss_val=28.0293, thetas=-0.6453 4.8895][[-4.3817597 ]\n",
      " [-1.69282481]]\n",
      "[[4.36674948]\n",
      " [1.68702584]]\n",
      "[[-4.35179068]\n",
      " [-1.68124674]]\n",
      "[[4.33688313]\n",
      " [1.67548744]]\n",
      "[[-4.32202663]\n",
      " [-1.66974786]]\n",
      "[[4.30722104]\n",
      " [1.66402795]]\n",
      "[[-4.29246616]\n",
      " [-1.65832763]]\n",
      "[[4.27776182]\n",
      " [1.65264684]]\n",
      "[[-4.26310786]\n",
      " [-1.64698551]]\n",
      "Training:   0%|                      | 1551/1000000 [00:18<3:17:57, 84.06it/s, loss_val=28.0293, thetas=-0.6453 4.8895][[4.24850409]\n",
      " [1.64134357]]\n",
      "[[-4.23395036]\n",
      " [-1.63572096]]\n",
      "[[4.21944647]\n",
      " [1.63011761]]\n",
      "[[-4.20499227]\n",
      " [-1.62453346]]\n",
      "[[4.19058759]\n",
      " [1.61896843]]\n",
      "[[-4.17623225]\n",
      " [-1.61342247]]\n",
      "[[4.16192609]\n",
      " [1.6078955 ]]\n",
      "[[-4.14766894]\n",
      " [-1.60238747]]\n",
      "[[4.13346062]\n",
      " [1.59689831]]\n",
      "Training:   0%|                      | 1560/1000000 [00:18<3:15:06, 85.29it/s, loss_val=28.0293, thetas=-0.6453 4.8895][[-4.11930098]\n",
      " [-1.59142795]]\n",
      "[[4.10518984]\n",
      " [1.58597633]]\n",
      "[[-4.09112704]\n",
      " [-1.58054339]]\n",
      "[[4.07711242]\n",
      " [1.57512906]]\n",
      "[[-4.0631458 ]\n",
      " [-1.56973327]]\n",
      "[[4.04922703]\n",
      " [1.56435597]]\n",
      "[[-4.03535594]\n",
      " [-1.55899709]]\n",
      "[[4.02153236]\n",
      " [1.55365657]]\n",
      "[[-4.00775614]\n",
      " [-1.54833434]]\n",
      "Training:   0%|                      | 1569/1000000 [00:18<3:15:20, 85.19it/s, loss_val=28.0293, thetas=-0.6453 4.8895][[3.99402711]\n",
      " [1.54303034]]\n",
      "[[-3.98034511]\n",
      " [-1.53774451]]\n",
      "[[3.96670999]\n",
      " [1.53247679]]\n",
      "[[-3.95312157]\n",
      " [-1.52722712]]\n",
      "[[3.93957969]\n",
      " [1.52199543]]\n",
      "[[-3.92608421]\n",
      " [-1.51678166]]\n",
      "[[3.91263496]\n",
      " [1.51158575]]\n",
      "[[-3.89923178]\n",
      " [-1.50640764]]\n",
      "[[3.88587452]\n",
      " [1.50124727]]\n",
      "Training:   0%|                      | 1578/1000000 [00:18<3:13:49, 85.85it/s, loss_val=28.0293, thetas=-0.6453 4.8895][[-3.87256301]\n",
      " [-1.49610457]]\n",
      "[[3.8592971 ]\n",
      " [1.49097949]]\n",
      "[[-3.84607663]\n",
      " [-1.48587197]]\n",
      "[[3.83290146]\n",
      " [1.48078195]]\n",
      "[[-3.81977141]\n",
      " [-1.47570936]]\n",
      "[[3.80668635]\n",
      " [1.47065415]]\n",
      "[[-3.79364611]\n",
      " [-1.46561625]]\n",
      "[[3.78065054]\n",
      " [1.46059562]]\n",
      "[[-3.76769949]\n",
      " [-1.45559218]]\n",
      "Training:   0%|                      | 1587/1000000 [00:18<3:13:19, 86.07it/s, loss_val=28.0293, thetas=-0.6453 4.8895][[3.7547928 ]\n",
      " [1.45060588]]\n",
      "[[-3.74193033]\n",
      " [-1.44563666]]\n",
      "[[3.72911191]\n",
      " [1.44068447]]\n",
      "[[-3.71633741]\n",
      " [-1.43574924]]\n",
      "[[3.70360667]\n",
      " [1.43083092]]\n",
      "[[-3.69091954]\n",
      " [-1.42592944]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.67827588]\n",
      " [1.42104476]]\n",
      "[[-3.66567552]\n",
      " [-1.4161768 ]]\n",
      "[[3.65311833]\n",
      " [1.41132553]]\n",
      "Training:   0%|                      | 1596/1000000 [00:18<3:13:32, 85.98it/s, loss_val=28.0293, thetas=-0.6453 4.8895][[-3.64060415]\n",
      " [-1.40649087]]\n",
      "[[3.62813285]\n",
      " [1.40167277]]\n",
      "[[-3.61570426]\n",
      " [-1.39687118]]\n",
      "[[3.60331825]\n",
      " [1.39208604]]\n",
      "[[-3.59097467]\n",
      " [-1.38731729]]\n",
      "Training:   0%|                      | 1596/1000000 [00:18<3:13:32, 85.98it/s, loss_val=28.0140, thetas=-0.6484 4.8883][[3.57867337]\n",
      " [1.38256488]]\n",
      "[[-3.56641422]\n",
      " [-1.37782874]]\n",
      "[[3.55419706]\n",
      " [1.37310883]]\n",
      "[[-3.54202175]\n",
      " [-1.36840509]]\n",
      "Training:   0%|                      | 1605/1000000 [00:18<3:15:20, 85.18it/s, loss_val=28.0140, thetas=-0.6484 4.8883][[3.52988815]\n",
      " [1.36371746]]\n",
      "[[-3.51779611]\n",
      " [-1.35904589]]\n",
      "[[3.5057455 ]\n",
      " [1.35439032]]\n",
      "[[-3.49373616]\n",
      " [-1.3497507 ]]\n",
      "[[3.48176797]\n",
      " [1.34512698]]\n",
      "[[-3.46984077]\n",
      " [-1.34051909]]\n",
      "[[3.45795444]\n",
      " [1.33592699]]\n",
      "[[-3.44610882]\n",
      " [-1.33135062]]\n",
      "[[3.43430378]\n",
      " [1.32678992]]\n",
      "Training:   0%|                      | 1614/1000000 [00:18<3:15:29, 85.12it/s, loss_val=28.0140, thetas=-0.6484 4.8883][[-3.42253917]\n",
      " [-1.32224485]]\n",
      "[[3.41081487]\n",
      " [1.31771535]]\n",
      "[[-3.39913074]\n",
      " [-1.31320137]]\n",
      "[[3.38748662]\n",
      " [1.30870284]]\n",
      "[[-3.3758824 ]\n",
      " [-1.30421973]]\n",
      "[[3.36431793]\n",
      " [1.29975198]]\n",
      "[[-3.35279307]\n",
      " [-1.29529953]]\n",
      "[[3.34130769]\n",
      " [1.29086233]]\n",
      "[[-3.32986166]\n",
      " [-1.28644034]]\n",
      "Training:   0%|                      | 1623/1000000 [00:19<3:14:29, 85.55it/s, loss_val=28.0140, thetas=-0.6484 4.8883][[3.31845484]\n",
      " [1.28203349]]\n",
      "[[-3.30708709]\n",
      " [-1.27764173]]\n",
      "[[3.29575828]\n",
      " [1.27326503]]\n",
      "[[-3.28446829]\n",
      " [-1.26890331]]\n",
      "[[3.27321696]\n",
      " [1.26455654]]\n",
      "[[-3.26200418]\n",
      " [-1.26022465]]\n",
      "[[3.25082981]\n",
      " [1.25590761]]\n",
      "[[-3.23969372]\n",
      " [-1.25160535]]\n",
      "[[3.22859578]\n",
      " [1.24731784]]\n",
      "Training:   0%|                      | 1632/1000000 [00:19<3:13:13, 86.11it/s, loss_val=28.0140, thetas=-0.6484 4.8883][[-3.21753586]\n",
      " [-1.24304501]]\n",
      "[[3.20651382]\n",
      " [1.23878681]]\n",
      "[[-3.19552954]\n",
      " [-1.23454321]]\n",
      "[[3.18458288]\n",
      " [1.23031414]]\n",
      "[[-3.17367373]\n",
      " [-1.22609955]]\n",
      "[[3.16280195]\n",
      " [1.22189941]]\n",
      "[[-3.15196741]\n",
      " [-1.21771365]]\n",
      "[[3.14116998]\n",
      " [1.21354224]]\n",
      "[[-3.13040954]\n",
      " [-1.20938511]]\n",
      "Training:   0%|                      | 1641/1000000 [00:19<3:13:23, 86.04it/s, loss_val=28.0140, thetas=-0.6484 4.8883][[3.11968597]\n",
      " [1.20524222]]\n",
      "[[-3.10899912]\n",
      " [-1.20111352]]\n",
      "[[3.09834889]\n",
      " [1.19699897]]\n",
      "[[-3.08773514]\n",
      " [-1.19289851]]\n",
      "[[3.07715775]\n",
      " [1.1888121 ]]\n",
      "[[-3.06661659]\n",
      " [-1.18473969]]\n",
      "[[3.05611155]\n",
      " [1.18068123]]\n",
      "[[-3.04564249]\n",
      " [-1.17663667]]\n",
      "[[3.03520929]\n",
      " [1.17260597]]\n",
      "Training:   0%|                      | 1650/1000000 [00:19<3:13:00, 86.21it/s, loss_val=28.0140, thetas=-0.6484 4.8883][[-3.02481183]\n",
      " [-1.16858907]]\n",
      "[[3.01444999]\n",
      " [1.16458594]]\n",
      "[[-3.00412365]\n",
      " [-1.16059651]]\n",
      "[[2.99383268]\n",
      " [1.15662076]]\n",
      "[[-2.98357696]\n",
      " [-1.15265862]]\n",
      "[[2.97335637]\n",
      " [1.14871005]]\n",
      "[[-2.9631708 ]\n",
      " [-1.14477502]]\n",
      "[[2.95302012]\n",
      " [1.14085346]]\n",
      "[[-2.94290421]\n",
      " [-1.13694533]]\n",
      "Training:   0%|                      | 1659/1000000 [00:19<3:14:25, 85.58it/s, loss_val=28.0140, thetas=-0.6484 4.8883][[2.93282295]\n",
      " [1.1330506 ]]\n",
      "[[-2.92277623]\n",
      " [-1.1291692 ]]\n",
      "[[2.91276393]\n",
      " [1.1253011 ]]\n",
      "[[-2.90278592]\n",
      " [-1.12144626]]\n",
      "[[2.89284209]\n",
      " [1.11760461]]\n",
      "[[-2.88293233]\n",
      " [-1.11377613]]\n",
      "[[2.87305652]\n",
      " [1.10996076]]\n",
      "[[-2.86321453]\n",
      " [-1.10615846]]\n",
      "[[2.85340626]\n",
      " [1.10236919]]\n",
      "Training:   0%|                      | 1668/1000000 [00:19<3:13:59, 85.77it/s, loss_val=28.0140, thetas=-0.6484 4.8883][[-2.84363159]\n",
      " [-1.0985929 ]]\n",
      "[[2.83389041]\n",
      " [1.09482954]]\n",
      "[[-2.82418259]\n",
      " [-1.09107908]]\n",
      "[[2.81450803]\n",
      " [1.08734146]]\n",
      "[[-2.80486661]\n",
      " [-1.08361665]]\n",
      "[[2.79525822]\n",
      " [1.0799046 ]]\n",
      "[[-2.78568274]\n",
      " [-1.07620526]]\n",
      "[[2.77614006]\n",
      " [1.0725186 ]]\n",
      "[[-2.76663008]\n",
      " [-1.06884456]]\n",
      "Training:   0%|                      | 1677/1000000 [00:19<3:12:53, 86.26it/s, loss_val=28.0140, thetas=-0.6484 4.8883][[2.75715267]\n",
      " [1.06518311]]\n",
      "[[-2.74770773]\n",
      " [-1.0615342 ]]\n",
      "[[2.73829514]\n",
      " [1.0578978 ]]\n",
      "[[-2.72891479]\n",
      " [-1.05427385]]\n",
      "[[2.71956658]\n",
      " [1.05066231]]\n",
      "[[-2.7102504 ]\n",
      " [-1.04706315]]\n",
      "[[2.70096612]\n",
      " [1.04347631]]\n",
      "[[-2.69171365]\n",
      " [-1.03990176]]\n",
      "[[2.68249288]\n",
      " [1.03633946]]\n",
      "Training:   0%|                      | 1686/1000000 [00:19<3:13:46, 85.87it/s, loss_val=28.0140, thetas=-0.6484 4.8883][[-2.67330369]\n",
      " [-1.03278936]]\n",
      "[[2.66414598]\n",
      " [1.02925142]]\n",
      "[[-2.65501965]\n",
      " [-1.0257256 ]]\n",
      "[[2.64592457]\n",
      " [1.02221186]]\n",
      "[[-2.63686065]\n",
      " [-1.01871016]]\n",
      "[[2.62782779]\n",
      " [1.01522045]]\n",
      "[[-2.61882586]\n",
      " [-1.0117427 ]]\n",
      "[[2.60985477]\n",
      " [1.00827686]]\n",
      "[[-2.60091441]\n",
      " [-1.00482289]]\n",
      "Training:   0%|                      | 1695/1000000 [00:19<3:14:23, 85.59it/s, loss_val=28.0140, thetas=-0.6484 4.8883][[2.59200468]\n",
      " [1.00138075]]\n",
      "[[-2.58312547]\n",
      " [-0.99795041]]\n",
      "[[2.57427668]\n",
      " [0.99453181]]\n",
      "[[-2.5654582 ]\n",
      " [-0.99112493]]\n",
      "[[2.55666993]\n",
      " [0.98772972]]\n",
      "[[-2.54791176]\n",
      " [-0.98434614]]\n",
      "Training:   0%|                      | 1695/1000000 [00:19<3:14:23, 85.59it/s, loss_val=28.0063, thetas=-0.6505 4.8874][[2.5391836 ]\n",
      " [0.98097415]]\n",
      "[[-2.53048534]\n",
      " [-0.97761371]]\n",
      "[[2.52181687]\n",
      " [0.97426478]]\n",
      "Training:   0%|                      | 1704/1000000 [00:19<3:17:08, 84.40it/s, loss_val=28.0063, thetas=-0.6505 4.8874][[-2.5131781 ]\n",
      " [-0.97092732]]\n",
      "[[2.50456892]\n",
      " [0.9676013 ]]\n",
      "[[-2.49598923]\n",
      " [-0.96428667]]\n",
      "[[2.48743893]\n",
      " [0.9609834 ]]\n",
      "[[-2.47891792]\n",
      " [-0.95769144]]\n",
      "[[2.47042611]\n",
      " [0.95441076]]\n",
      "[[-2.46196338]\n",
      " [-0.95114131]]\n",
      "[[2.45352964]\n",
      " [0.94788307]]\n",
      "[[-2.44512479]\n",
      " [-0.94463599]]\n",
      "Training:   0%|                      | 1713/1000000 [00:20<3:15:05, 85.28it/s, loss_val=28.0063, thetas=-0.6505 4.8874][[2.43674874]\n",
      " [0.94140003]]\n",
      "[[-2.42840137]\n",
      " [-0.93817515]]\n",
      "[[2.42008261]\n",
      " [0.93496133]]\n",
      "[[-2.41179234]\n",
      " [-0.93175851]]\n",
      "[[2.40353047]\n",
      " [0.92856667]]\n",
      "[[-2.3952969 ]\n",
      " [-0.92538575]]\n",
      "[[2.38709153]\n",
      " [0.92221574]]\n",
      "[[-2.37891428]\n",
      " [-0.91905658]]\n",
      "[[2.37076503]\n",
      " [0.91590825]]\n",
      "Training:   0%|                      | 1722/1000000 [00:20<3:14:12, 85.67it/s, loss_val=28.0063, thetas=-0.6505 4.8874][[-2.3626437]\n",
      " [-0.9127707]]\n",
      "[[2.3545502]\n",
      " [0.9096439]]\n",
      "[[-2.34648442]\n",
      " [-0.90652781]]\n",
      "[[2.33844626]\n",
      " [0.9034224 ]]\n",
      "[[-2.33043565]\n",
      " [-0.90032762]]\n",
      "[[2.32245247]\n",
      " [0.89724344]]\n",
      "[[-2.31449665]\n",
      " [-0.89416983]]\n",
      "[[2.30656807]\n",
      " [0.89110675]]\n",
      "[[-2.29866666]\n",
      " [-0.88805416]]\n",
      "Training:   0%|                      | 1731/1000000 [00:20<3:14:08, 85.70it/s, loss_val=28.0063, thetas=-0.6505 4.8874][[2.29079231]\n",
      " [0.88501203]]\n",
      "[[-2.28294494]\n",
      " [-0.88198032]]\n",
      "[[2.27512445]\n",
      " [0.878959  ]]\n",
      "[[-2.26733075]\n",
      " [-0.87594802]]\n",
      "[[2.25956375]\n",
      " [0.87294736]]\n",
      "[[-2.25182336]\n",
      " [-0.86995698]]\n",
      "[[2.24410948]\n",
      " [0.86697684]]\n",
      "[[-2.23642202]\n",
      " [-0.86400691]]\n",
      "[[2.2287609 ]\n",
      " [0.86104716]]\n",
      "Training:   0%|                      | 1740/1000000 [00:20<3:14:05, 85.72it/s, loss_val=28.0063, thetas=-0.6505 4.8874][[-2.22112603]\n",
      " [-0.85809754]]\n",
      "[[2.2135173 ]\n",
      " [0.85515803]]\n",
      "[[-2.20593465]\n",
      " [-0.85222859]]\n",
      "[[2.19837796]\n",
      " [0.84930918]]\n",
      "[[-2.19084717]\n",
      " [-0.84639978]]\n",
      "[[2.18334217]\n",
      " [0.84350034]]\n",
      "[[-2.17586288]\n",
      " [-0.84061083]]\n",
      "[[2.16840921]\n",
      " [0.83773122]]\n",
      "[[-2.16098108]\n",
      " [-0.83486148]]\n",
      "Training:   0%|                      | 1749/1000000 [00:20<3:12:56, 86.23it/s, loss_val=28.0063, thetas=-0.6505 4.8874][[2.15357839]\n",
      " [0.83200156]]\n",
      "[[-2.14620106]\n",
      " [-0.82915145]]\n",
      "[[2.138849  ]\n",
      " [0.82631109]]\n",
      "[[-2.13152213]\n",
      " [-0.82348047]]\n",
      "[[2.12422036]\n",
      " [0.82065954]]\n",
      "[[-2.1169436 ]\n",
      " [-0.81784828]]\n",
      "[[2.10969176]\n",
      " [0.81504665]]\n",
      "[[-2.10246477]\n",
      " [-0.81225461]]\n",
      "[[2.09526254]\n",
      " [0.80947214]]\n",
      "[[-2.08808498]\n",
      " [-0.8066992 ]]\n",
      "Training:   0%|                      | 1759/1000000 [00:20<3:10:25, 87.37it/s, loss_val=28.0063, thetas=-0.6505 4.8874][[2.080932  ]\n",
      " [0.80393576]]\n",
      "[[-2.07380353]\n",
      " [-0.80118178]]\n",
      "[[2.06669948]\n",
      " [0.79843724]]\n",
      "[[-2.05961976]\n",
      " [-0.79570211]]\n",
      "[[2.0525643 ]\n",
      " [0.79297634]]\n",
      "[[-2.045533  ]\n",
      " [-0.79025991]]\n",
      "[[2.0385258 ]\n",
      " [0.78755278]]\n",
      "[[-2.03154259]\n",
      " [-0.78485493]]\n",
      "[[2.02458331]\n",
      " [0.78216632]]\n",
      "Training:   0%|                      | 1768/1000000 [00:20<3:12:36, 86.38it/s, loss_val=28.0063, thetas=-0.6505 4.8874][[-2.01764787]\n",
      " [-0.77948692]]\n",
      "[[2.01073618]\n",
      " [0.7768167 ]]\n",
      "[[-2.00384818]\n",
      " [-0.77415562]]\n",
      "[[1.99698377]\n",
      " [0.77150366]]\n",
      "[[-1.99014287]\n",
      " [-0.76886079]]\n",
      "[[1.98332541]\n",
      " [0.76622697]]\n",
      "[[-1.9765313 ]\n",
      " [-0.76360217]]\n",
      "[[1.96976046]\n",
      " [0.76098636]]\n",
      "[[-1.96301282]\n",
      " [-0.75837952]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:   0%|                      | 1777/1000000 [00:20<3:12:12, 86.56it/s, loss_val=28.0063, thetas=-0.6505 4.8874][[1.9562883]\n",
      " [0.7557816]]\n",
      "[[-1.94958681]\n",
      " [-0.75319258]]\n",
      "[[1.94290827]\n",
      " [0.75061244]]\n",
      "[[-1.93625262]\n",
      " [-0.74804113]]\n",
      "[[1.92961976]\n",
      " [0.74547863]]\n",
      "[[-1.92300963]\n",
      " [-0.7429249 ]]\n",
      "[[1.91642214]\n",
      " [0.74037993]]\n",
      "[[-1.90985722]\n",
      " [-0.73784367]]\n",
      "[[1.90331478]\n",
      " [0.7353161 ]]\n",
      "Training:   0%|                      | 1786/1000000 [00:20<3:11:04, 87.07it/s, loss_val=28.0063, thetas=-0.6505 4.8874][[-1.89679476]\n",
      " [-0.73279719]]\n",
      "[[1.89029707]\n",
      " [0.73028691]]\n",
      "[[-1.88382164]\n",
      " [-0.72778523]]\n",
      "[[1.87736839]\n",
      " [0.72529212]]\n",
      "[[-1.87093725]\n",
      " [-0.72280755]]\n",
      "[[1.86452814]\n",
      " [0.72033149]]\n",
      "[[-1.85814099]\n",
      " [-0.71786391]]\n",
      "[[1.85177571]\n",
      " [0.71540479]]\n",
      "[[-1.84543224]\n",
      " [-0.71295408]]\n",
      "[[1.8391105 ]\n",
      " [0.71051178]]\n",
      "Training:   0%|                      | 1796/1000000 [00:21<3:09:07, 87.97it/s, loss_val=28.0063, thetas=-0.6505 4.8874][[-1.83281042]\n",
      " [-0.70807784]]\n",
      "[[1.82653192]\n",
      " [0.70565224]]\n",
      "[[-1.82027492]\n",
      " [-0.70323494]]\n",
      "[[1.81403936]\n",
      " [0.70082593]]\n",
      "[[-1.80782516]\n",
      " [-0.69842517]]\n",
      "Training:   0%|                      | 1796/1000000 [00:21<3:09:07, 87.97it/s, loss_val=28.0024, thetas=-0.6521 4.8868][[1.80163225]\n",
      " [0.69603264]]\n",
      "[[-1.79546055]\n",
      " [-0.6936483 ]]\n",
      "[[1.78930999]\n",
      " [0.69127213]]\n",
      "[[-1.78318051]\n",
      " [-0.68890409]]\n",
      "Training:   0%|                      | 1805/1000000 [00:21<3:13:53, 85.80it/s, loss_val=28.0024, thetas=-0.6521 4.8868][[1.77707202]\n",
      " [0.68654417]]\n",
      "[[-1.77098445]\n",
      " [-0.68419234]]\n",
      "[[1.76491774]\n",
      " [0.68184856]]\n",
      "[[-1.75887182]\n",
      " [-0.67951281]]\n",
      "[[1.7528466 ]\n",
      " [0.67718506]]\n",
      "[[-1.74684202]\n",
      " [-0.67486528]]\n",
      "[[1.74085801]\n",
      " [0.67255346]]\n",
      "[[-1.73489451]\n",
      " [-0.67024955]]\n",
      "[[1.72895143]\n",
      " [0.66795353]]\n",
      "Training:   0%|                      | 1814/1000000 [00:21<3:13:21, 86.04it/s, loss_val=28.0024, thetas=-0.6521 4.8868][[-1.7230287 ]\n",
      " [-0.66566538]]\n",
      "[[1.71712627]\n",
      " [0.66338507]]\n",
      "[[-1.71124406]\n",
      " [-0.66111256]]\n",
      "[[1.705382  ]\n",
      " [0.65884785]]\n",
      "[[-1.69954001]\n",
      " [-0.65659089]]\n",
      "[[1.69371804]\n",
      " [0.65434166]]\n",
      "[[-1.68791602]\n",
      " [-0.65210014]]\n",
      "[[1.68213387]\n",
      " [0.64986629]]\n",
      "[[-1.67637153]\n",
      " [-0.6476401 ]]\n",
      "Training:   0%|                      | 1823/1000000 [00:21<3:15:16, 85.19it/s, loss_val=28.0024, thetas=-0.6521 4.8868][[1.67062892]\n",
      " [0.64542154]]\n",
      "[[-1.66490599]\n",
      " [-0.64321057]]\n",
      "[[1.65920267]\n",
      " [0.64100718]]\n",
      "[[-1.65351888]\n",
      " [-0.63881134]]\n",
      "[[1.64785456]\n",
      " [0.63662302]]\n",
      "[[-1.64220964]\n",
      " [-0.63444219]]\n",
      "[[1.63658407]\n",
      " [0.63226884]]\n",
      "[[-1.63097776]\n",
      " [-0.63010293]]\n",
      "[[1.62539066]\n",
      " [0.62794444]]\n",
      "Training:   0%|                      | 1832/1000000 [00:21<3:14:19, 85.61it/s, loss_val=28.0024, thetas=-0.6521 4.8868][[-1.6198227 ]\n",
      " [-0.62579334]]\n",
      "[[1.61427381]\n",
      " [0.62364961]]\n",
      "[[-1.60874393]\n",
      " [-0.62151323]]\n",
      "[[1.60323299]\n",
      " [0.61938417]]\n",
      "[[-1.59774093]\n",
      " [-0.61726239]]\n",
      "[[1.59226769]\n",
      " [0.61514789]]\n",
      "[[-1.58681319]\n",
      " [-0.61304063]]\n",
      "[[1.58137738]\n",
      " [0.61094059]]\n",
      "[[-1.57596019]\n",
      " [-0.60884774]]\n",
      "Training:   0%|                      | 1841/1000000 [00:21<3:14:46, 85.41it/s, loss_val=28.0024, thetas=-0.6521 4.8868][[1.57056156]\n",
      " [0.60676207]]\n",
      "[[-1.56518142]\n",
      " [-0.60468353]]\n",
      "[[1.55981971]\n",
      " [0.60261212]]\n",
      "[[-1.55447637]\n",
      " [-0.6005478 ]]\n",
      "[[1.54915133]\n",
      " [0.59849056]]\n",
      "[[-1.54384454]\n",
      " [-0.59644036]]\n",
      "[[1.53855592]\n",
      " [0.59439718]]\n",
      "[[-1.53328542]\n",
      " [-0.59236101]]\n",
      "[[1.52803298]\n",
      " [0.59033181]]\n",
      "Training:   0%|                      | 1850/1000000 [00:21<3:15:04, 85.28it/s, loss_val=28.0024, thetas=-0.6521 4.8868][[-1.52279853]\n",
      " [-0.58830956]]\n",
      "[[1.517582  ]\n",
      " [0.58629424]]\n",
      "[[-1.51238335]\n",
      " [-0.58428582]]\n",
      "[[1.50720251]\n",
      " [0.58228428]]\n",
      "[[-1.50203942]\n",
      " [-0.5802896 ]]\n",
      "[[1.49689401]\n",
      " [0.57830175]]\n",
      "[[-1.49176623]\n",
      " [-0.57632071]]\n",
      "[[1.48665601]\n",
      " [0.57434646]]\n",
      "[[-1.4815633 ]\n",
      " [-0.57237897]]\n",
      "Training:   0%|                      | 1859/1000000 [00:21<3:13:38, 85.91it/s, loss_val=28.0024, thetas=-0.6521 4.8868][[1.47648803]\n",
      " [0.57041822]]\n",
      "[[-1.47143015]\n",
      " [-0.56846419]]\n",
      "[[1.4663896 ]\n",
      " [0.56651685]]\n",
      "[[-1.46136632]\n",
      " [-0.56457618]]\n",
      "[[1.45636024]\n",
      " [0.56264216]]\n",
      "[[-1.45137131]\n",
      " [-0.56071476]]\n",
      "[[1.44639947]\n",
      " [0.55879397]]\n",
      "[[-1.44144466]\n",
      " [-0.55687976]]\n",
      "[[1.43650683]\n",
      " [0.5549721 ]]\n",
      "Training:   0%|                      | 1868/1000000 [00:21<3:13:11, 86.11it/s, loss_val=28.0024, thetas=-0.6521 4.8868][[-1.43158591]\n",
      " [-0.55307098]]\n",
      "[[1.42668185]\n",
      " [0.55117637]]\n",
      "[[-1.42179459]\n",
      " [-0.54928826]]\n",
      "[[1.41692407]\n",
      " [0.54740661]]\n",
      "[[-1.41207023]\n",
      " [-0.5455314 ]]\n",
      "[[1.40723302]\n",
      " [0.54366262]]\n",
      "[[-1.40241238]\n",
      " [-0.54180024]]\n",
      "[[1.39760826]\n",
      " [0.53994424]]\n",
      "[[-1.39282059]\n",
      " [-0.5380946 ]]\n",
      "Training:   0%|                      | 1877/1000000 [00:21<3:12:18, 86.51it/s, loss_val=28.0024, thetas=-0.6521 4.8868][[1.38804932]\n",
      " [0.5362513 ]]\n",
      "[[-1.3832944 ]\n",
      " [-0.53441431]]\n",
      "[[1.37855577]\n",
      " [0.53258361]]\n",
      "[[-1.37383337]\n",
      " [-0.53075918]]\n",
      "[[1.36912714]\n",
      " [0.52894101]]\n",
      "[[-1.36443704]\n",
      " [-0.52712906]]\n",
      "[[1.35976301]\n",
      " [0.52532332]]\n",
      "[[-1.35510498]\n",
      " [-0.52352376]]\n",
      "[[1.35046291]\n",
      " [0.52173037]]\n",
      "Training:   0%|                      | 1886/1000000 [00:22<3:13:21, 86.04it/s, loss_val=28.0024, thetas=-0.6521 4.8868][[-1.34583675]\n",
      " [-0.51994313]]\n",
      "[[1.34122643]\n",
      " [0.518162  ]]\n",
      "[[-1.33663191]\n",
      " [-0.51638698]]\n",
      "[[1.33205312]\n",
      " [0.51461803]]\n",
      "[[-1.32749002]\n",
      " [-0.51285515]]\n",
      "[[1.32294255]\n",
      " [0.51109831]]\n",
      "[[-1.31841066]\n",
      " [-0.50934748]]\n",
      "[[1.31389429]\n",
      " [0.50760265]]\n",
      "[[-1.3093934]\n",
      " [-0.5058638]]\n",
      "Training:   0%|                      | 1895/1000000 [00:22<3:14:33, 85.50it/s, loss_val=28.0024, thetas=-0.6521 4.8868][[1.30490792]\n",
      " [0.50413091]]\n",
      "[[-1.30043781]\n",
      " [-0.50240395]]\n",
      "[[1.29598301]\n",
      " [0.50068291]]\n",
      "[[-1.29154347]\n",
      " [-0.49896776]]\n",
      "[[1.28711914]\n",
      " [0.49725849]]\n",
      "[[-1.28270997]\n",
      " [-0.49555507]]\n",
      "Training:   0%|                      | 1895/1000000 [00:22<3:14:33, 85.50it/s, loss_val=28.0004, thetas=-0.6532 4.8864][[1.2783159 ]\n",
      " [0.49385749]]\n",
      "[[-1.27393688]\n",
      " [-0.49216573]]\n",
      "[[1.26957286]\n",
      " [0.49047976]]\n",
      "Training:   0%|                      | 1904/1000000 [00:22<3:17:42, 84.14it/s, loss_val=28.0004, thetas=-0.6532 4.8864][[-1.26522379]\n",
      " [-0.48879956]]\n",
      "[[1.26088962]\n",
      " [0.48712512]]\n",
      "[[-1.2565703 ]\n",
      " [-0.48545642]]\n",
      "[[1.25226578]\n",
      " [0.48379343]]\n",
      "[[-1.247976  ]\n",
      " [-0.48213614]]\n",
      "[[1.24370091]\n",
      " [0.48048453]]\n",
      "[[-1.23944047]\n",
      " [-0.47883858]]\n",
      "[[1.23519463]\n",
      " [0.47719826]]\n",
      "[[-1.23096333]\n",
      " [-0.47556356]]\n",
      "Training:   0%|                      | 1913/1000000 [00:22<3:16:34, 84.62it/s, loss_val=28.0004, thetas=-0.6532 4.8864][[1.22674652]\n",
      " [0.47393446]]\n",
      "[[-1.22254416]\n",
      " [-0.47231095]]\n",
      "[[1.21835619]\n",
      " [0.47069299]]\n",
      "[[-1.21418257]\n",
      " [-0.46908058]]\n",
      "[[1.21002325]\n",
      " [0.46747369]]\n",
      "[[-1.20587818]\n",
      " [-0.46587231]]\n",
      "[[1.2017473 ]\n",
      " [0.46427641]]\n",
      "[[-1.19763058]\n",
      " [-0.46268597]]\n",
      "[[1.19352796]\n",
      " [0.46110099]]\n",
      "Training:   0%|                      | 1922/1000000 [00:22<3:14:07, 85.69it/s, loss_val=28.0004, thetas=-0.6532 4.8864][[-1.18943939]\n",
      " [-0.45952144]]\n",
      "[[1.18536483]\n",
      " [0.45794729]]\n",
      "[[-1.18130423]\n",
      " [-0.45637854]]\n",
      "[[1.17725754]\n",
      " [0.45481516]]\n",
      "[[-1.17322471]\n",
      " [-0.45325714]]\n",
      "[[1.16920569]\n",
      " [0.45170446]]\n",
      "[[-1.16520044]\n",
      " [-0.45015709]]\n",
      "[[1.16120891]\n",
      " [0.44861503]]\n",
      "[[-1.15723106]\n",
      " [-0.44707825]]\n",
      "Training:   0%|                      | 1931/1000000 [00:22<3:14:37, 85.47it/s, loss_val=28.0004, thetas=-0.6532 4.8864][[1.15326683]\n",
      " [0.44554673]]\n",
      "[[-1.14931618]\n",
      " [-0.44402046]]\n",
      "[[1.14537907]\n",
      " [0.44249941]]\n",
      "[[-1.14145544]\n",
      " [-0.44098358]]\n",
      "[[1.13754526]\n",
      " [0.43947294]]\n",
      "[[-1.13364846]\n",
      " [-0.43796748]]\n",
      "[[1.12976502]\n",
      " [0.43646717]]\n",
      "[[-1.12589488]\n",
      " [-0.434972  ]]\n",
      "[[1.122038  ]\n",
      " [0.43348195]]\n",
      "Training:   0%|                      | 1940/1000000 [00:22<3:13:52, 85.80it/s, loss_val=28.0004, thetas=-0.6532 4.8864][[-1.11819433]\n",
      " [-0.43199701]]\n",
      "[[1.11436383]\n",
      " [0.43051716]]\n",
      "[[-1.11054645]\n",
      " [-0.42904237]]\n",
      "[[1.10674214]\n",
      " [0.42757264]]\n",
      "[[-1.10295087]\n",
      " [-0.42610794]]\n",
      "[[1.09917258]\n",
      " [0.42464826]]\n",
      "[[-1.09540724]\n",
      " [-0.42319358]]\n",
      "[[1.0916548 ]\n",
      " [0.42174388]]\n",
      "[[-1.08791521]\n",
      " [-0.42029915]]\n",
      "Training:   0%|                      | 1949/1000000 [00:22<3:13:53, 85.79it/s, loss_val=28.0004, thetas=-0.6532 4.8864][[1.08418843]\n",
      " [0.41885936]]\n",
      "[[-1.08047442]\n",
      " [-0.41742451]]\n",
      "[[1.07677313]\n",
      " [0.41599458]]\n",
      "[[-1.07308452]\n",
      " [-0.41456954]]\n",
      "[[1.06940855]\n",
      " [0.41314938]]\n",
      "[[-1.06574517]\n",
      " [-0.41173409]]\n",
      "[[1.06209433]\n",
      " [0.41032365]]\n",
      "[[-1.05845601]\n",
      " [-0.40891804]]\n",
      "[[1.05483015]\n",
      " [0.40751724]]\n",
      "Training:   0%|                      | 1958/1000000 [00:22<3:13:59, 85.75it/s, loss_val=28.0004, thetas=-0.6532 4.8864][[-1.0512167 ]\n",
      " [-0.40612125]]\n",
      "[[1.04761564]\n",
      " [0.40473003]]\n",
      "[[-1.04402691]\n",
      " [-0.40334358]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.04045048]\n",
      " [0.40196188]]\n",
      "[[-1.0368863 ]\n",
      " [-0.40058492]]\n",
      "[[1.03333432]\n",
      " [0.39921267]]\n",
      "[[-1.02979452]\n",
      " [-0.39784512]]\n",
      "[[1.02626684]\n",
      " [0.39648225]]\n",
      "[[-1.02275124]\n",
      " [-0.39512406]]\n",
      "Training:   0%|                      | 1967/1000000 [00:23<3:13:58, 85.75it/s, loss_val=28.0004, thetas=-0.6532 4.8864][[1.01924769]\n",
      " [0.39377052]]\n",
      "[[-1.01575614]\n",
      " [-0.39242161]]\n",
      "[[1.01227655]\n",
      " [0.39107732]]\n",
      "[[-1.00880888]\n",
      " [-0.38973764]]\n",
      "[[1.00535309]\n",
      " [0.38840255]]\n",
      "[[-1.00190914]\n",
      " [-0.38707204]]\n",
      "[[0.99847699]\n",
      " [0.38574608]]\n",
      "[[-0.99505659]\n",
      " [-0.38442466]]\n",
      "[[0.99164791]\n",
      " [0.38310777]]\n",
      "Training:   0%|                      | 1976/1000000 [00:23<3:13:57, 85.76it/s, loss_val=28.0004, thetas=-0.6532 4.8864][[-0.98825091]\n",
      " [-0.38179539]]\n",
      "[[0.98486554]\n",
      " [0.3804875 ]]\n",
      "[[-0.98149177]\n",
      " [-0.3791841 ]]\n",
      "[[0.97812956]\n",
      " [0.37788516]]\n",
      "[[-0.97477886]\n",
      " [-0.37659067]]\n",
      "[[0.97143964]\n",
      " [0.37530062]]\n",
      "[[-0.96811187]\n",
      " [-0.37401498]]\n",
      "[[0.96479549]\n",
      " [0.37273375]]\n",
      "[[-0.96149047]\n",
      " [-0.37145691]]\n",
      "Training:   0%|                      | 1985/1000000 [00:23<3:12:50, 86.25it/s, loss_val=28.0004, thetas=-0.6532 4.8864][[0.95819677]\n",
      " [0.37018444]]\n",
      "[[-0.95491436]\n",
      " [-0.36891633]]\n",
      "[[0.95164319]\n",
      " [0.36765257]]\n",
      "[[-0.94838323]\n",
      " [-0.36639313]]\n",
      "[[0.94513443]\n",
      " [0.36513801]]\n",
      "[[-0.94189677]\n",
      " [-0.36388719]]\n",
      "[[0.93867019]\n",
      " [0.36264065]]\n",
      "[[-0.93545467]\n",
      " [-0.36139838]]\n",
      "[[0.93225016]\n",
      " [0.36016037]]\n",
      "Training:   0%|                      | 1994/1000000 [00:23<3:12:37, 86.35it/s, loss_val=28.0004, thetas=-0.6532 4.8864][[-0.92905663]\n",
      " [-0.3589266 ]]\n",
      "[[0.92587404]\n",
      " [0.35769706]]\n",
      "[[-0.92270236]\n",
      " [-0.35647172]]\n",
      "[[0.91954153]\n",
      " [0.35525059]]\n",
      "[[-0.91639154]\n",
      " [-0.35403364]]\n",
      "[[0.91325233]\n",
      " [0.35282086]]\n",
      "[[-0.91012388]\n",
      " [-0.35161223]]\n",
      "Training:   0%|                      | 1994/1000000 [00:23<3:12:37, 86.35it/s, loss_val=27.9994, thetas=-0.6540 4.8861][[0.90700615]\n",
      " [0.35040774]]\n",
      "[[-0.9038991 ]\n",
      " [-0.34920738]]\n",
      "Training:   0%|                      | 2003/1000000 [00:23<3:14:07, 85.68it/s, loss_val=27.9994, thetas=-0.6540 4.8861][[0.90080269]\n",
      " [0.34801113]]\n",
      "[[-0.89771688]\n",
      " [-0.34681897]]\n",
      "[[0.89464165]\n",
      " [0.34563091]]\n",
      "[[-0.89157695]\n",
      " [-0.34444691]]\n",
      "[[0.88852275]\n",
      " [0.34326697]]\n",
      "[[-0.88547902]\n",
      " [-0.34209107]]\n",
      "[[0.88244571]\n",
      " [0.34091919]]\n",
      "[[-0.87942279]\n",
      " [-0.33975134]]\n",
      "[[0.87641023]\n",
      " [0.33858748]]\n",
      "Training:   0%|                      | 2012/1000000 [00:23<3:14:03, 85.71it/s, loss_val=27.9994, thetas=-0.6540 4.8861][[-0.87340798]\n",
      " [-0.33742761]]\n",
      "[[0.87041602]\n",
      " [0.33627171]]\n",
      "[[-0.86743431]\n",
      " [-0.33511977]]\n",
      "[[0.86446282]\n",
      " [0.33397178]]\n",
      "[[-0.8615015 ]\n",
      " [-0.33282772]]\n",
      "[[0.85855033]\n",
      " [0.33168758]]\n",
      "[[-0.85560927]\n",
      " [-0.33055135]]\n",
      "[[0.85267828]\n",
      " [0.32941901]]\n",
      "[[-0.84975733]\n",
      " [-0.32829055]]\n",
      "Training:   0%|                      | 2021/1000000 [00:23<3:13:28, 85.97it/s, loss_val=27.9994, thetas=-0.6540 4.8861][[0.84684639]\n",
      " [0.32716595]]\n",
      "[[-0.84394542]\n",
      " [-0.32604521]]\n",
      "[[0.84105439]\n",
      " [0.3249283 ]]\n",
      "[[-0.83817326]\n",
      " [-0.32381522]]\n",
      "[[0.835302  ]\n",
      " [0.32270595]]\n",
      "[[-0.83244058]\n",
      " [-0.32160049]]\n",
      "[[0.82958896]\n",
      " [0.32049881]]\n",
      "[[-0.82674711]\n",
      " [-0.3194009 ]]\n",
      "[[0.82391499]\n",
      " [0.31830676]]\n",
      "Training:   0%|                      | 2030/1000000 [00:23<3:12:29, 86.41it/s, loss_val=27.9994, thetas=-0.6540 4.8861][[-0.82109257]\n",
      " [-0.31721636]]\n",
      "[[0.81827983]\n",
      " [0.3161297 ]]\n",
      "[[-0.81547671]\n",
      " [-0.31504676]]\n",
      "[[0.81268321]\n",
      " [0.31396753]]\n",
      "[[-0.80989927]\n",
      " [-0.312892  ]]\n",
      "[[0.80712486]\n",
      " [0.31182016]]\n",
      "[[-0.80435996]\n",
      " [-0.31075198]]\n",
      "[[0.80160454]\n",
      " [0.30968746]]\n",
      "[[-0.79885855]\n",
      " [-0.30862659]]\n",
      "Training:   0%|                      | 2039/1000000 [00:23<3:13:19, 86.03it/s, loss_val=27.9994, thetas=-0.6540 4.8861][[0.79612197]\n",
      " [0.30756936]]\n",
      "[[-0.79339476]\n",
      " [-0.30651574]]\n",
      "[[0.7906769 ]\n",
      " [0.30546574]]\n",
      "[[-0.78796834]\n",
      " [-0.30441933]]\n",
      "[[0.78526907]\n",
      " [0.30337651]]\n",
      "[[-0.78257904]\n",
      " [-0.30233726]]\n",
      "[[0.77989822]\n",
      " [0.30130157]]\n",
      "[[-0.77722659]\n",
      " [-0.30026942]]\n",
      "[[0.77456411]\n",
      " [0.29924081]]\n",
      "Training:   0%|                      | 2048/1000000 [00:23<3:12:57, 86.20it/s, loss_val=27.9994, thetas=-0.6540 4.8861][[-0.77191075]\n",
      " [-0.29821573]]\n",
      "[[0.76926649]\n",
      " [0.29719416]]\n",
      "[[-0.76663127]\n",
      " [-0.29617609]]\n",
      "[[0.76400509]\n",
      " [0.2951615 ]]\n",
      "[[-0.7613879 ]\n",
      " [-0.29415039]]\n",
      "[[0.75877968]\n",
      " [0.29314275]]\n",
      "[[-0.7561804 ]\n",
      " [-0.29213855]]\n",
      "[[0.75359001]\n",
      " [0.2911378 ]]\n",
      "[[-0.7510085 ]\n",
      " [-0.29014047]]\n",
      "Training:   0%|                      | 2057/1000000 [00:24<3:13:47, 85.82it/s, loss_val=27.9994, thetas=-0.6540 4.8861][[0.74843584]\n",
      " [0.28914656]]\n",
      "[[-0.74587199]\n",
      " [-0.28815606]]\n",
      "[[0.74331692]\n",
      " [0.28716895]]\n",
      "[[-0.7407706 ]\n",
      " [-0.28618522]]\n",
      "[[0.738233  ]\n",
      " [0.28520486]]\n",
      "[[-0.7357041 ]\n",
      " [-0.28422785]]\n",
      "[[0.73318386]\n",
      " [0.2832542 ]]\n",
      "[[-0.73067226]\n",
      " [-0.28228388]]\n",
      "[[0.72816926]\n",
      " [0.28131688]]\n",
      "Training:   0%|                      | 2066/1000000 [00:24<3:13:49, 85.81it/s, loss_val=27.9994, thetas=-0.6540 4.8861][[-0.72567483]\n",
      " [-0.2803532 ]]\n",
      "[[0.72318895]\n",
      " [0.27939282]]\n",
      "[[-0.72071158]\n",
      " [-0.27843573]]\n",
      "[[0.7182427 ]\n",
      " [0.27748191]]\n",
      "[[-0.71578228]\n",
      " [-0.27653137]]\n",
      "[[0.71333028]\n",
      " [0.27558408]]\n",
      "[[-0.71088669]\n",
      " [-0.27464003]]\n",
      "[[0.70845146]\n",
      " [0.27369922]]\n",
      "[[-0.70602458]\n",
      " [-0.27276163]]\n",
      "Training:   0%|                      | 2075/1000000 [00:24<3:13:51, 85.79it/s, loss_val=27.9994, thetas=-0.6540 4.8861][[0.70360601]\n",
      " [0.27182726]]\n",
      "[[-0.70119573]\n",
      " [-0.27089608]]\n",
      "[[0.6987937 ]\n",
      " [0.26996809]]\n",
      "[[-0.69639991]\n",
      " [-0.26904329]]\n",
      "[[0.69401431]\n",
      " [0.26812165]]\n",
      "[[-0.69163688]\n",
      " [-0.26720317]]\n",
      "[[0.6892676 ]\n",
      " [0.26628783]]\n",
      "[[-0.68690644]\n",
      " [-0.26537563]]\n",
      "[[0.68455336]\n",
      " [0.26446656]]\n",
      "Training:   0%|                      | 2084/1000000 [00:24<3:16:05, 84.82it/s, loss_val=27.9994, thetas=-0.6540 4.8861][[-0.68220834]\n",
      " [-0.2635606 ]]\n",
      "[[0.67987136]\n",
      " [0.26265774]]\n",
      "[[-0.67754238]\n",
      " [-0.26175798]]\n",
      "[[0.67522138]\n",
      " [0.26086129]]\n",
      "[[-0.67290834]\n",
      " [-0.25996768]]\n",
      "[[0.67060321]\n",
      " [0.25907714]]\n",
      "[[-0.66830598]\n",
      " [-0.25818964]]\n",
      "[[0.66601662]\n",
      " [0.25730518]]\n",
      "[[-0.66373511]\n",
      " [-0.25642375]]\n",
      "Training:   0%|                      | 2093/1000000 [00:24<3:16:32, 84.62it/s, loss_val=27.9994, thetas=-0.6540 4.8861][[0.66146141]\n",
      " [0.25554534]]\n",
      "[[-0.6591955 ]\n",
      " [-0.25466994]]\n",
      "[[0.65693735]\n",
      " [0.25379754]]\n",
      "[[-0.65468693]\n",
      " [-0.25292813]]\n",
      "[[0.65244423]\n",
      " [0.25206169]]\n",
      "[[-0.6502092 ]\n",
      " [-0.25119823]]\n",
      "[[0.64798184]\n",
      " [0.25033772]]\n",
      "[[-0.6457621 ]\n",
      " [-0.24948016]]\n",
      "Training:   0%|                      | 2093/1000000 [00:24<3:16:32, 84.62it/s, loss_val=27.9989, thetas=-0.6546 4.8859][[0.64354997]\n",
      " [0.24862554]]\n",
      "Training:   0%|                      | 2102/1000000 [00:24<3:16:51, 84.48it/s, loss_val=27.9989, thetas=-0.6546 4.8859][[-0.64134542]\n",
      " [-0.24777384]]\n",
      "[[0.63914841]\n",
      " [0.24692506]]\n",
      "[[-0.63695894]\n",
      " [-0.24607919]]\n",
      "[[0.63477696]\n",
      " [0.24523622]]\n",
      "[[-0.63260246]\n",
      " [-0.24439613]]\n",
      "[[0.63043541]\n",
      " [0.24355893]]\n",
      "[[-0.62827578]\n",
      " [-0.24272459]]\n",
      "[[0.62612355]\n",
      " [0.24189311]]\n",
      "[[-0.62397869]\n",
      " [-0.24106448]]\n",
      "Training:   0%|                      | 2111/1000000 [00:24<3:15:58, 84.86it/s, loss_val=27.9989, thetas=-0.6546 4.8859][[0.62184118]\n",
      " [0.24023868]]\n",
      "[[-0.61971099]\n",
      " [-0.23941572]]\n",
      "[[0.6175881 ]\n",
      " [0.23859557]]\n",
      "[[-0.61547248]\n",
      " [-0.23777823]]\n",
      "[[0.61336411]\n",
      " [0.2369637 ]]\n",
      "[[-0.61126296]\n",
      " [-0.23615195]]\n",
      "[[0.60916901]\n",
      " [0.23534299]]\n",
      "[[-0.60708223]\n",
      " [-0.23453679]]\n",
      "[[0.6050026 ]\n",
      " [0.23373336]]\n",
      "Training:   0%|                      | 2120/1000000 [00:24<3:16:27, 84.65it/s, loss_val=27.9989, thetas=-0.6546 4.8859][[-0.60293009]\n",
      " [-0.23293268]]\n",
      "[[0.60086469]\n",
      " [0.23213474]]\n",
      "[[-0.59880636]\n",
      " [-0.23133954]]\n",
      "[[0.59675508]\n",
      " [0.23054706]]\n",
      "[[-0.59471083]\n",
      " [-0.22975729]]\n",
      "[[0.59267357]\n",
      " [0.22897023]]\n",
      "[[-0.5906433 ]\n",
      " [-0.22818587]]\n",
      "[[0.58861999]\n",
      " [0.22740419]]\n",
      "[[-0.5866036 ]\n",
      " [-0.22662519]]\n",
      "Training:   0%|                      | 2129/1000000 [00:24<3:15:51, 84.91it/s, loss_val=27.9989, thetas=-0.6546 4.8859][[0.58459412]\n",
      " [0.22584886]]\n",
      "[[-0.58259153]\n",
      " [-0.22507519]]\n",
      "[[0.5805958 ]\n",
      " [0.22430417]]\n",
      "[[-0.5786069 ]\n",
      " [-0.22353579]]\n",
      "[[0.57662481]\n",
      " [0.22277004]]\n",
      "[[-0.57464952]\n",
      " [-0.22200692]]\n",
      "[[0.57268099]\n",
      " [0.22124641]]\n",
      "[[-0.57071921]\n",
      " [-0.2204885 ]]\n",
      "[[0.56876414]\n",
      " [0.21973319]]\n",
      "Training:   0%|                      | 2138/1000000 [00:25<3:14:43, 85.41it/s, loss_val=27.9989, thetas=-0.6546 4.8859][[-0.56681578]\n",
      " [-0.21898047]]\n",
      "[[0.56487408]\n",
      " [0.21823033]]\n",
      "[[-0.56293904]\n",
      " [-0.21748276]]\n",
      "[[0.56101063]\n",
      " [0.21673774]]\n",
      "[[-0.55908882]\n",
      " [-0.21599528]]\n",
      "[[0.5571736 ]\n",
      " [0.21525537]]\n",
      "[[-0.55526494]\n",
      " [-0.21451799]]\n",
      "[[0.55336282]\n",
      " [0.21378313]]\n",
      "[[-0.55146721]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [-0.21305079]]\n",
      "Training:   0%|                      | 2147/1000000 [00:25<3:15:35, 85.03it/s, loss_val=27.9989, thetas=-0.6546 4.8859][[0.54957809]\n",
      " [0.21232096]]\n",
      "[[-0.54769545]\n",
      " [-0.21159363]]\n",
      "[[0.54581926]\n",
      " [0.21086879]]\n",
      "[[-0.54394949]\n",
      " [-0.21014644]]\n",
      "[[0.54208613]\n",
      " [0.20942656]]\n",
      "[[-0.54022915]\n",
      " [-0.20870914]]\n",
      "[[0.53837853]\n",
      " [0.20799419]]\n",
      "[[-0.53653426]\n",
      " [-0.20728168]]\n",
      "[[0.5346963 ]\n",
      " [0.20657161]]\n",
      "Training:   0%|                      | 2156/1000000 [00:25<3:15:38, 85.01it/s, loss_val=27.9989, thetas=-0.6546 4.8859][[-0.53286463]\n",
      " [-0.20586398]]\n",
      "[[0.53103925]\n",
      " [0.20515876]]\n",
      "[[-0.52922011]\n",
      " [-0.20445597]]\n",
      "[[0.52740721]\n",
      " [0.20375558]]\n",
      "[[-0.52560051]\n",
      " [-0.20305759]]\n",
      "[[0.52380001]\n",
      " [0.202362  ]]\n",
      "[[-0.52200567]\n",
      " [-0.20166878]]\n",
      "[[0.52021748]\n",
      " [0.20097794]]\n",
      "[[-0.51843541]\n",
      " [-0.20028947]]\n",
      "Training:   0%|                      | 2165/1000000 [00:25<3:13:27, 85.97it/s, loss_val=27.9989, thetas=-0.6546 4.8859][[0.51665945]\n",
      " [0.19960336]]\n",
      "[[-0.51488958]\n",
      " [-0.19891959]]\n",
      "[[0.51312576]\n",
      " [0.19823817]]\n",
      "[[-0.51136799]\n",
      " [-0.19755908]]\n",
      "[[0.50961624]\n",
      " [0.19688232]]\n",
      "[[-0.5078705 ]\n",
      " [-0.19620788]]\n",
      "[[0.50613073]\n",
      " [0.19553575]]\n",
      "[[-0.50439692]\n",
      " [-0.19486592]]\n",
      "[[0.50266905]\n",
      " [0.19419838]]\n",
      "Training:   0%|                      | 2174/1000000 [00:25<3:12:28, 86.40it/s, loss_val=27.9989, thetas=-0.6546 4.8859][[-0.5009471 ]\n",
      " [-0.19353313]]\n",
      "[[0.49923105]\n",
      " [0.19287016]]\n",
      "[[-0.49752087]\n",
      " [-0.19220946]]\n",
      "[[0.49581656]\n",
      " [0.19155103]]\n",
      "[[-0.49411808]\n",
      " [-0.19089485]]\n",
      "[[0.49242542]\n",
      " [0.19024091]]\n",
      "[[-0.49073856]\n",
      " [-0.18958922]]\n",
      "[[0.48905748]\n",
      " [0.18893976]]\n",
      "[[-0.48738216]\n",
      " [-0.18829253]]\n",
      "Training:   0%|                      | 2183/1000000 [00:25<3:10:41, 87.21it/s, loss_val=27.9989, thetas=-0.6546 4.8859][[0.48571258]\n",
      " [0.18764751]]\n",
      "[[-0.48404871]\n",
      " [-0.1870047 ]]\n",
      "[[0.48239055]\n",
      " [0.1863641 ]]\n",
      "[[-0.48073806]\n",
      " [-0.18572568]]\n",
      "[[0.47909124]\n",
      " [0.18508946]]\n",
      "[[-0.47745006]\n",
      " [-0.18445541]]\n",
      "[[0.4758145 ]\n",
      " [0.18382354]]\n",
      "[[-0.47418454]\n",
      " [-0.18319383]]\n",
      "[[0.47256017]\n",
      " [0.18256628]]\n",
      "Training:   0%|                      | 2192/1000000 [00:25<3:11:39, 86.77it/s, loss_val=27.9989, thetas=-0.6546 4.8859][[-0.47094136]\n",
      " [-0.18194088]]\n",
      "[[0.4693281 ]\n",
      " [0.18131762]]\n",
      "[[-0.46772036]\n",
      " [-0.1806965 ]]\n",
      "[[0.46611813]\n",
      " [0.1800775 ]]\n",
      "[[-0.46452139]\n",
      " [-0.17946062]]\n",
      "[[0.46293012]\n",
      " [0.17884586]]\n",
      "[[-0.4613443]\n",
      " [-0.1782332]]\n",
      "[[0.45976391]\n",
      " [0.17762264]]\n",
      "[[-0.45818893]\n",
      " [-0.17701418]]\n",
      "Training:   0%|                      | 2201/1000000 [00:25<3:12:19, 86.47it/s, loss_val=27.9987, thetas=-0.6550 4.8857][[0.45661936]\n",
      " [0.1764078 ]]\n",
      "[[-0.45505515]\n",
      " [-0.17580349]]\n",
      "[[0.45349631]\n",
      " [0.17520126]]\n",
      "[[-0.45194281]\n",
      " [-0.17460108]]\n",
      "[[0.45039462]\n",
      " [0.17400297]]\n",
      "[[-0.44885175]\n",
      " [-0.1734069 ]]\n",
      "[[0.44731415]\n",
      " [0.17281288]]\n",
      "[[-0.44578183]\n",
      " [-0.17222089]]\n",
      "[[0.44425475]\n",
      " [0.17163092]]\n",
      "Training:   0%|                      | 2210/1000000 [00:25<3:12:14, 86.51it/s, loss_val=27.9987, thetas=-0.6550 4.8857][[-0.4427329 ]\n",
      " [-0.17104298]]\n",
      "[[0.44121627]\n",
      " [0.17045705]]\n",
      "[[-0.43970483]\n",
      " [-0.16987313]]\n",
      "[[0.43819858]\n",
      " [0.16929121]]\n",
      "[[-0.43669748]\n",
      " [-0.16871129]]\n",
      "[[0.43520152]\n",
      " [0.16813335]]\n",
      "[[-0.43371069]\n",
      " [-0.16755739]]\n",
      "[[0.43222496]\n",
      " [0.1669834 ]]\n",
      "[[-0.43074432]\n",
      " [-0.16641138]]\n",
      "Training:   0%|                      | 2219/1000000 [00:25<3:10:31, 87.29it/s, loss_val=27.9987, thetas=-0.6550 4.8857][[0.42926876]\n",
      " [0.16584132]]\n",
      "[[-0.42779825]\n",
      " [-0.16527321]]\n",
      "[[0.42633278]\n",
      " [0.16470705]]\n",
      "[[-0.42487233]\n",
      " [-0.16414282]]\n",
      "[[0.42341688]\n",
      " [0.16358053]]\n",
      "[[-0.42196641]\n",
      " [-0.16302017]]\n",
      "[[0.42052092]\n",
      " [0.16246173]]\n",
      "[[-0.41908038]\n",
      " [-0.1619052 ]]\n",
      "[[0.41764477]\n",
      " [0.16135057]]\n",
      "Training:   0%|                      | 2228/1000000 [00:26<3:12:04, 86.57it/s, loss_val=27.9987, thetas=-0.6550 4.8857][[-0.41621408]\n",
      " [-0.16079785]]\n",
      "[[0.41478829]\n",
      " [0.16024701]]\n",
      "[[-0.41336739]\n",
      " [-0.15969807]]\n",
      "[[0.41195135]\n",
      " [0.15915101]]\n",
      "[[-0.41054016]\n",
      " [-0.15860582]]\n",
      "[[0.40913381]\n",
      " [0.15806249]]\n",
      "[[-0.40773227]\n",
      " [-0.15752103]]\n",
      "[[0.40633554]\n",
      " [0.15698143]]\n",
      "[[-0.40494359]\n",
      " [-0.15644367]]\n",
      "Training:   0%|                      | 2237/1000000 [00:26<3:14:50, 85.35it/s, loss_val=27.9987, thetas=-0.6550 4.8857][[0.40355641]\n",
      " [0.15590775]]\n",
      "[[-0.40217398]\n",
      " [-0.15537367]]\n",
      "[[0.40079629]\n",
      " [0.15484142]]\n",
      "[[-0.39942332]\n",
      " [-0.15431099]]\n",
      "[[0.39805505]\n",
      " [0.15378238]]\n",
      "[[-0.39669146]\n",
      " [-0.15325559]]\n",
      "[[0.39533255]\n",
      " [0.15273059]]\n",
      "[[-0.39397829]\n",
      " [-0.15220739]]\n",
      "[[0.39262868]\n",
      " [0.15168599]]\n",
      "Training:   0%|                      | 2246/1000000 [00:26<3:14:37, 85.44it/s, loss_val=27.9987, thetas=-0.6550 4.8857][[-0.39128368]\n",
      " [-0.15116637]]\n",
      "[[0.38994329]\n",
      " [0.15064854]]\n",
      "[[-0.3886075 ]\n",
      " [-0.15013247]]\n",
      "[[0.38727628]\n",
      " [0.14961818]]\n",
      "[[-0.38594962]\n",
      " [-0.14910564]]\n",
      "[[0.3846275 ]\n",
      " [0.14859486]]\n",
      "[[-0.38330992]\n",
      " [-0.14808583]]\n",
      "[[0.38199685]\n",
      " [0.14757855]]\n",
      "[[-0.38068827]\n",
      " [-0.147073  ]]\n",
      "Training:   0%|                      | 2255/1000000 [00:26<3:14:53, 85.33it/s, loss_val=27.9987, thetas=-0.6550 4.8857][[0.37938418]\n",
      " [0.14656919]]\n",
      "[[-0.37808456]\n",
      " [-0.1460671 ]]\n",
      "[[0.37678939]\n",
      " [0.14556673]]\n",
      "[[-0.37549865]\n",
      " [-0.14506807]]\n",
      "[[0.37421234]\n",
      " [0.14457112]]\n",
      "[[-0.37293043]\n",
      " [-0.14407588]]\n",
      "[[0.37165291]\n",
      " [0.14358233]]\n",
      "[[-0.37037977]\n",
      " [-0.14309047]]\n",
      "[[0.369111 ]\n",
      " [0.1426003]]\n",
      "Training:   0%|                      | 2264/1000000 [00:26<3:14:35, 85.46it/s, loss_val=27.9987, thetas=-0.6550 4.8857][[-0.36784656]\n",
      " [-0.14211181]]\n",
      "[[0.36658646]\n",
      " [0.14162499]]\n",
      "[[-0.36533068]\n",
      " [-0.14113983]]\n",
      "[[0.3640792 ]\n",
      " [0.14065634]]\n",
      "[[-0.362832  ]\n",
      " [-0.14017451]]\n",
      "[[0.36158908]\n",
      " [0.13969432]]\n",
      "[[-0.36035041]\n",
      " [-0.13921579]]\n",
      "[[0.35911599]\n",
      " [0.13873889]]\n",
      "[[-0.3578858 ]\n",
      " [-0.13826362]]\n",
      "Training:   0%|                      | 2273/1000000 [00:26<3:14:22, 85.55it/s, loss_val=27.9987, thetas=-0.6550 4.8857][[0.35665982]\n",
      " [0.13778998]]\n",
      "[[-0.35543804]\n",
      " [-0.13731797]]\n",
      "[[0.35422045]\n",
      " [0.13684757]]\n",
      "[[-0.35300702]\n",
      " [-0.13637878]]\n",
      "[[0.35179776]\n",
      " [0.1359116 ]]\n",
      "[[-0.35059264]\n",
      " [-0.13544602]]\n",
      "[[0.34939164]\n",
      " [0.13498203]]\n",
      "[[-0.34819476]\n",
      " [-0.13451964]]\n",
      "[[0.34700198]\n",
      " [0.13405882]]\n",
      "Training:   0%|                      | 2282/1000000 [00:26<3:14:13, 85.62it/s, loss_val=27.9987, thetas=-0.6550 4.8857][[-0.34581328]\n",
      " [-0.13359959]]\n",
      "[[0.34462866]\n",
      " [0.13314193]]\n",
      "[[-0.34344809]\n",
      " [-0.13268584]]\n",
      "[[0.34227157]\n",
      " [0.13223131]]\n",
      "[[-0.34109908]\n",
      " [-0.13177833]]\n",
      "[[0.33993061]\n",
      " [0.13132691]]\n",
      "[[-0.33876614]\n",
      " [-0.13087704]]\n",
      "[[0.33760566]\n",
      " [0.1304287 ]]\n",
      "[[-0.33644915]\n",
      " [-0.1299819 ]]\n",
      "Training:   0%|                      | 2291/1000000 [00:26<3:14:40, 85.42it/s, loss_val=27.9987, thetas=-0.6550 4.8857][[0.3352966 ]\n",
      " [0.12953664]]\n",
      "[[-0.33414801]\n",
      " [-0.12909289]]\n",
      "[[0.33300334]\n",
      " [0.12865067]]\n",
      "[[-0.3318626 ]\n",
      " [-0.12820996]]\n",
      "[[0.33072577]\n",
      " [0.12777076]]\n",
      "[[-0.32959283]\n",
      " [-0.12733307]]\n",
      "[[0.32846377]\n",
      " [0.12689688]]\n",
      "[[-0.32733858]\n",
      " [-0.12646218]]\n",
      "[[0.32621725]\n",
      " [0.12602897]]\n",
      "Training:   0%|                      | 2300/1000000 [00:26<3:14:59, 85.28it/s, loss_val=27.9987, thetas=-0.6550 4.8857][[-0.32509975]\n",
      " [-0.12559724]]\n",
      "Training:   0%|                      | 2300/1000000 [00:26<3:14:59, 85.28it/s, loss_val=27.9986, thetas=-0.6552 4.8856][[0.32398609]\n",
      " [0.12516699]]\n",
      "[[-0.32287623]\n",
      " [-0.12473822]]\n",
      "[[0.32177018]\n",
      " [0.12431091]]\n",
      "[[-0.32066792]\n",
      " [-0.12388507]]\n",
      "[[0.31956944]\n",
      " [0.12346069]]\n",
      "[[-0.31847472]\n",
      " [-0.12303776]]\n",
      "[[0.31738375]\n",
      " [0.12261628]]\n",
      "[[-0.31629651]\n",
      " [-0.12219624]]\n",
      "Training:   0%|                      | 2309/1000000 [00:27<3:19:05, 83.52it/s, loss_val=27.9986, thetas=-0.6552 4.8856][[0.315213  ]\n",
      " [0.12177765]]\n",
      "[[-0.3141332 ]\n",
      " [-0.12136048]]\n",
      "[[0.3130571 ]\n",
      " [0.12094475]]\n",
      "[[-0.31198469]\n",
      " [-0.12053044]]\n",
      "[[0.31091595]\n",
      " [0.12011755]]\n",
      "[[-0.30985087]\n",
      " [-0.11970607]]\n",
      "[[0.30878944]\n",
      " [0.11929601]]\n",
      "[[-0.30773165]\n",
      " [-0.11888734]]\n",
      "[[0.30667748]\n",
      " [0.11848008]]\n",
      "Training:   0%|                      | 2318/1000000 [00:27<3:17:31, 84.18it/s, loss_val=27.9986, thetas=-0.6552 4.8856][[-0.30562692]\n",
      " [-0.11807421]]\n",
      "[[0.30457996]\n",
      " [0.11766974]]\n",
      "[[-0.30353659]\n",
      " [-0.11726665]]\n",
      "[[0.30249679]\n",
      " [0.11686494]]\n",
      "[[-0.30146055]\n",
      " [-0.1164646 ]]\n",
      "[[0.30042786]\n",
      " [0.11606564]]\n",
      "[[-0.29939871]\n",
      " [-0.11566804]]\n",
      "[[0.29837309]\n",
      " [0.11527181]]\n",
      "[[-0.29735098]\n",
      " [-0.11487693]]\n",
      "Training:   0%|                      | 2327/1000000 [00:27<3:17:31, 84.18it/s, loss_val=27.9986, thetas=-0.6552 4.8856][[0.29633237]\n",
      " [0.11448341]]\n",
      "[[-0.29531725]\n",
      " [-0.11409123]]\n",
      "[[0.2943056]\n",
      " [0.1137004]]\n",
      "[[-0.29329743]\n",
      " [-0.11331091]]\n",
      "[[0.2922927 ]\n",
      " [0.11292275]]\n",
      "[[-0.29129142]\n",
      " [-0.11253592]]\n",
      "[[0.29029357]\n",
      " [0.11215041]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.28929913]\n",
      " [-0.11176623]]\n",
      "[[0.28830811]\n",
      " [0.11138336]]\n",
      "Training:   0%|                      | 2336/1000000 [00:27<3:16:15, 84.72it/s, loss_val=27.9986, thetas=-0.6552 4.8856][[-0.28732047]\n",
      " [-0.1110018 ]]\n",
      "[[0.28633622]\n",
      " [0.11062155]]\n",
      "[[-0.28535535]\n",
      " [-0.11024261]]\n",
      "[[0.28437783]\n",
      " [0.10986496]]\n",
      "[[-0.28340366]\n",
      " [-0.1094886 ]]\n",
      "[[0.28243283]\n",
      " [0.10911354]]\n",
      "[[-0.28146532]\n",
      " [-0.10873976]]\n",
      "[[0.28050113]\n",
      " [0.10836726]]\n",
      "[[-0.27954024]\n",
      " [-0.10799603]]\n",
      "Training:   0%|                      | 2345/1000000 [00:27<3:15:32, 85.03it/s, loss_val=27.9986, thetas=-0.6552 4.8856][[0.27858264]\n",
      " [0.10762608]]\n",
      "[[-0.27762833]\n",
      " [-0.10725739]]\n",
      "[[0.27667728]\n",
      " [0.10688997]]\n",
      "[[-0.27572949]\n",
      " [-0.10652381]]\n",
      "[[0.27478495]\n",
      " [0.1061589 ]]\n",
      "[[-0.27384364]\n",
      " [-0.10579524]]\n",
      "[[0.27290556]\n",
      " [0.10543282]]\n",
      "[[-0.27197069]\n",
      " [-0.10507165]]\n",
      "[[0.27103902]\n",
      " [0.10471172]]\n",
      "Training:   0%|                      | 2354/1000000 [00:27<3:16:08, 84.77it/s, loss_val=27.9986, thetas=-0.6552 4.8856][[-0.27011055]\n",
      " [-0.10435301]]\n",
      "[[0.26918525]\n",
      " [0.10399554]]\n",
      "[[-0.26826313]\n",
      " [-0.10363929]]\n",
      "[[0.26734416]\n",
      " [0.10328426]]\n",
      "[[-0.26642834]\n",
      " [-0.10293045]]\n",
      "[[0.26551566]\n",
      " [0.10257785]]\n",
      "[[-0.26460611]\n",
      " [-0.10222646]]\n",
      "[[0.26369967]\n",
      " [0.10187627]]\n",
      "[[-0.26279634]\n",
      " [-0.10152728]]\n",
      "Training:   0%|                      | 2363/1000000 [00:27<3:13:14, 86.04it/s, loss_val=27.9986, thetas=-0.6552 4.8856][[0.2618961 ]\n",
      " [0.10117949]]\n",
      "[[-0.26099894]\n",
      " [-0.10083289]]\n",
      "[[0.26010486]\n",
      " [0.10048747]]\n",
      "[[-0.25921384]\n",
      " [-0.10014324]]\n",
      "[[0.25832587]\n",
      " [0.09980019]]\n",
      "[[-0.25744095]\n",
      " [-0.09945831]]\n",
      "[[0.25655906]\n",
      " [0.09911761]]\n",
      "[[-0.25568018]\n",
      " [-0.09877807]]\n",
      "[[0.25480432]\n",
      " [0.09843969]]\n",
      "Training:   0%|                      | 2372/1000000 [00:27<3:13:25, 85.96it/s, loss_val=27.9986, thetas=-0.6552 4.8856][[-0.25393146]\n",
      " [-0.09810248]]\n",
      "[[0.25306159]\n",
      " [0.09776641]]\n",
      "[[-0.2521947]\n",
      " [-0.0974315]]\n",
      "[[0.25133077]\n",
      " [0.09709774]]\n",
      "[[-0.25046981]\n",
      " [-0.09676512]]\n",
      "[[0.2496118 ]\n",
      " [0.09643364]]\n",
      "[[-0.24875673]\n",
      " [-0.0961033 ]]\n",
      "[[0.24790458]\n",
      " [0.09577408]]\n",
      "[[-0.24705536]\n",
      " [-0.095446  ]]\n",
      "Training:   0%|                      | 2381/1000000 [00:27<3:13:05, 86.11it/s, loss_val=27.9986, thetas=-0.6552 4.8856][[0.24620904]\n",
      " [0.09511904]]\n",
      "[[-0.24536562]\n",
      " [-0.0947932 ]]\n",
      "[[0.24452509]\n",
      " [0.09446847]]\n",
      "[[-0.24368744]\n",
      " [-0.09414486]]\n",
      "[[0.24285267]\n",
      " [0.09382236]]\n",
      "[[-0.24202075]\n",
      " [-0.09350096]]\n",
      "[[0.24119168]\n",
      " [0.09318066]]\n",
      "[[-0.24036545]\n",
      " [-0.09286146]]\n",
      "[[0.23954205]\n",
      " [0.09254335]]\n",
      "Training:   0%|                      | 2390/1000000 [00:27<3:12:45, 86.25it/s, loss_val=27.9986, thetas=-0.6552 4.8856][[-0.23872147]\n",
      " [-0.09222633]]\n",
      "[[0.2379037]\n",
      " [0.0919104]]\n",
      "[[-0.23708873]\n",
      " [-0.09159555]]\n",
      "[[0.23627656]\n",
      " [0.09128178]]\n",
      "[[-0.23546717]\n",
      " [-0.09096908]]\n",
      "[[0.23466055]\n",
      " [0.09065746]]\n",
      "[[-0.23385669]\n",
      " [-0.0903469 ]]\n",
      "[[0.23305559]\n",
      " [0.09003741]]\n",
      "[[-0.23225723]\n",
      " [-0.08972897]]\n",
      "Training:   0%|                      | 2399/1000000 [00:28<3:10:52, 87.11it/s, loss_val=27.9986, thetas=-0.6552 4.8856][[0.2314616]\n",
      " [0.0894216]]\n",
      "[[-0.23066871]\n",
      " [-0.08911527]]\n",
      "Training:   0%|                      | 2399/1000000 [00:28<3:10:52, 87.11it/s, loss_val=27.9985, thetas=-0.6554 4.8855][[0.22987852]\n",
      " [0.08881   ]]\n",
      "[[-0.22909105]\n",
      " [-0.08850577]]\n",
      "[[0.22830627]\n",
      " [0.08820258]]\n",
      "[[-0.22752418]\n",
      " [-0.08790043]]\n",
      "[[0.22674477]\n",
      " [0.08759932]]\n",
      "[[-0.22596803]\n",
      " [-0.08729924]]\n",
      "[[0.22519395]\n",
      " [0.08700019]]\n",
      "Training:   0%|                      | 2408/1000000 [00:28<3:14:34, 85.45it/s, loss_val=27.9985, thetas=-0.6554 4.8855][[-0.22442252]\n",
      " [-0.08670216]]\n",
      "[[0.22365374]\n",
      " [0.08640515]]\n",
      "[[-0.22288759]\n",
      " [-0.08610916]]\n",
      "[[0.22212406]\n",
      " [0.08581418]]\n",
      "[[-0.22136315]\n",
      " [-0.08552021]]\n",
      "[[0.22060484]\n",
      " [0.08522726]]\n",
      "[[-0.21984914]\n",
      " [-0.0849353 ]]\n",
      "[[0.21909602]\n",
      " [0.08464434]]\n",
      "[[-0.21834548]\n",
      " [-0.08435439]]\n",
      "Training:   0%|                      | 2417/1000000 [00:28<3:14:21, 85.55it/s, loss_val=27.9985, thetas=-0.6554 4.8855][[0.21759751]\n",
      " [0.08406542]]\n",
      "[[-0.21685211]\n",
      " [-0.08377744]]\n",
      "[[0.21610926]\n",
      " [0.08349045]]\n",
      "[[-0.21536895]\n",
      " [-0.08320445]]\n",
      "[[0.21463118]\n",
      " [0.08291942]]\n",
      "[[-0.21389593]\n",
      " [-0.08263537]]\n",
      "[[0.21316321]\n",
      " [0.0823523 ]]\n",
      "[[-0.21243299]\n",
      " [-0.08207019]]\n",
      "[[0.21170528]\n",
      " [0.08178905]]\n",
      "Training:   0%|                      | 2426/1000000 [00:28<3:12:32, 86.35it/s, loss_val=27.9985, thetas=-0.6554 4.8855][[-0.21098006]\n",
      " [-0.08150887]]\n",
      "[[0.21025732]\n",
      " [0.08122965]]\n",
      "[[-0.20953706]\n",
      " [-0.08095139]]\n",
      "[[0.20881927]\n",
      " [0.08067408]]\n",
      "[[-0.20810394]\n",
      " [-0.08039772]]\n",
      "[[0.20739105]\n",
      " [0.08012231]]\n",
      "[[-0.20668061]\n",
      " [-0.07984784]]\n",
      "[[0.2059726 ]\n",
      " [0.07957432]]\n",
      "[[-0.20526702]\n",
      " [-0.07930172]]\n",
      "Training:   0%|                      | 2435/1000000 [00:28<3:13:29, 85.93it/s, loss_val=27.9985, thetas=-0.6554 4.8855][[0.20456385]\n",
      " [0.07903007]]\n",
      "[[-0.2038631 ]\n",
      " [-0.07875934]]\n",
      "[[0.20316474]\n",
      " [0.07848954]]\n",
      "[[-0.20246878]\n",
      " [-0.07822067]]\n",
      "[[0.2017752 ]\n",
      " [0.07795271]]\n",
      "[[-0.20108399]\n",
      " [-0.07768568]]\n",
      "[[0.20039516]\n",
      " [0.07741956]]\n",
      "[[-0.19970868]\n",
      " [-0.07715435]]\n",
      "[[0.19902455]\n",
      " [0.07689005]]\n",
      "Training:   0%|                      | 2444/1000000 [00:28<3:12:40, 86.29it/s, loss_val=27.9985, thetas=-0.6554 4.8855][[-0.19834277]\n",
      " [-0.07662665]]\n",
      "[[0.19766333]\n",
      " [0.07636416]]\n",
      "[[-0.19698621]\n",
      " [-0.07610256]]\n",
      "[[0.19631141]\n",
      " [0.07584186]]\n",
      "[[-0.19563892]\n",
      " [-0.07558206]]\n",
      "[[0.19496874]\n",
      " [0.07532314]]\n",
      "[[-0.19430085]\n",
      " [-0.07506512]]\n",
      "[[0.19363525]\n",
      " [0.07480797]]\n",
      "[[-0.19297193]\n",
      " [-0.07455171]]\n",
      "Training:   0%|                      | 2453/1000000 [00:28<3:13:34, 85.88it/s, loss_val=27.9985, thetas=-0.6554 4.8855][[0.19231088]\n",
      " [0.07429632]]\n",
      "[[-0.1916521 ]\n",
      " [-0.07404181]]\n",
      "[[0.19099557]\n",
      " [0.07378817]]\n",
      "[[-0.1903413]\n",
      " [-0.0735354]]\n",
      "[[0.18968926]\n",
      " [0.0732835 ]]\n",
      "[[-0.18903946]\n",
      " [-0.07303246]]\n",
      "[[0.18839188]\n",
      " [0.07278228]]\n",
      "[[-0.18774652]\n",
      " [-0.07253295]]\n",
      "[[0.18710338]\n",
      " [0.07228448]]\n",
      "Training:   0%|                      | 2462/1000000 [00:28<3:13:39, 85.85it/s, loss_val=27.9985, thetas=-0.6554 4.8855][[-0.18646243]\n",
      " [-0.07203686]]\n",
      "[[0.18582368]\n",
      " [0.07179009]]\n",
      "[[-0.18518712]\n",
      " [-0.07154417]]\n",
      "[[0.18455274]\n",
      " [0.07129909]]\n",
      "[[-0.18392054]\n",
      " [-0.07105484]]\n",
      "[[0.1832905 ]\n",
      " [0.07081144]]\n",
      "[[-0.18266261]\n",
      " [-0.07056886]]\n",
      "[[0.18203688]\n",
      " [0.07032712]]\n",
      "[[-0.18141329]\n",
      " [-0.07008621]]\n",
      "Training:   0%|                      | 2471/1000000 [00:28<3:14:16, 85.58it/s, loss_val=27.9985, thetas=-0.6554 4.8855][[0.18079184]\n",
      " [0.06984612]]\n",
      "[[-0.18017252]\n",
      " [-0.06960685]]\n",
      "[[0.17955532]\n",
      " [0.06936841]]\n",
      "[[-0.17894023]\n",
      " [-0.06913078]]\n",
      "[[0.17832725]\n",
      " [0.06889396]]\n",
      "[[-0.17771637]\n",
      " [-0.06865796]]\n",
      "[[0.17710758]\n",
      " [0.06842276]]\n",
      "[[-0.17650088]\n",
      " [-0.06818837]]\n",
      "[[0.17589626]\n",
      " [0.06795479]]\n",
      "Training:   0%|                      | 2480/1000000 [00:29<3:14:08, 85.64it/s, loss_val=27.9985, thetas=-0.6554 4.8855][[-0.1752937]\n",
      " [-0.067722 ]]\n",
      "[[0.17469321]\n",
      " [0.06749001]]\n",
      "[[-0.17409478]\n",
      " [-0.06725882]]\n",
      "[[0.1734984 ]\n",
      " [0.06702841]]\n",
      "[[-0.17290406]\n",
      " [-0.0667988 ]]\n",
      "[[0.17231176]\n",
      " [0.06656997]]\n",
      "[[-0.17172149]\n",
      " [-0.06634193]]\n",
      "[[0.17113323]\n",
      " [0.06611467]]\n",
      "[[-0.170547  ]\n",
      " [-0.06588818]]\n",
      "Training:   0%|                      | 2489/1000000 [00:29<3:15:09, 85.19it/s, loss_val=27.9985, thetas=-0.6554 4.8855][[0.16996277]\n",
      " [0.06566248]]\n",
      "[[-0.16938054]\n",
      " [-0.06543754]]\n",
      "[[0.16880031]\n",
      " [0.06521338]]\n",
      "[[-0.16822206]\n",
      " [-0.06498998]]\n",
      "[[0.1676458 ]\n",
      " [0.06476735]]\n",
      "[[-0.16707151]\n",
      " [-0.06454548]]\n",
      "[[0.16649919]\n",
      " [0.06432438]]\n",
      "[[-0.16592883]\n",
      " [-0.06410402]]\n",
      "[[0.16536042]\n",
      " [0.06388443]]\n",
      "Training:   0%|                      | 2498/1000000 [00:29<3:14:44, 85.37it/s, loss_val=27.9985, thetas=-0.6554 4.8855][[-0.16479396]\n",
      " [-0.06366559]]\n",
      "[[0.16422944]\n",
      " [0.06344749]]\n",
      "[[-0.16366685]\n",
      " [-0.06323015]]\n",
      "Training:   0%|                      | 2498/1000000 [00:29<3:14:44, 85.37it/s, loss_val=27.9985, thetas=-0.6556 4.8855][[0.16310619]\n",
      " [0.06301354]]\n",
      "[[-0.16254745]\n",
      " [-0.06279768]]\n",
      "[[0.16199063]\n",
      " [0.06258256]]\n",
      "[[-0.16143571]\n",
      " [-0.06236818]]\n",
      "[[0.16088269]\n",
      " [0.06215453]]\n",
      "[[-0.16033157]\n",
      " [-0.06194161]]\n",
      "Training:   0%|                      | 2507/1000000 [00:29<3:16:40, 84.53it/s, loss_val=27.9985, thetas=-0.6556 4.8855][[0.15978234]\n",
      " [0.06172942]]\n",
      "[[-0.15923498]\n",
      " [-0.06151796]]\n",
      "[[0.15868951]\n",
      " [0.06130723]]\n",
      "[[-0.1581459 ]\n",
      " [-0.06109721]]\n",
      "[[0.15760415]\n",
      " [0.06088792]]\n",
      "[[-0.15706426]\n",
      " [-0.06067934]]\n",
      "[[0.15652622]\n",
      " [0.06047147]]\n",
      "[[-0.15599002]\n",
      " [-0.06026432]]\n",
      "[[0.15545566]\n",
      " [0.06005788]]\n",
      "Training:   0%|                      | 2516/1000000 [00:29<3:14:43, 85.38it/s, loss_val=27.9985, thetas=-0.6556 4.8855][[-0.15492313]\n",
      " [-0.05985214]]\n",
      "[[0.15439242]\n",
      " [0.05964711]]\n",
      "[[-0.15386353]\n",
      " [-0.05944278]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.15333645]\n",
      " [0.05923916]]\n",
      "[[-0.15281118]\n",
      " [-0.05903623]]\n",
      "[[0.15228771]\n",
      " [0.05883399]]\n",
      "[[-0.15176603]\n",
      " [-0.05863245]]\n",
      "[[0.15124614]\n",
      " [0.0584316 ]]\n",
      "[[-0.15072803]\n",
      " [-0.05823143]]\n",
      "Training:   0%|                      | 2525/1000000 [00:29<3:13:20, 85.98it/s, loss_val=27.9985, thetas=-0.6556 4.8855][[0.15021169]\n",
      " [0.05803195]]\n",
      "[[-0.14969712]\n",
      " [-0.05783316]]\n",
      "[[0.14918432]\n",
      " [0.05763504]]\n",
      "[[-0.14867327]\n",
      " [-0.05743761]]\n",
      "[[0.14816397]\n",
      " [0.05724085]]\n",
      "[[-0.14765642]\n",
      " [-0.05704476]]\n",
      "[[0.14715061]\n",
      " [0.05684935]]\n",
      "[[-0.14664653]\n",
      " [-0.05665461]]\n",
      "[[0.14614417]\n",
      " [0.05646053]]\n",
      "Training:   0%|                      | 2534/1000000 [00:29<3:12:31, 86.35it/s, loss_val=27.9985, thetas=-0.6556 4.8855][[-0.14564354]\n",
      " [-0.05626712]]\n",
      "[[0.14514462]\n",
      " [0.05607437]]\n",
      "[[-0.14464741]\n",
      " [-0.05588228]]\n",
      "[[0.1441519 ]\n",
      " [0.05569085]]\n",
      "[[-0.14365809]\n",
      " [-0.05550007]]\n",
      "[[0.14316598]\n",
      " [0.05530995]]\n",
      "[[-0.14267554]\n",
      " [-0.05512048]]\n",
      "[[0.14218679]\n",
      " [0.05493166]]\n",
      "[[-0.14169972]\n",
      " [-0.05474348]]\n",
      "Training:   0%|                      | 2543/1000000 [00:29<3:13:54, 85.73it/s, loss_val=27.9985, thetas=-0.6556 4.8855][[0.14121431]\n",
      " [0.05455595]]\n",
      "[[-0.14073056]\n",
      " [-0.05436907]]\n",
      "[[0.14024847]\n",
      " [0.05418282]]\n",
      "[[-0.13976804]\n",
      " [-0.05399721]]\n",
      "[[0.13928924]\n",
      " [0.05381224]]\n",
      "[[-0.13881209]\n",
      " [-0.0536279 ]]\n",
      "[[0.13833658]\n",
      " [0.05344419]]\n",
      "[[-0.13786269]\n",
      " [-0.05326111]]\n",
      "[[0.13739042]\n",
      " [0.05307866]]\n",
      "Training:   0%|                      | 2552/1000000 [00:29<3:14:59, 85.26it/s, loss_val=27.9985, thetas=-0.6556 4.8855][[-0.13691978]\n",
      " [-0.05289683]]\n",
      "[[0.13645074]\n",
      " [0.05271563]]\n",
      "[[-0.13598332]\n",
      " [-0.05253504]]\n",
      "[[0.13551749]\n",
      " [0.05235508]]\n",
      "[[-0.13505326]\n",
      " [-0.05217573]]\n",
      "[[0.13459062]\n",
      " [0.05199699]]\n",
      "[[-0.13412956]\n",
      " [-0.05181887]]\n",
      "[[0.13367009]\n",
      " [0.05164136]]\n",
      "[[-0.13321218]\n",
      " [-0.05146446]]\n",
      "Training:   0%|                      | 2561/1000000 [00:29<3:14:38, 85.41it/s, loss_val=27.9985, thetas=-0.6556 4.8855][[0.13275585]\n",
      " [0.05128816]]\n",
      "[[-0.13230108]\n",
      " [-0.05111247]]\n",
      "[[0.13184787]\n",
      " [0.05093738]]\n",
      "[[-0.13139621]\n",
      " [-0.05076288]]\n",
      "[[0.13094609]\n",
      " [0.05058899]]\n",
      "[[-0.13049752]\n",
      " [-0.05041569]]\n",
      "[[0.13005049]\n",
      " [0.05024299]]\n",
      "[[-0.12960499]\n",
      " [-0.05007087]]\n",
      "[[0.12916101]\n",
      " [0.04989935]]\n",
      "[[-0.12871855]\n",
      " [-0.04972841]]\n",
      "Training:   0%|                      | 2571/1000000 [00:30<3:11:04, 87.00it/s, loss_val=27.9985, thetas=-0.6556 4.8855][[0.12827761]\n",
      " [0.04955806]]\n",
      "[[-0.12783818]\n",
      " [-0.0493883 ]]\n",
      "[[0.12740026]\n",
      " [0.04921911]]\n",
      "[[-0.12696384]\n",
      " [-0.04905051]]\n",
      "[[0.12652891]\n",
      " [0.04888248]]\n",
      "[[-0.12609547]\n",
      " [-0.04871503]]\n",
      "[[0.12566351]\n",
      " [0.04854815]]\n",
      "[[-0.12523304]\n",
      " [-0.04838184]]\n",
      "[[0.12480404]\n",
      " [0.0482161 ]]\n",
      "Training:   0%|                      | 2580/1000000 [00:30<3:12:26, 86.38it/s, loss_val=27.9985, thetas=-0.6556 4.8855][[-0.12437651]\n",
      " [-0.04805093]]\n",
      "[[0.12395044]\n",
      " [0.04788633]]\n",
      "[[-0.12352583]\n",
      " [-0.04772229]]\n",
      "[[0.12310268]\n",
      " [0.04755881]]\n",
      "[[-0.12268098]\n",
      " [-0.04739589]]\n",
      "[[0.12226072]\n",
      " [0.04723353]]\n",
      "[[-0.1218419 ]\n",
      " [-0.04707173]]\n",
      "[[0.12142452]\n",
      " [0.04691048]]\n",
      "[[-0.12100857]\n",
      " [-0.04674978]]\n",
      "Training:   0%|                      | 2589/1000000 [00:30<3:10:38, 87.20it/s, loss_val=27.9985, thetas=-0.6556 4.8855][[0.12059404]\n",
      " [0.04658963]]\n",
      "[[-0.12018093]\n",
      " [-0.04643004]]\n",
      "[[0.11976924]\n",
      " [0.04627098]]\n",
      "[[-0.11935895]\n",
      " [-0.04611248]]\n",
      "[[0.11895008]\n",
      " [0.04595451]]\n",
      "[[-0.1185426 ]\n",
      " [-0.04579709]]\n",
      "[[0.11813652]\n",
      " [0.04564021]]\n",
      "[[-0.11773183]\n",
      " [-0.04548386]]\n",
      "[[0.11732852]\n",
      " [0.04532805]]\n",
      "Training:   0%|                      | 2598/1000000 [00:30<3:11:02, 87.01it/s, loss_val=27.9985, thetas=-0.6556 4.8855][[-0.1169266 ]\n",
      " [-0.04517278]]\n",
      "[[0.11652606]\n",
      " [0.04501803]]\n",
      "[[-0.11612688]\n",
      " [-0.04486382]]\n",
      "Training:   0%|                      | 2598/1000000 [00:30<3:11:02, 87.01it/s, loss_val=27.9984, thetas=-0.6557 4.8855][[0.11572908]\n",
      " [0.04471013]]\n",
      "[[-0.11533263]\n",
      " [-0.04455697]]\n",
      "[[0.11493755]\n",
      " [0.04440434]]\n",
      "[[-0.11454382]\n",
      " [-0.04425222]]\n",
      "[[0.11415143]\n",
      " [0.04410063]]\n",
      "[[-0.11376039]\n",
      " [-0.04394956]]\n",
      "Training:   0%|                      | 2607/1000000 [00:30<3:12:59, 86.14it/s, loss_val=27.9984, thetas=-0.6557 4.8855][[0.11337069]\n",
      " [0.04379901]]\n",
      "[[-0.11298233]\n",
      " [-0.04364897]]\n",
      "[[0.1125953 ]\n",
      " [0.04349944]]\n",
      "[[-0.11220959]\n",
      " [-0.04335043]]\n",
      "[[0.1118252 ]\n",
      " [0.04320193]]\n",
      "[[-0.11144213]\n",
      " [-0.04305394]]\n",
      "[[0.11106037]\n",
      " [0.04290645]]\n",
      "[[-0.11067992]\n",
      " [-0.04275947]]\n",
      "[[0.11030078]\n",
      " [0.04261299]]\n",
      "Training:   0%|                      | 2616/1000000 [00:30<3:13:46, 85.78it/s, loss_val=27.9984, thetas=-0.6557 4.8855][[-0.10992293]\n",
      " [-0.04246702]]\n",
      "[[0.10954638]\n",
      " [0.04232154]]\n",
      "[[-0.10917111]\n",
      " [-0.04217656]]\n",
      "[[0.10879713]\n",
      " [0.04203208]]\n",
      "[[-0.10842444]\n",
      " [-0.0418881 ]]\n",
      "[[0.10805302]\n",
      " [0.0417446 ]]\n",
      "[[-0.10768287]\n",
      " [-0.0416016 ]]\n",
      "[[0.10731399]\n",
      " [0.04145909]]\n",
      "[[-0.10694637]\n",
      " [-0.04131707]]\n",
      "Training:   0%|                      | 2625/1000000 [00:30<3:12:48, 86.22it/s, loss_val=27.9984, thetas=-0.6557 4.8855][[0.10658001]\n",
      " [0.04117553]]\n",
      "[[-0.10621491]\n",
      " [-0.04103448]]\n",
      "[[0.10585106]\n",
      " [0.04089391]]\n",
      "[[-0.10548846]\n",
      " [-0.04075383]]\n",
      "[[0.10512709]\n",
      " [0.04061422]]\n",
      "[[-0.10476697]\n",
      " [-0.04047509]]\n",
      "[[0.10440808]\n",
      " [0.04033644]]\n",
      "[[-0.10405042]\n",
      " [-0.04019826]]\n",
      "[[0.10369398]\n",
      " [0.04006056]]\n",
      "Training:   0%|                      | 2634/1000000 [00:30<3:10:53, 87.08it/s, loss_val=27.9984, thetas=-0.6557 4.8855][[-0.10333876]\n",
      " [-0.03992333]]\n",
      "[[0.10298476]\n",
      " [0.03978656]]\n",
      "[[-0.10263198]\n",
      " [-0.03965027]]\n",
      "[[0.1022804 ]\n",
      " [0.03951444]]\n",
      "[[-0.10193003]\n",
      " [-0.03937908]]\n",
      "[[0.10158085]\n",
      " [0.03924419]]\n",
      "[[-0.10123288]\n",
      " [-0.03910975]]\n",
      "[[0.10088609]\n",
      " [0.03897578]]\n",
      "[[-0.1005405 ]\n",
      " [-0.03884226]]\n",
      "Training:   0%|                      | 2643/1000000 [00:30<3:13:25, 85.94it/s, loss_val=27.9984, thetas=-0.6557 4.8855][[0.10019608]\n",
      " [0.0387092 ]]\n",
      "[[-0.09985285]\n",
      " [-0.0385766 ]]\n",
      "[[0.09951079]\n",
      " [0.03844445]]\n",
      "[[-0.09916991]\n",
      " [-0.03831275]]\n",
      "[[0.09883019]\n",
      " [0.03818151]]\n",
      "[[-0.09849163]\n",
      " [-0.03805071]]\n",
      "[[0.09815424]\n",
      " [0.03792037]]\n",
      "[[-0.097818  ]\n",
      " [-0.03779047]]\n",
      "[[0.09748291]\n",
      " [0.03766101]]\n",
      "Training:   0%|                      | 2652/1000000 [00:31<3:12:54, 86.17it/s, loss_val=27.9984, thetas=-0.6557 4.8855][[-0.09714898]\n",
      " [-0.037532  ]]\n",
      "[[0.09681618]\n",
      " [0.03740343]]\n",
      "[[-0.09648453]\n",
      " [-0.0372753 ]]\n",
      "[[0.09615401]\n",
      " [0.03714761]]\n",
      "[[-0.09582462]\n",
      " [-0.03702035]]\n",
      "[[0.09549636]\n",
      " [0.03689354]]\n",
      "[[-0.09516923]\n",
      " [-0.03676715]]\n",
      "[[0.09484322]\n",
      " [0.0366412 ]]\n",
      "[[-0.09451832]\n",
      " [-0.03651568]]\n",
      "Training:   0%|                      | 2661/1000000 [00:31<3:12:37, 86.29it/s, loss_val=27.9984, thetas=-0.6557 4.8855][[0.09419454]\n",
      " [0.0363906 ]]\n",
      "[[-0.09387186]\n",
      " [-0.03626594]]\n",
      "[[0.09355029]\n",
      " [0.0361417 ]]\n",
      "[[-0.09322983]\n",
      " [-0.0360179 ]]\n",
      "[[0.09291046]\n",
      " [0.03589451]]\n",
      "[[-0.09259218]\n",
      " [-0.03577155]]\n",
      "[[0.092275  ]\n",
      " [0.03564901]]\n",
      "[[-0.0919589 ]\n",
      " [-0.03552689]]\n",
      "[[0.09164388]\n",
      " [0.03540519]]\n",
      "Training:   0%|                      | 2670/1000000 [00:31<3:12:25, 86.38it/s, loss_val=27.9984, thetas=-0.6557 4.8855][[-0.09132994]\n",
      " [-0.03528391]]\n",
      "[[0.09101708]\n",
      " [0.03516304]]\n",
      "[[-0.09070529]\n",
      " [-0.03504258]]\n",
      "[[0.09039457]\n",
      " [0.03492254]]\n",
      "[[-0.09008492]\n",
      " [-0.03480291]]\n",
      "[[0.08977632]\n",
      " [0.03468369]]\n",
      "[[-0.08946878]\n",
      " [-0.03456487]]\n",
      "[[0.08916229]\n",
      " [0.03444647]]\n",
      "[[-0.08885686]\n",
      " [-0.03432847]]\n",
      "Training:   0%|                      | 2679/1000000 [00:31<3:11:43, 86.69it/s, loss_val=27.9984, thetas=-0.6557 4.8855][[0.08855247]\n",
      " [0.03421087]]\n",
      "[[-0.08824912]\n",
      " [-0.03409368]]\n",
      "[[0.08794682]\n",
      " [0.03397689]]\n",
      "[[-0.08764554]\n",
      " [-0.03386049]]\n",
      "[[0.0873453]\n",
      " [0.0337445]]\n",
      "[[-0.08704609]\n",
      " [-0.03362891]]\n",
      "[[0.08674791]\n",
      " [0.03351371]]\n",
      "[[-0.08645074]\n",
      " [-0.0333989 ]]\n",
      "[[0.08615459]\n",
      " [0.03328449]]\n",
      "Training:   0%|                      | 2688/1000000 [00:31<3:12:21, 86.41it/s, loss_val=27.9984, thetas=-0.6557 4.8855][[-0.08585946]\n",
      " [-0.03317047]]\n",
      "[[0.08556534]\n",
      " [0.03305684]]\n",
      "[[-0.08527223]\n",
      " [-0.0329436 ]]\n",
      "[[0.08498012]\n",
      " [0.03283075]]\n",
      "[[-0.08468901]\n",
      " [-0.03271828]]\n",
      "[[0.0843989]\n",
      " [0.0326062]]\n",
      "[[-0.08410978]\n",
      " [-0.03249451]]\n",
      "[[0.08382165]\n",
      " [0.03238319]]\n",
      "[[-0.08353451]\n",
      " [-0.03227226]]\n",
      "Training:   0%|                      | 2697/1000000 [00:31<3:12:13, 86.47it/s, loss_val=27.9984, thetas=-0.6557 4.8855][[0.08324835]\n",
      " [0.03216171]]\n",
      "[[-0.08296318]\n",
      " [-0.03205153]]\n",
      "[[0.08267898]\n",
      " [0.03194174]]\n",
      "[[-0.08239575]\n",
      " [-0.03183232]]\n",
      "Training:   0%|                      | 2697/1000000 [00:31<3:12:13, 86.47it/s, loss_val=27.9984, thetas=-0.6557 4.8854][[0.08211349]\n",
      " [0.03172327]]\n",
      "[[-0.0818322]\n",
      " [-0.0316146]]\n",
      "[[0.08155188]\n",
      " [0.0315063 ]]\n",
      "[[-0.08127251]\n",
      " [-0.03139837]]\n",
      "[[0.0809941 ]\n",
      " [0.03129081]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:   0%|                      | 2706/1000000 [00:31<3:14:54, 85.28it/s, loss_val=27.9984, thetas=-0.6557 4.8854][[-0.08071665]\n",
      " [-0.03118362]]\n",
      "[[0.08044015]\n",
      " [0.0310768 ]]\n",
      "[[-0.08016459]\n",
      " [-0.03097034]]\n",
      "[[0.07988998]\n",
      " [0.03086425]]\n",
      "[[-0.0796163 ]\n",
      " [-0.03075852]]\n",
      "[[0.07934357]\n",
      " [0.03065316]]\n",
      "[[-0.07907177]\n",
      " [-0.03054815]]\n",
      "[[0.0788009]\n",
      " [0.0304435]]\n",
      "[[-0.07853096]\n",
      " [-0.03033922]]\n",
      "Training:   0%|                      | 2715/1000000 [00:31<3:14:34, 85.42it/s, loss_val=27.9984, thetas=-0.6557 4.8854][[0.07826194]\n",
      " [0.03023529]]\n",
      "[[-0.07799385]\n",
      " [-0.03013171]]\n",
      "[[0.07772667]\n",
      " [0.03002849]]\n",
      "[[-0.07746041]\n",
      " [-0.02992563]]\n",
      "[[0.07719506]\n",
      " [0.02982311]]\n",
      "[[-0.07693062]\n",
      " [-0.02972095]]\n",
      "[[0.07666708]\n",
      " [0.02961914]]\n",
      "[[-0.07640445]\n",
      " [-0.02951767]]\n",
      "[[0.07614272]\n",
      " [0.02941656]]\n",
      "Training:   0%|                      | 2724/1000000 [00:31<3:13:14, 86.02it/s, loss_val=27.9984, thetas=-0.6557 4.8854][[-0.07588188]\n",
      " [-0.02931579]]\n",
      "[[0.07562194]\n",
      " [0.02921536]]\n",
      "[[-0.07536289]\n",
      " [-0.02911528]]\n",
      "[[0.07510472]\n",
      " [0.02901554]]\n",
      "[[-0.07484744]\n",
      " [-0.02891615]]\n",
      "[[0.07459105]\n",
      " [0.02881709]]\n",
      "[[-0.07433553]\n",
      " [-0.02871838]]\n",
      "[[0.07408088]\n",
      " [0.02862   ]]\n",
      "[[-0.07382711]\n",
      " [-0.02852196]]\n",
      "Training:   0%|                      | 2733/1000000 [00:31<3:12:17, 86.44it/s, loss_val=27.9984, thetas=-0.6557 4.8854][[0.07357421]\n",
      " [0.02842425]]\n",
      "[[-0.07332217]\n",
      " [-0.02832688]]\n",
      "[[0.073071  ]\n",
      " [0.02822984]]\n",
      "[[-0.07282068]\n",
      " [-0.02813314]]\n",
      "[[0.07257123]\n",
      " [0.02803677]]\n",
      "[[-0.07232263]\n",
      " [-0.02794072]]\n",
      "[[0.07207488]\n",
      " [0.02784501]]\n",
      "[[-0.07182798]\n",
      " [-0.02774962]]\n",
      "[[0.07158192]\n",
      " [0.02765456]]\n",
      "Training:   0%|                      | 2742/1000000 [00:32<3:12:11, 86.48it/s, loss_val=27.9984, thetas=-0.6557 4.8854][[-0.07133671]\n",
      " [-0.02755983]]\n",
      "[[0.07109234]\n",
      " [0.02746542]]\n",
      "[[-0.0708488 ]\n",
      " [-0.02737133]]\n",
      "[[0.0706061 ]\n",
      " [0.02727757]]\n",
      "[[-0.07036423]\n",
      " [-0.02718413]]\n",
      "[[0.07012319]\n",
      " [0.02709101]]\n",
      "[[-0.06988298]\n",
      " [-0.0269982 ]]\n",
      "[[0.06964358]\n",
      " [0.02690572]]\n",
      "[[-0.06940501]\n",
      " [-0.02681355]]\n",
      "Training:   0%|                      | 2751/1000000 [00:32<3:11:33, 86.77it/s, loss_val=27.9984, thetas=-0.6557 4.8854][[0.06916726]\n",
      " [0.0267217 ]]\n",
      "[[-0.06893032]\n",
      " [-0.02663016]]\n",
      "[[0.06869419]\n",
      " [0.02653893]]\n",
      "[[-0.06845887]\n",
      " [-0.02644802]]\n",
      "[[0.06822435]\n",
      " [0.02635742]]\n",
      "[[-0.06799064]\n",
      " [-0.02626713]]\n",
      "[[0.06775773]\n",
      " [0.02617715]]\n",
      "[[-0.06752562]\n",
      " [-0.02608748]]\n",
      "[[0.06729431]\n",
      " [0.02599811]]\n",
      "Training:   0%|                      | 2760/1000000 [00:32<3:13:53, 85.72it/s, loss_val=27.9984, thetas=-0.6557 4.8854][[-0.06706378]\n",
      " [-0.02590905]]\n",
      "[[0.06683405]\n",
      " [0.0258203 ]]\n",
      "[[-0.0666051 ]\n",
      " [-0.02573185]]\n",
      "[[0.06637693]\n",
      " [0.0256437 ]]\n",
      "[[-0.06614955]\n",
      " [-0.02555585]]\n",
      "[[0.06592295]\n",
      " [0.02546831]]\n",
      "[[-0.06569712]\n",
      " [-0.02538106]]\n",
      "[[0.06547207]\n",
      " [0.02529412]]\n",
      "[[-0.06524779]\n",
      " [-0.02520747]]\n",
      "Training:   0%|                      | 2769/1000000 [00:32<3:12:44, 86.23it/s, loss_val=27.9984, thetas=-0.6557 4.8854][[0.06502427]\n",
      " [0.02512112]]\n",
      "[[-0.06480153]\n",
      " [-0.02503506]]\n",
      "[[0.06457954]\n",
      " [0.0249493 ]]\n",
      "[[-0.06435832]\n",
      " [-0.02486384]]\n",
      "[[0.06413785]\n",
      " [0.02477866]]\n",
      "[[-0.06391814]\n",
      " [-0.02469378]]\n",
      "[[0.06369918]\n",
      " [0.02460919]]\n",
      "[[-0.06348097]\n",
      " [-0.02452489]]\n",
      "[[0.06326351]\n",
      " [0.02444087]]\n",
      "Training:   0%|                      | 2778/1000000 [00:32<3:13:36, 85.84it/s, loss_val=27.9984, thetas=-0.6557 4.8854][[-0.06304679]\n",
      " [-0.02435715]]\n",
      "[[0.06283082]\n",
      " [0.02427371]]\n",
      "[[-0.06261558]\n",
      " [-0.02419056]]\n",
      "[[0.06240109]\n",
      " [0.02410769]]\n",
      "[[-0.06218733]\n",
      " [-0.02402511]]\n",
      "[[0.0619743 ]\n",
      " [0.02394281]]\n",
      "[[-0.061762  ]\n",
      " [-0.02386079]]\n",
      "[[0.06155042]\n",
      " [0.02377905]]\n",
      "[[-0.06133958]\n",
      " [-0.02369759]]\n",
      "[[0.06112945]\n",
      " [0.02361641]]\n",
      "Training:   0%|                      | 2788/1000000 [00:32<3:10:20, 87.32it/s, loss_val=27.9984, thetas=-0.6557 4.8854][[-0.06092004]\n",
      " [-0.02353551]]\n",
      "[[0.06071135]\n",
      " [0.02345489]]\n",
      "[[-0.06050338]\n",
      " [-0.02337454]]\n",
      "[[0.06029612]\n",
      " [0.02329447]]\n",
      "[[-0.06008957]\n",
      " [-0.02321467]]\n",
      "[[0.05988372]\n",
      " [0.02313515]]\n",
      "[[-0.05967859]\n",
      " [-0.02305589]]\n",
      "[[0.05947415]\n",
      " [0.02297691]]\n",
      "[[-0.05927042]\n",
      " [-0.0228982 ]]\n",
      "Training:   0%|                      | 2797/1000000 [00:32<3:10:49, 87.10it/s, loss_val=27.9984, thetas=-0.6557 4.8854][[0.05906738]\n",
      " [0.02281976]]\n",
      "[[-0.05886504]\n",
      " [-0.02274159]]\n",
      "[[0.05866339]\n",
      " [0.02266369]]\n",
      "[[-0.05846243]\n",
      " [-0.02258605]]\n",
      "Training:   0%|                      | 2797/1000000 [00:32<3:10:49, 87.10it/s, loss_val=27.9984, thetas=-0.6558 4.8854][[0.05826216]\n",
      " [0.02250868]]\n",
      "[[-0.05806257]\n",
      " [-0.02243157]]\n",
      "[[0.05786367]\n",
      " [0.02235473]]\n",
      "[[-0.05766546]\n",
      " [-0.02227815]]\n",
      "[[0.05746792]\n",
      " [0.02220184]]\n",
      "Training:   0%|                      | 2806/1000000 [00:32<3:16:41, 84.50it/s, loss_val=27.9984, thetas=-0.6558 4.8854][[-0.05727105]\n",
      " [-0.02212578]]\n",
      "[[0.05707486]\n",
      " [0.02204999]]\n",
      "[[-0.05687935]\n",
      " [-0.02197445]]\n",
      "[[0.0566845 ]\n",
      " [0.02189918]]\n",
      "[[-0.05649032]\n",
      " [-0.02182416]]\n",
      "[[0.05629681]\n",
      " [0.0217494 ]]\n",
      "[[-0.05610396]\n",
      " [-0.02167489]]\n",
      "[[0.05591177]\n",
      " [0.02160064]]\n",
      "[[-0.05572023]\n",
      " [-0.02152665]]\n",
      "Training:   0%|                      | 2815/1000000 [00:32<3:15:15, 85.12it/s, loss_val=27.9984, thetas=-0.6558 4.8854][[0.05552936]\n",
      " [0.02145291]]\n",
      "[[-0.05533914]\n",
      " [-0.02137942]]\n",
      "[[0.05514957]\n",
      " [0.02130618]]\n",
      "[[-0.05496064]\n",
      " [-0.02123319]]\n",
      "[[0.05477237]\n",
      " [0.02116045]]\n",
      "[[-0.05458474]\n",
      " [-0.02108797]]\n",
      "[[0.05439776]\n",
      " [0.02101573]]\n",
      "[[-0.05421141]\n",
      " [-0.02094374]]\n",
      "[[0.0540257 ]\n",
      " [0.02087199]]\n",
      "Training:   0%|                      | 2824/1000000 [00:33<3:14:48, 85.31it/s, loss_val=27.9984, thetas=-0.6558 4.8854][[-0.05384063]\n",
      " [-0.02080049]]\n",
      "[[0.05365619]\n",
      " [0.02072924]]\n",
      "[[-0.05347239]\n",
      " [-0.02065823]]\n",
      "[[0.05328921]\n",
      " [0.02058746]]\n",
      "[[-0.05310666]\n",
      " [-0.02051693]]\n",
      "[[0.05292474]\n",
      " [0.02044665]]\n",
      "[[-0.05274344]\n",
      " [-0.02037661]]\n",
      "[[0.05256276]\n",
      " [0.02030681]]\n",
      "[[-0.0523827 ]\n",
      " [-0.02023724]]\n",
      "Training:   0%|                      | 2833/1000000 [00:33<3:15:36, 84.96it/s, loss_val=27.9984, thetas=-0.6558 4.8854][[0.05220326]\n",
      " [0.02016792]]\n",
      "[[-0.05202443]\n",
      " [-0.02009883]]\n",
      "[[0.05184622]\n",
      " [0.02002998]]\n",
      "[[-0.05166861]\n",
      " [-0.01996137]]\n",
      "[[0.05149161]\n",
      " [0.01989299]]\n",
      "[[-0.05131522]\n",
      " [-0.01982484]]\n",
      "[[0.05113944]\n",
      " [0.01975693]]\n",
      "[[-0.05096425]\n",
      " [-0.01968925]]\n",
      "[[0.05078967]\n",
      " [0.0196218 ]]\n",
      "Training:   0%|                      | 2842/1000000 [00:33<3:13:43, 85.78it/s, loss_val=27.9984, thetas=-0.6558 4.8854][[-0.05061568]\n",
      " [-0.01955458]]\n",
      "[[0.05044229]\n",
      " [0.0194876 ]]\n",
      "[[-0.0502695 ]\n",
      " [-0.01942084]]\n",
      "[[0.05009729]\n",
      " [0.01935431]]\n",
      "[[-0.04992568]\n",
      " [-0.01928801]]\n",
      "[[0.04975465]\n",
      " [0.01922194]]\n",
      "[[-0.04958421]\n",
      " [-0.01915609]]\n",
      "[[0.04941436]\n",
      " [0.01909047]]\n",
      "[[-0.04924508]\n",
      " [-0.01902507]]\n",
      "Training:   0%|                      | 2851/1000000 [00:33<3:13:11, 86.03it/s, loss_val=27.9984, thetas=-0.6558 4.8854][[0.04907639]\n",
      " [0.0189599 ]]\n",
      "[[-0.04890827]\n",
      " [-0.01889495]]\n",
      "[[0.04874073]\n",
      " [0.01883022]]\n",
      "[[-0.04857376]\n",
      " [-0.01876572]]\n",
      "[[0.04840737]\n",
      " [0.01870143]]\n",
      "[[-0.04824154]\n",
      " [-0.01863737]]\n",
      "[[0.04807629]\n",
      " [0.01857353]]\n",
      "[[-0.0479116]\n",
      " [-0.0185099]]\n",
      "[[0.04774747]\n",
      " [0.01844649]]\n",
      "Training:   0%|                      | 2860/1000000 [00:33<3:13:21, 85.95it/s, loss_val=27.9984, thetas=-0.6558 4.8854][[-0.0475839]\n",
      " [-0.0183833]]\n",
      "[[0.0474209 ]\n",
      " [0.01832033]]\n",
      "[[-0.04725845]\n",
      " [-0.01825757]]\n",
      "[[0.04709657]\n",
      " [0.01819503]]\n",
      "[[-0.04693523]\n",
      " [-0.0181327 ]]\n",
      "[[0.04677445]\n",
      " [0.01807058]]\n",
      "[[-0.04661422]\n",
      " [-0.01800868]]\n",
      "[[0.04645454]\n",
      " [0.01794699]]\n",
      "[[-0.0462954 ]\n",
      " [-0.01788551]]\n",
      "Training:   0%|                      | 2869/1000000 [00:33<3:12:55, 86.14it/s, loss_val=27.9984, thetas=-0.6558 4.8854][[0.04613681]\n",
      " [0.01782424]]\n",
      "[[-0.04597876]\n",
      " [-0.01776318]]\n",
      "[[0.04582126]\n",
      " [0.01770233]]\n",
      "[[-0.04566429]\n",
      " [-0.01764169]]\n",
      "[[0.04550786]\n",
      " [0.01758126]]\n",
      "[[-0.04535197]\n",
      " [-0.01752103]]\n",
      "[[0.04519661]\n",
      " [0.01746101]]\n",
      "[[-0.04504179]\n",
      " [-0.01740119]]\n",
      "[[0.04488749]\n",
      " [0.01734158]]\n",
      "Training:   0%|                      | 2878/1000000 [00:33<3:12:37, 86.28it/s, loss_val=27.9984, thetas=-0.6558 4.8854][[-0.04473372]\n",
      " [-0.01728218]]\n",
      "[[0.04458048]\n",
      " [0.01722298]]\n",
      "[[-0.04442777]\n",
      " [-0.01716398]]\n",
      "[[0.04427557]\n",
      " [0.01710518]]\n",
      "[[-0.0441239 ]\n",
      " [-0.01704658]]\n",
      "[[0.04397275]\n",
      " [0.01698819]]\n",
      "[[-0.04382212]\n",
      " [-0.01692999]]\n",
      "[[0.043672]\n",
      " [0.016872]]\n",
      "[[-0.0435224]\n",
      " [-0.0168142]]\n",
      "Training:   0%|                      | 2887/1000000 [00:33<3:11:51, 86.62it/s, loss_val=27.9984, thetas=-0.6558 4.8854][[0.04337331]\n",
      " [0.0167566 ]]\n",
      "[[-0.04322473]\n",
      " [-0.0166992 ]]\n",
      "[[0.04307665]\n",
      " [0.016642  ]]\n",
      "[[-0.04292909]\n",
      " [-0.01658499]]\n",
      "[[0.04278203]\n",
      " [0.01652817]]\n",
      "[[-0.04263548]\n",
      " [-0.01647155]]\n",
      "[[0.04248942]\n",
      " [0.01641513]]\n",
      "[[-0.04234387]\n",
      " [-0.0163589 ]]\n",
      "[[0.04219882]\n",
      " [0.01630286]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:   0%|                      | 2896/1000000 [00:33<3:10:46, 87.11it/s, loss_val=27.9984, thetas=-0.6558 4.8854][[-0.04205426]\n",
      " [-0.01624701]]\n",
      "[[0.0419102 ]\n",
      " [0.01619135]]\n",
      "[[-0.04176663]\n",
      " [-0.01613589]]\n",
      "[[0.04162356]\n",
      " [0.01608061]]\n",
      "[[-0.04148097]\n",
      " [-0.01602553]]\n",
      "Training:   0%|                      | 2896/1000000 [00:33<3:10:46, 87.11it/s, loss_val=27.9984, thetas=-0.6558 4.8854][[0.04133887]\n",
      " [0.01597063]]\n",
      "[[-0.04119726]\n",
      " [-0.01591592]]\n",
      "[[0.04105613]\n",
      " [0.0158614 ]]\n",
      "[[-0.04091549]\n",
      " [-0.01580706]]\n",
      "Training:   0%|                      | 2905/1000000 [00:33<3:13:19, 85.96it/s, loss_val=27.9984, thetas=-0.6558 4.8854][[0.04077533]\n",
      " [0.01575292]]\n",
      "[[-0.04063565]\n",
      " [-0.01569895]]\n",
      "[[0.04049645]\n",
      " [0.01564517]]\n",
      "[[-0.04035772]\n",
      " [-0.01559158]]\n",
      "[[0.04021947]\n",
      " [0.01553817]]\n",
      "[[-0.0400817 ]\n",
      " [-0.01548494]]\n",
      "[[0.03994439]\n",
      " [0.0154319 ]]\n",
      "[[-0.03980756]\n",
      " [-0.01537903]]\n",
      "[[0.03967119]\n",
      " [0.01532635]]\n",
      "Training:   0%|                      | 2914/1000000 [00:34<3:13:27, 85.90it/s, loss_val=27.9984, thetas=-0.6558 4.8854][[-0.03953529]\n",
      " [-0.01527385]]\n",
      "[[0.03939986]\n",
      " [0.01522152]]\n",
      "[[-0.03926489]\n",
      " [-0.01516938]]\n",
      "[[0.03913039]\n",
      " [0.01511742]]\n",
      "[[-0.03899634]\n",
      " [-0.01506563]]\n",
      "[[0.03886275]\n",
      " [0.01501402]]\n",
      "[[-0.03872963]\n",
      " [-0.01496259]]\n",
      "[[0.03859695]\n",
      " [0.01491133]]\n",
      "[[-0.03846473]\n",
      " [-0.01486025]]\n",
      "Training:   0%|                      | 2923/1000000 [00:34<3:14:39, 85.37it/s, loss_val=27.9984, thetas=-0.6558 4.8854][[0.03833297]\n",
      " [0.01480935]]\n",
      "[[-0.03820166]\n",
      " [-0.01475862]]\n",
      "[[0.03807079]\n",
      " [0.01470806]]\n",
      "[[-0.03794038]\n",
      " [-0.01465767]]\n",
      "[[0.03781041]\n",
      " [0.01460746]]\n",
      "[[-0.03768088]\n",
      " [-0.01455742]]\n",
      "[[0.0375518 ]\n",
      " [0.01450756]]\n",
      "[[-0.03742316]\n",
      " [-0.01445786]]\n",
      "[[0.03729497]\n",
      " [0.01440833]]\n",
      "Training:   0%|                      | 2932/1000000 [00:34<3:12:39, 86.25it/s, loss_val=27.9984, thetas=-0.6558 4.8854][[-0.03716721]\n",
      " [-0.01435897]]\n",
      "[[0.03703989]\n",
      " [0.01430979]]\n",
      "[[-0.036913  ]\n",
      " [-0.01426077]]\n",
      "[[0.03678655]\n",
      " [0.01421191]]\n",
      "[[-0.03666054]\n",
      " [-0.01416323]]\n",
      "[[0.03653495]\n",
      " [0.01411471]]\n",
      "[[-0.0364098 ]\n",
      " [-0.01406636]]\n",
      "[[0.03628507]\n",
      " [0.01401817]]\n",
      "[[-0.03616077]\n",
      " [-0.01397015]]\n",
      "Training:   0%|                      | 2941/1000000 [00:34<3:10:46, 87.11it/s, loss_val=27.9984, thetas=-0.6558 4.8854][[0.0360369]\n",
      " [0.0139223]]\n",
      "[[-0.03591345]\n",
      " [-0.0138746 ]]\n",
      "[[0.03579043]\n",
      " [0.01382708]]\n",
      "[[-0.03566782]\n",
      " [-0.01377971]]\n",
      "[[0.03554564]\n",
      " [0.01373251]]\n",
      "[[-0.03542387]\n",
      " [-0.01368546]]\n",
      "[[0.03530252]\n",
      " [0.01363858]]\n",
      "[[-0.03518159]\n",
      " [-0.01359186]]\n",
      "[[0.03506107]\n",
      " [0.0135453 ]]\n",
      "Training:   0%|                      | 2950/1000000 [00:34<3:10:33, 87.20it/s, loss_val=27.9984, thetas=-0.6558 4.8854][[-0.03494097]\n",
      " [-0.0134989 ]]\n",
      "[[0.03482127]\n",
      " [0.01345266]]\n",
      "[[-0.03470199]\n",
      " [-0.01340657]]\n",
      "[[0.03458311]\n",
      " [0.01336065]]\n",
      "[[-0.03446464]\n",
      " [-0.01331488]]\n",
      "[[0.03434658]\n",
      " [0.01326927]]\n",
      "[[-0.03422892]\n",
      " [-0.01322381]]\n",
      "[[0.03411167]\n",
      " [0.01317851]]\n",
      "[[-0.03399481]\n",
      " [-0.01313337]]\n",
      "Training:   0%|                      | 2959/1000000 [00:34<3:09:18, 87.78it/s, loss_val=27.9984, thetas=-0.6558 4.8854][[0.03387836]\n",
      " [0.01308838]]\n",
      "[[-0.03376231]\n",
      " [-0.01304354]]\n",
      "[[0.03364665]\n",
      " [0.01299886]]\n",
      "[[-0.03353139]\n",
      " [-0.01295433]]\n",
      "[[0.03341652]\n",
      " [0.01290996]]\n",
      "[[-0.03330205]\n",
      " [-0.01286573]]\n",
      "[[0.03318797]\n",
      " [0.01282166]]\n",
      "[[-0.03307428]\n",
      " [-0.01277774]]\n",
      "[[0.03296098]\n",
      " [0.01273396]]\n",
      "Training:   0%|                      | 2968/1000000 [00:34<3:11:47, 86.64it/s, loss_val=27.9984, thetas=-0.6558 4.8854][[-0.03284807]\n",
      " [-0.01269034]]\n",
      "[[0.03273555]\n",
      " [0.01264687]]\n",
      "[[-0.03262341]\n",
      " [-0.01260355]]\n",
      "[[0.03251165]\n",
      " [0.01256037]]\n",
      "[[-0.03240028]\n",
      " [-0.01251734]]\n",
      "[[0.03228929]\n",
      " [0.01247447]]\n",
      "[[-0.03217868]\n",
      " [-0.01243173]]\n",
      "[[0.03206845]\n",
      " [0.01238915]]\n",
      "[[-0.03195859]\n",
      " [-0.01234671]]\n",
      "Training:   0%|                      | 2977/1000000 [00:34<3:11:16, 86.87it/s, loss_val=27.9984, thetas=-0.6558 4.8854][[0.03184911]\n",
      " [0.01230441]]\n",
      "[[-0.03174001]\n",
      " [-0.01226226]]\n",
      "[[0.03163128]\n",
      " [0.01222025]]\n",
      "[[-0.03152293]\n",
      " [-0.01217839]]\n",
      "[[0.03141494]\n",
      " [0.01213667]]\n",
      "[[-0.03130733]\n",
      " [-0.0120951 ]]\n",
      "[[0.03120008]\n",
      " [0.01205367]]\n",
      "[[-0.0310932 ]\n",
      " [-0.01201237]]\n",
      "[[0.03098669]\n",
      " [0.01197122]]\n",
      "Training:   0%|                      | 2986/1000000 [00:34<3:12:33, 86.29it/s, loss_val=27.9984, thetas=-0.6558 4.8854][[-0.03088054]\n",
      " [-0.01193022]]\n",
      "[[0.03077475]\n",
      " [0.01188935]]\n",
      "[[-0.03066933]\n",
      " [-0.01184862]]\n",
      "[[0.03056427]\n",
      " [0.01180803]]\n",
      "[[-0.03045957]\n",
      " [-0.01176758]]\n",
      "[[0.03035522]\n",
      " [0.01172727]]\n",
      "[[-0.03025124]\n",
      " [-0.0116871 ]]\n",
      "[[0.03014761]\n",
      " [0.01164706]]\n",
      "[[-0.03004434]\n",
      " [-0.01160716]]\n",
      "Training:   0%|                      | 2995/1000000 [00:34<3:12:55, 86.13it/s, loss_val=27.9984, thetas=-0.6558 4.8854][[0.02994142]\n",
      " [0.0115674 ]]\n",
      "[[-0.02983885]\n",
      " [-0.01152778]]\n",
      "[[0.02973663]\n",
      " [0.01148829]]\n",
      "[[-0.02963477]\n",
      " [-0.01144893]]\n",
      "[[0.02953325]\n",
      " [0.01140971]]\n",
      "[[-0.02943208]\n",
      " [-0.01137063]]\n",
      "Training:   0%|                      | 2995/1000000 [00:35<3:12:55, 86.13it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.02933126]\n",
      " [0.01133168]]\n",
      "[[-0.02923078]\n",
      " [-0.01129286]]\n",
      "[[0.02913064]\n",
      " [0.01125417]]\n",
      "Training:   0%|                      | 3004/1000000 [00:35<3:17:35, 84.10it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.02903085]\n",
      " [-0.01121562]]\n",
      "[[0.02893141]\n",
      " [0.0111772 ]]\n",
      "[[-0.0288323 ]\n",
      " [-0.01113891]]\n",
      "[[0.02873353]\n",
      " [0.01110075]]\n",
      "[[-0.0286351 ]\n",
      " [-0.01106273]]\n",
      "[[0.02853701]\n",
      " [0.01102483]]\n",
      "[[-0.02843925]\n",
      " [-0.01098706]]\n",
      "[[0.02834183]\n",
      " [0.01094943]]\n",
      "[[-0.02824474]\n",
      " [-0.01091192]]\n",
      "Training:   0%|                      | 3013/1000000 [00:35<3:16:59, 84.35it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.02814798]\n",
      " [0.01087454]]\n",
      "[[-0.02805156]\n",
      " [-0.01083728]]\n",
      "[[0.02795547]\n",
      " [0.01080016]]\n",
      "[[-0.0278597 ]\n",
      " [-0.01076316]]\n",
      "[[0.02776427]\n",
      " [0.01072629]]\n",
      "[[-0.02766916]\n",
      " [-0.01068955]]\n",
      "[[0.02757437]\n",
      " [0.01065293]]\n",
      "[[-0.02747991]\n",
      " [-0.01061644]]\n",
      "[[0.02738578]\n",
      " [0.01058007]]\n",
      "Training:   0%|                      | 3022/1000000 [00:35<3:16:00, 84.77it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.02729196]\n",
      " [-0.01054383]]\n",
      "[[0.02719847]\n",
      " [0.01050771]]\n",
      "[[-0.0271053 ]\n",
      " [-0.01047171]]\n",
      "[[0.02701245]\n",
      " [0.01043584]]\n",
      "[[-0.02691991]\n",
      " [-0.01040009]]\n",
      "[[0.0268277 ]\n",
      " [0.01036446]]\n",
      "[[-0.0267358 ]\n",
      " [-0.01032896]]\n",
      "[[0.02664421]\n",
      " [0.01029358]]\n",
      "[[-0.02655294]\n",
      " [-0.01025831]]\n",
      "Training:   0%|                      | 3031/1000000 [00:35<3:15:06, 85.17it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.02646198]\n",
      " [0.01022317]]\n",
      "[[-0.02637133]\n",
      " [-0.01018815]]\n",
      "[[0.02628099]\n",
      " [0.01015325]]\n",
      "[[-0.02619096]\n",
      " [-0.01011847]]\n",
      "[[0.02610124]\n",
      " [0.01008381]]\n",
      "[[-0.02601183]\n",
      " [-0.01004927]]\n",
      "[[0.02592272]\n",
      " [0.01001484]]\n",
      "[[-0.02583392]\n",
      " [-0.00998053]]\n",
      "[[0.02574542]\n",
      " [0.00994634]]\n",
      "Training:   0%|                      | 3040/1000000 [00:35<3:13:34, 85.83it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.02565723]\n",
      " [-0.00991227]]\n",
      "[[0.02556934]\n",
      " [0.00987832]]\n",
      "[[-0.02548175]\n",
      " [-0.00984448]]\n",
      "[[0.02539446]\n",
      " [0.00981075]]\n",
      "[[-0.02530746]\n",
      " [-0.00977715]]\n",
      "[[0.02522077]\n",
      " [0.00974365]]\n",
      "[[-0.02513437]\n",
      " [-0.00971028]]\n",
      "[[0.02504827]\n",
      " [0.00967701]]\n",
      "[[-0.02496247]\n",
      " [-0.00964386]]\n",
      "Training:   0%|                      | 3049/1000000 [00:35<3:14:27, 85.45it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.02487696]\n",
      " [0.00961083]]\n",
      "[[-0.02479174]\n",
      " [-0.0095779 ]]\n",
      "[[0.02470681]\n",
      " [0.00954509]]\n",
      "[[-0.02462217]\n",
      " [-0.00951239]]\n",
      "[[0.02453783]\n",
      " [0.00947981]]\n",
      "[[-0.02445377]\n",
      " [-0.00944733]]\n",
      "[[0.02437   ]\n",
      " [0.00941497]]\n",
      "[[-0.02428652]\n",
      " [-0.00938272]]\n",
      "[[0.02420332]\n",
      " [0.00935058]]\n",
      "Training:   0%|                      | 3058/1000000 [00:35<3:15:53, 84.82it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.02412041]\n",
      " [-0.00931855]]\n",
      "[[0.02403778]\n",
      " [0.00928662]]\n",
      "[[-0.02395544]\n",
      " [-0.00925481]]\n",
      "[[0.02387338]\n",
      " [0.00922311]]\n",
      "[[-0.0237916 ]\n",
      " [-0.00919151]]\n",
      "[[0.0237101 ]\n",
      " [0.00916003]]\n",
      "[[-0.02362887]\n",
      " [-0.00912865]]\n",
      "[[0.02354793]\n",
      " [0.00909738]]\n",
      "[[-0.02346727]\n",
      " [-0.00906621]]\n",
      "Training:   0%|                      | 3067/1000000 [00:35<3:16:21, 84.62it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.02338688]\n",
      " [0.00903516]]\n",
      "[[-0.02330676]\n",
      " [-0.00900421]]\n",
      "[[0.02322692]\n",
      " [0.00897336]]\n",
      "[[-0.02314735]\n",
      " [-0.00894262]]\n",
      "[[0.02306806]\n",
      " [0.00891199]]\n",
      "[[-0.02298904]\n",
      " [-0.00888146]]\n",
      "[[0.02291029]\n",
      " [0.00885103]]\n",
      "[[-0.0228318 ]\n",
      " [-0.00882071]]\n",
      "[[0.02275359]\n",
      " [0.0087905 ]]\n",
      "Training:   0%|                      | 3076/1000000 [00:35<3:14:27, 85.45it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.02267565]\n",
      " [-0.00876038]]\n",
      "[[0.02259797]\n",
      " [0.00873037]]\n",
      "[[-0.02252056]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [-0.00870047]]\n",
      "[[0.02244341]\n",
      " [0.00867066]]\n",
      "[[-0.02236653]\n",
      " [-0.00864096]]\n",
      "[[0.02228991]\n",
      " [0.00861136]]\n",
      "[[-0.02221355]\n",
      " [-0.00858186]]\n",
      "[[0.02213746]\n",
      " [0.00855246]]\n",
      "[[-0.02206162]\n",
      " [-0.00852317]]\n",
      "Training:   0%|                      | 3085/1000000 [00:36<3:15:20, 85.06it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.02198605]\n",
      " [0.00849397]]\n",
      "[[-0.02191073]\n",
      " [-0.00846487]]\n",
      "[[0.02183567]\n",
      " [0.00843587]]\n",
      "[[-0.02176087]\n",
      " [-0.00840698]]\n",
      "[[0.02168633]\n",
      " [0.00837818]]\n",
      "[[-0.02161204]\n",
      " [-0.00834948]]\n",
      "[[0.02153801]\n",
      " [0.00832087]]\n",
      "[[-0.02146423]\n",
      " [-0.00829237]]\n",
      "[[0.0213907 ]\n",
      " [0.00826396]]\n",
      "Training:   0%|                      | 3094/1000000 [00:36<3:14:18, 85.51it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.02131742]\n",
      " [-0.00823565]]\n",
      "[[0.0212444 ]\n",
      " [0.00820744]]\n",
      "[[-0.02117162]\n",
      " [-0.00817933]]\n",
      "[[0.02109909]\n",
      " [0.00815131]]\n",
      "[[-0.02102682]\n",
      " [-0.00812338]]\n",
      "[[0.02095479]\n",
      " [0.00809556]]\n",
      "[[-0.020883  ]\n",
      " [-0.00806782]]\n",
      "Training:   0%|                      | 3094/1000000 [00:36<3:14:18, 85.51it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.02081147]\n",
      " [0.00804019]]\n",
      "[[-0.02074018]\n",
      " [-0.00801264]]\n",
      "Training:   0%|                      | 3103/1000000 [00:36<3:18:00, 83.91it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.02066913]\n",
      " [0.0079852 ]]\n",
      "[[-0.02059832]\n",
      " [-0.00795784]]\n",
      "[[0.02052776]\n",
      " [0.00793058]]\n",
      "[[-0.02045744]\n",
      " [-0.00790341]]\n",
      "[[0.02038736]\n",
      " [0.00787634]]\n",
      "[[-0.02031752]\n",
      " [-0.00784936]]\n",
      "[[0.02024792]\n",
      " [0.00782247]]\n",
      "[[-0.02017856]\n",
      " [-0.00779567]]\n",
      "[[0.02010944]\n",
      " [0.00776897]]\n",
      "Training:   0%|                      | 3112/1000000 [00:36<3:15:36, 84.94it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.02004055]\n",
      " [-0.00774235]]\n",
      "[[0.0199719 ]\n",
      " [0.00771583]]\n",
      "[[-0.01990348]\n",
      " [-0.0076894 ]]\n",
      "[[0.0198353 ]\n",
      " [0.00766306]]\n",
      "[[-0.01976735]\n",
      " [-0.00763681]]\n",
      "[[0.01969964]\n",
      " [0.00761065]]\n",
      "[[-0.01963215]\n",
      " [-0.00758458]]\n",
      "[[0.0195649]\n",
      " [0.0075586]]\n",
      "[[-0.01949788]\n",
      " [-0.0075327 ]]\n",
      "Training:   0%|                      | 3121/1000000 [00:36<3:15:02, 85.19it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.01943109]\n",
      " [0.0075069 ]]\n",
      "[[-0.01936452]\n",
      " [-0.00748118]]\n",
      "[[0.01929819]\n",
      " [0.00745556]]\n",
      "[[-0.01923208]\n",
      " [-0.00743002]]\n",
      "[[0.0191662 ]\n",
      " [0.00740456]]\n",
      "[[-0.01910054]\n",
      " [-0.0073792 ]]\n",
      "[[0.01903511]\n",
      " [0.00735392]]\n",
      "[[-0.0189699 ]\n",
      " [-0.00732873]]\n",
      "[[0.01890492]\n",
      " [0.00730362]]\n",
      "Training:   0%|                      | 3130/1000000 [00:36<3:13:32, 85.85it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.01884016]\n",
      " [-0.0072786 ]]\n",
      "[[0.01877562]\n",
      " [0.00725367]]\n",
      "[[-0.0187113 ]\n",
      " [-0.00722882]]\n",
      "[[0.01864721]\n",
      " [0.00720406]]\n",
      "[[-0.01858333]\n",
      " [-0.00717938]]\n",
      "[[0.01851967]\n",
      " [0.00715479]]\n",
      "[[-0.01845623]\n",
      " [-0.00713028]]\n",
      "[[0.018393  ]\n",
      " [0.00710585]]\n",
      "[[-0.01833   ]\n",
      " [-0.00708151]]\n",
      "Training:   0%|                      | 3139/1000000 [00:36<3:14:41, 85.33it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.0182672 ]\n",
      " [0.00705725]]\n",
      "[[-0.01820463]\n",
      " [-0.00703308]]\n",
      "[[0.01814227]\n",
      " [0.00700898]]\n",
      "[[-0.01808012]\n",
      " [-0.00698497]]\n",
      "[[0.01801818]\n",
      " [0.00696104]]\n",
      "[[-0.01795646]\n",
      " [-0.0069372 ]]\n",
      "[[0.01789495]\n",
      " [0.00691343]]\n",
      "[[-0.01783364]\n",
      " [-0.00688975]]\n",
      "[[0.01777255]\n",
      " [0.00686615]]\n",
      "Training:   0%|                      | 3148/1000000 [00:36<3:13:17, 85.95it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.01771167]\n",
      " [-0.00684263]]\n",
      "[[0.017651  ]\n",
      " [0.00681919]]\n",
      "[[-0.01759053]\n",
      " [-0.00679583]]\n",
      "[[0.01753027]\n",
      " [0.00677255]]\n",
      "[[-0.01747022]\n",
      " [-0.00674935]]\n",
      "[[0.01741038]\n",
      " [0.00672623]]\n",
      "[[-0.01735074]\n",
      " [-0.00670319]]\n",
      "[[0.0172913 ]\n",
      " [0.00668022]]\n",
      "[[-0.01723206]\n",
      " [-0.00665734]]\n",
      "Training:   0%|                      | 3157/1000000 [00:36<3:12:18, 86.39it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.01717303]\n",
      " [0.00663454]]\n",
      "[[-0.01711421]\n",
      " [-0.00661181]]\n",
      "[[0.01705558]\n",
      " [0.00658916]]\n",
      "[[-0.01699715]\n",
      " [-0.00656659]]\n",
      "[[0.01693893]\n",
      " [0.00654409]]\n",
      "[[-0.0168809 ]\n",
      " [-0.00652167]]\n",
      "[[0.01682307]\n",
      " [0.00649933]]\n",
      "[[-0.01676544]\n",
      " [-0.00647707]]\n",
      "[[0.01670801]\n",
      " [0.00645488]]\n",
      "Training:   0%|                      | 3166/1000000 [00:36<3:12:10, 86.45it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.01665078]\n",
      " [-0.00643277]]\n",
      "[[0.01659374]\n",
      " [0.00641073]]\n",
      "[[-0.01653689]\n",
      " [-0.00638877]]\n",
      "[[0.01648025]\n",
      " [0.00636689]]\n",
      "[[-0.01642379]\n",
      " [-0.00634508]]\n",
      "[[0.01636753]\n",
      " [0.00632334]]\n",
      "[[-0.01631146]\n",
      " [-0.00630168]]\n",
      "[[0.01625558]\n",
      " [0.00628009]]\n",
      "[[-0.0161999 ]\n",
      " [-0.00625858]]\n",
      "Training:   0%|                      | 3175/1000000 [00:37<3:11:49, 86.61it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.0161444 ]\n",
      " [0.00623714]]\n",
      "[[-0.0160891 ]\n",
      " [-0.00621577]]\n",
      "[[0.01603398]\n",
      " [0.00619448]]\n",
      "[[-0.01597906]\n",
      " [-0.00617326]]\n",
      "[[0.01592432]\n",
      " [0.00615211]]\n",
      "[[-0.01586977]\n",
      " [-0.00613104]]\n",
      "[[0.01581541]\n",
      " [0.00611004]]\n",
      "[[-0.01576123]\n",
      " [-0.00608911]]\n",
      "[[0.01570724]\n",
      " [0.00606825]]\n",
      "Training:   0%|                      | 3184/1000000 [00:37<3:12:33, 86.28it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.01565343]\n",
      " [-0.00604746]]\n",
      "[[0.01559981]\n",
      " [0.00602674]]\n",
      "[[-0.01554637]\n",
      " [-0.0060061 ]]\n",
      "[[0.01549311]\n",
      " [0.00598552]]\n",
      "[[-0.01544004]\n",
      " [-0.00596502]]\n",
      "[[0.01538715]\n",
      " [0.00594459]]\n",
      "[[-0.01533444]\n",
      " [-0.00592422]]\n",
      "[[0.01528191]\n",
      " [0.00590393]]\n",
      "[[-0.01522956]\n",
      " [-0.0058837 ]]\n",
      "Training:   0%|                      | 3193/1000000 [00:37<3:12:03, 86.51it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.01517739]\n",
      " [0.00586355]]\n",
      "[[-0.01512539]\n",
      " [-0.00584346]]\n",
      "[[0.01507358]\n",
      " [0.00582344]]\n",
      "[[-0.01502194]\n",
      " [-0.00580349]]\n",
      "[[0.01497048]\n",
      " [0.00578361]]\n",
      "[[-0.0149192]\n",
      " [-0.0057638]]\n",
      "[[0.01486809]\n",
      " [0.00574406]]\n",
      "[[-0.01481716]\n",
      " [-0.00572438]]\n",
      "Training:   0%|                      | 3193/1000000 [00:37<3:12:03, 86.51it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.0147664 ]\n",
      " [0.00570477]]\n",
      "Training:   0%|                      | 3202/1000000 [00:37<3:14:49, 85.27it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.01471582]\n",
      " [-0.00568523]]\n",
      "[[0.01466541]\n",
      " [0.00566575]]\n",
      "[[-0.01461517]\n",
      " [-0.00564634]]\n",
      "[[0.01456511]\n",
      " [0.005627  ]]\n",
      "[[-0.01451521]\n",
      " [-0.00560773]]\n",
      "[[0.01446549]\n",
      " [0.00558852]]\n",
      "[[-0.01441593]\n",
      " [-0.00556937]]\n",
      "[[0.01436655]\n",
      " [0.00555029]]\n",
      "[[-0.01431734]\n",
      " [-0.00553128]]\n",
      "Training:   0%|                      | 3211/1000000 [00:37<3:12:36, 86.25it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.01426829]\n",
      " [0.00551233]]\n",
      "[[-0.01421941]\n",
      " [-0.00549345]]\n",
      "[[0.0141707 ]\n",
      " [0.00547463]]\n",
      "[[-0.01412216]\n",
      " [-0.00545588]]\n",
      "[[0.01407378]\n",
      " [0.00543719]]\n",
      "[[-0.01402557]\n",
      " [-0.00541856]]\n",
      "[[0.01397752]\n",
      " [0.0054    ]]\n",
      "[[-0.01392964]\n",
      " [-0.0053815 ]]\n",
      "[[0.01388193]\n",
      " [0.00536307]]\n",
      "Training:   0%|                      | 3220/1000000 [00:37<3:13:29, 85.86it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.01383437]\n",
      " [-0.00534469]]\n",
      "[[0.01378698]\n",
      " [0.00532639]]\n",
      "[[-0.01373975]\n",
      " [-0.00530814]]\n",
      "[[0.01369268]\n",
      " [0.00528996]]\n",
      "[[-0.01364578]\n",
      " [-0.00527183]]\n",
      "[[0.01359903]\n",
      " [0.00525378]]\n",
      "[[-0.01355245]\n",
      " [-0.00523578]]\n",
      "[[0.01350602]\n",
      " [0.00521784]]\n",
      "[[-0.01345976]\n",
      " [-0.00519997]]\n",
      "Training:   0%|                      | 3229/1000000 [00:37<3:12:35, 86.26it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.01341365]\n",
      " [0.00518215]]\n",
      "[[-0.0133677]\n",
      " [-0.0051644]]\n",
      "[[0.01332191]\n",
      " [0.00514671]]\n",
      "[[-0.01327627]\n",
      " [-0.00512908]]\n",
      "[[0.01323079]\n",
      " [0.00511151]]\n",
      "[[-0.01318547]\n",
      " [-0.005094  ]]\n",
      "[[0.0131403 ]\n",
      " [0.00507655]]\n",
      "[[-0.01309528]\n",
      " [-0.00505916]]\n",
      "[[0.01305043]\n",
      " [0.00504183]]\n",
      "Training:   0%|                      | 3238/1000000 [00:37<3:14:34, 85.38it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.01300572]\n",
      " [-0.00502456]]\n",
      "[[0.01296117]\n",
      " [0.00500735]]\n",
      "[[-0.01291677]\n",
      " [-0.00499019]]\n",
      "[[0.01287252]\n",
      " [0.0049731 ]]\n",
      "[[-0.01282842]\n",
      " [-0.00495606]]\n",
      "[[0.01278448]\n",
      " [0.00493908]]\n",
      "[[-0.01274068]\n",
      " [-0.00492217]]\n",
      "[[0.01269704]\n",
      " [0.0049053 ]]\n",
      "[[-0.01265354]\n",
      " [-0.0048885 ]]\n",
      "Training:   0%|                      | 3247/1000000 [00:37<3:14:52, 85.25it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.0126102 ]\n",
      " [0.00487175]]\n",
      "[[-0.012567  ]\n",
      " [-0.00485507]]\n",
      "[[0.01252395]\n",
      " [0.00483843]]\n",
      "[[-0.01248105]\n",
      " [-0.00482186]]\n",
      "[[0.01243829]\n",
      " [0.00480534]]\n",
      "[[-0.01239568]\n",
      " [-0.00478888]]\n",
      "[[0.01235322]\n",
      " [0.00477247]]\n",
      "[[-0.0123109 ]\n",
      " [-0.00475613]]\n",
      "[[0.01226873]\n",
      " [0.00473983]]\n",
      "Training:   0%|                      | 3256/1000000 [00:38<3:14:14, 85.53it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.0122267]\n",
      " [-0.0047236]]\n",
      "[[0.01218482]\n",
      " [0.00470742]]\n",
      "[[-0.01214308]\n",
      " [-0.00469129]]\n",
      "[[0.01210148]\n",
      " [0.00467522]]\n",
      "[[-0.01206003]\n",
      " [-0.0046592 ]]\n",
      "[[0.01201871]\n",
      " [0.00464324]]\n",
      "[[-0.01197754]\n",
      " [-0.00462734]]\n",
      "[[0.01193651]\n",
      " [0.00461149]]\n",
      "[[-0.01189562]\n",
      " [-0.00459569]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:   0%|                      | 3265/1000000 [00:38<3:12:57, 86.09it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.01185487]\n",
      " [0.00457995]]\n",
      "[[-0.01181426]\n",
      " [-0.00456426]]\n",
      "[[0.01177379]\n",
      " [0.00454862]]\n",
      "[[-0.01173346]\n",
      " [-0.00453304]]\n",
      "[[0.01169326]\n",
      " [0.00451751]]\n",
      "[[-0.01165321]\n",
      " [-0.00450204]]\n",
      "[[0.01161329]\n",
      " [0.00448661]]\n",
      "[[-0.0115735 ]\n",
      " [-0.00447124]]\n",
      "[[0.01153386]\n",
      " [0.00445593]]\n",
      "Training:   0%|                      | 3274/1000000 [00:38<3:12:37, 86.24it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.01149435]\n",
      " [-0.00444066]]\n",
      "[[0.01145497]\n",
      " [0.00442545]]\n",
      "[[-0.01141573]\n",
      " [-0.00441029]]\n",
      "[[0.01137663]\n",
      " [0.00439518]]\n",
      "[[-0.01133765]\n",
      " [-0.00438013]]\n",
      "[[0.01129882]\n",
      " [0.00436512]]\n",
      "[[-0.01126011]\n",
      " [-0.00435017]]\n",
      "[[0.01122154]\n",
      " [0.00433527]]\n",
      "[[-0.0111831 ]\n",
      " [-0.00432042]]\n",
      "Training:   0%|                      | 3283/1000000 [00:38<3:12:23, 86.34it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.01114479]\n",
      " [0.00430562]]\n",
      "[[-0.01110661]\n",
      " [-0.00429087]]\n",
      "[[0.01106856]\n",
      " [0.00427617]]\n",
      "[[-0.01103065]\n",
      " [-0.00426152]]\n",
      "[[0.01099286]\n",
      " [0.00424692]]\n",
      "[[-0.0109552 ]\n",
      " [-0.00423237]]\n",
      "[[0.01091767]\n",
      " [0.00421787]]\n",
      "[[-0.01088027]\n",
      " [-0.00420343]]\n",
      "[[0.010843  ]\n",
      " [0.00418903]]\n",
      "Training:   0%|                      | 3292/1000000 [00:38<3:11:40, 86.67it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.01080586]\n",
      " [-0.00417468]]\n",
      "[[0.01076884]\n",
      " [0.00416037]]\n",
      "[[-0.01073195]\n",
      " [-0.00414612]]\n",
      "[[0.01069519]\n",
      " [0.00413192]]\n",
      "[[-0.01065855]\n",
      " [-0.00411777]]\n",
      "[[0.01062204]\n",
      " [0.00410366]]\n",
      "[[-0.01058565]\n",
      " [-0.0040896 ]]\n",
      "[[0.01054939]\n",
      " [0.00407559]]\n",
      "[[-0.01051325]\n",
      " [-0.00406163]]\n",
      "Training:   0%|                      | 3301/1000000 [00:38<3:13:56, 85.66it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.01047724]\n",
      " [0.00404772]]\n",
      "[[-0.01044135]\n",
      " [-0.00403385]]\n",
      "[[0.01040558]\n",
      " [0.00402003]]\n",
      "[[-0.01036993]\n",
      " [-0.00400626]]\n",
      "[[0.01033441]\n",
      " [0.00399254]]\n",
      "[[-0.01029901]\n",
      " [-0.00397886]]\n",
      "[[0.01026373]\n",
      " [0.00396523]]\n",
      "[[-0.01022857]\n",
      " [-0.00395165]]\n",
      "[[0.01019353]\n",
      " [0.00393811]]\n",
      "Training:   0%|                      | 3310/1000000 [00:38<3:14:24, 85.45it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.01015861]\n",
      " [-0.00392462]]\n",
      "[[0.01012381]\n",
      " [0.00391118]]\n",
      "[[-0.01008913]\n",
      " [-0.00389778]]\n",
      "[[0.01005457]\n",
      " [0.00388443]]\n",
      "[[-0.01002013]\n",
      " [-0.00387112]]\n",
      "[[0.0099858 ]\n",
      " [0.00385786]]\n",
      "[[-0.00995159]\n",
      " [-0.00384464]]\n",
      "[[0.0099175 ]\n",
      " [0.00383147]]\n",
      "[[-0.00988353]\n",
      " [-0.00381835]]\n",
      "Training:   0%|                      | 3319/1000000 [00:38<3:14:44, 85.30it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00984967]\n",
      " [0.00380527]]\n",
      "[[-0.00981593]\n",
      " [-0.00379223]]\n",
      "[[0.0097823 ]\n",
      " [0.00377924]]\n",
      "[[-0.00974879]\n",
      " [-0.0037663 ]]\n",
      "[[0.0097154 ]\n",
      " [0.00375339]]\n",
      "[[-0.00968212]\n",
      " [-0.00374054]]\n",
      "[[0.00964895]\n",
      " [0.00372772]]\n",
      "[[-0.0096159 ]\n",
      " [-0.00371495]]\n",
      "[[0.00958296]\n",
      " [0.00370223]]\n",
      "Training:   0%|                      | 3328/1000000 [00:38<3:14:58, 85.20it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00955013]\n",
      " [-0.00368954]]\n",
      "[[0.00951741]\n",
      " [0.00367691]]\n",
      "[[-0.00948481]\n",
      " [-0.00366431]]\n",
      "[[0.00945232]\n",
      " [0.00365176]]\n",
      "[[-0.00941994]\n",
      " [-0.00363925]]\n",
      "[[0.00938767]\n",
      " [0.00362678]]\n",
      "[[-0.00935551]\n",
      " [-0.00361436]]\n",
      "[[0.00932346]\n",
      " [0.00360198]]\n",
      "[[-0.00929152]\n",
      " [-0.00358964]]\n",
      "Training:   0%|                      | 3337/1000000 [00:38<3:13:20, 85.91it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.0092597 ]\n",
      " [0.00357734]]\n",
      "[[-0.00922798]\n",
      " [-0.00356509]]\n",
      "[[0.00919636]\n",
      " [0.00355287]]\n",
      "[[-0.00916486]\n",
      " [-0.0035407 ]]\n",
      "[[0.00913347]\n",
      " [0.00352857]]\n",
      "[[-0.00910218]\n",
      " [-0.00351649]]\n",
      "[[0.009071  ]\n",
      " [0.00350444]]\n",
      "[[-0.00903992]\n",
      " [-0.00349243]]\n",
      "[[0.00900896]\n",
      " [0.00348047]]\n",
      "Training:   0%|                      | 3346/1000000 [00:39<3:14:33, 85.38it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.0089781 ]\n",
      " [-0.00346855]]\n",
      "[[0.00894734]\n",
      " [0.00345667]]\n",
      "[[-0.00891669]\n",
      " [-0.00344482]]\n",
      "[[0.00888614]\n",
      " [0.00343302]]\n",
      "[[-0.0088557 ]\n",
      " [-0.00342126]]\n",
      "[[0.00882537]\n",
      " [0.00340954]]\n",
      "[[-0.00879514]\n",
      " [-0.00339786]]\n",
      "[[0.00876501]\n",
      " [0.00338622]]\n",
      "[[-0.00873498]\n",
      " [-0.00337462]]\n",
      "Training:   0%|                      | 3355/1000000 [00:39<3:13:10, 85.99it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00870506]\n",
      " [0.00336306]]\n",
      "[[-0.00867524]\n",
      " [-0.00335154]]\n",
      "[[0.00864552]\n",
      " [0.00334006]]\n",
      "[[-0.0086159 ]\n",
      " [-0.00332862]]\n",
      "[[0.00858639]\n",
      " [0.00331722]]\n",
      "[[-0.00855698]\n",
      " [-0.00330585]]\n",
      "[[0.00852766]\n",
      " [0.00329453]]\n",
      "[[-0.00849845]\n",
      " [-0.00328324]]\n",
      "[[0.00846934]\n",
      " [0.003272  ]]\n",
      "Training:   0%|                      | 3364/1000000 [00:39<3:12:46, 86.17it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00844032]\n",
      " [-0.00326079]]\n",
      "[[0.00841141]\n",
      " [0.00324962]]\n",
      "[[-0.0083826 ]\n",
      " [-0.00323849]]\n",
      "[[0.00835388]\n",
      " [0.00322739]]\n",
      "[[-0.00832526]\n",
      " [-0.00321634]]\n",
      "[[0.00829675]\n",
      " [0.00320532]]\n",
      "[[-0.00826832]\n",
      " [-0.00319434]]\n",
      "[[0.00824  ]\n",
      " [0.0031834]]\n",
      "[[-0.00821177]\n",
      " [-0.00317249]]\n",
      "Training:   0%|                      | 3373/1000000 [00:39<3:14:41, 85.31it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00818364]\n",
      " [0.00316162]]\n",
      "[[-0.00815561]\n",
      " [-0.00315079]]\n",
      "[[0.00812767]\n",
      " [0.00314   ]]\n",
      "[[-0.00809983]\n",
      " [-0.00312924]]\n",
      "[[0.00807208]\n",
      " [0.00311852]]\n",
      "[[-0.00804443]\n",
      " [-0.00310784]]\n",
      "[[0.00801687]\n",
      " [0.00309719]]\n",
      "[[-0.00798941]\n",
      " [-0.00308658]]\n",
      "[[0.00796204]\n",
      " [0.00307601]]\n",
      "Training:   0%|                      | 3382/1000000 [00:39<3:14:43, 85.30it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00793477]\n",
      " [-0.00306547]]\n",
      "[[0.00790758]\n",
      " [0.00305497]]\n",
      "[[-0.0078805 ]\n",
      " [-0.00304451]]\n",
      "[[0.0078535 ]\n",
      " [0.00303408]]\n",
      "[[-0.0078266 ]\n",
      " [-0.00302368]]\n",
      "[[0.00779979]\n",
      " [0.00301333]]\n",
      "[[-0.00777307]\n",
      " [-0.003003  ]]\n",
      "[[0.00774644]\n",
      " [0.00299272]]\n",
      "[[-0.0077199 ]\n",
      " [-0.00298247]]\n",
      "Training:   0%|                      | 3391/1000000 [00:39<3:15:30, 84.96it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00769346]\n",
      " [0.00297225]]\n",
      "[[-0.0076671 ]\n",
      " [-0.00296207]]\n",
      "[[0.00764084]\n",
      " [0.00295192]]\n",
      "[[-0.00761466]\n",
      " [-0.00294181]]\n",
      "[[0.00758858]\n",
      " [0.00293173]]\n",
      "[[-0.00756258]\n",
      " [-0.00292169]]\n",
      "[[0.00753668]\n",
      " [0.00291168]]\n",
      "[[-0.00751086]\n",
      " [-0.0029017 ]]\n",
      "[[0.00748513]\n",
      " [0.00289176]]\n",
      "Training:   0%|                      | 3400/1000000 [00:39<3:12:44, 86.18it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00745949]\n",
      " [-0.00288186]]\n",
      "Training:   0%|                      | 3400/1000000 [00:39<3:12:44, 86.18it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00743394]\n",
      " [0.00287199]]\n",
      "[[-0.00740847]\n",
      " [-0.00286215]]\n",
      "[[0.00738309]\n",
      " [0.00285234]]\n",
      "[[-0.0073578 ]\n",
      " [-0.00284257]]\n",
      "[[0.0073326 ]\n",
      " [0.00283283]]\n",
      "[[-0.00730748]\n",
      " [-0.00282313]]\n",
      "[[0.00728244]\n",
      " [0.00281346]]\n",
      "[[-0.0072575 ]\n",
      " [-0.00280382]]\n",
      "Training:   0%|                      | 3409/1000000 [00:39<3:16:53, 84.36it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00723264]\n",
      " [0.00279422]]\n",
      "[[-0.00720786]\n",
      " [-0.00278464]]\n",
      "[[0.00718317]\n",
      " [0.00277511]]\n",
      "[[-0.00715856]\n",
      " [-0.0027656 ]]\n",
      "[[0.00713404]\n",
      " [0.00275613]]\n",
      "[[-0.0071096 ]\n",
      " [-0.00274668]]\n",
      "[[0.00708525]\n",
      " [0.00273727]]\n",
      "[[-0.00706097]\n",
      " [-0.0027279 ]]\n",
      "[[0.00703679]\n",
      " [0.00271855]]\n",
      "Training:   0%|                      | 3418/1000000 [00:39<3:14:15, 85.50it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00701268]\n",
      " [-0.00270924]]\n",
      "[[0.00698866]\n",
      " [0.00269996]]\n",
      "[[-0.00696472]\n",
      " [-0.00269071]]\n",
      "[[0.00694086]\n",
      " [0.00268149]]\n",
      "[[-0.00691708]\n",
      " [-0.00267231]]\n",
      "[[0.00689339]\n",
      " [0.00266315]]\n",
      "[[-0.00686977]\n",
      " [-0.00265403]]\n",
      "[[0.00684624]\n",
      " [0.00264494]]\n",
      "[[-0.00682279]\n",
      " [-0.00263588]]\n",
      "Training:   0%|                      | 3427/1000000 [00:40<3:13:31, 85.83it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00679942]\n",
      " [0.00262685]]\n",
      "[[-0.00677612]\n",
      " [-0.00261785]]\n",
      "[[0.00675291]\n",
      " [0.00260888]]\n",
      "[[-0.00672978]\n",
      " [-0.00259995]]\n",
      "[[0.00670672]\n",
      " [0.00259104]]\n",
      "[[-0.00668375]\n",
      " [-0.00258216]]\n",
      "[[0.00666085]\n",
      " [0.00257332]]\n",
      "[[-0.00663804]\n",
      " [-0.0025645 ]]\n",
      "[[0.0066153 ]\n",
      " [0.00255572]]\n",
      "Training:   0%|                      | 3436/1000000 [00:40<3:12:27, 86.30it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00659264]\n",
      " [-0.00254696]]\n",
      "[[0.00657005]\n",
      " [0.00253824]]\n",
      "[[-0.00654754]\n",
      " [-0.00252954]]\n",
      "[[0.00652512]\n",
      " [0.00252088]]\n",
      "[[-0.00650276]\n",
      " [-0.00251224]]\n",
      "[[0.00648049]\n",
      " [0.00250364]]\n",
      "[[-0.00645829]\n",
      " [-0.00249506]]\n",
      "[[0.00643616]\n",
      " [0.00248651]]\n",
      "[[-0.00641412]\n",
      " [-0.00247799]]\n",
      "Training:   0%|                      | 3445/1000000 [00:40<3:12:15, 86.39it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00639214]\n",
      " [0.00246951]]\n",
      "[[-0.00637025]\n",
      " [-0.00246105]]\n",
      "[[0.00634842]\n",
      " [0.00245262]]\n",
      "[[-0.00632668]\n",
      " [-0.00244421]]\n",
      "[[0.006305  ]\n",
      " [0.00243584]]\n",
      "[[-0.00628341]\n",
      " [-0.0024275 ]]\n",
      "[[0.00626188]\n",
      " [0.00241918]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00624043]\n",
      " [-0.00241089]]\n",
      "[[0.00621905]\n",
      " [0.00240263]]\n",
      "Training:   0%|                      | 3454/1000000 [00:40<3:12:40, 86.20it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00619775]\n",
      " [-0.0023944 ]]\n",
      "[[0.00617652]\n",
      " [0.0023862 ]]\n",
      "[[-0.00615536]\n",
      " [-0.00237803]]\n",
      "[[0.00613427]\n",
      " [0.00236988]]\n",
      "[[-0.00611326]\n",
      " [-0.00236176]]\n",
      "[[0.00609232]\n",
      " [0.00235367]]\n",
      "[[-0.00607145]\n",
      " [-0.00234561]]\n",
      "[[0.00605065]\n",
      " [0.00233757]]\n",
      "[[-0.00602992]\n",
      " [-0.00232957]]\n",
      "Training:   0%|                      | 3463/1000000 [00:40<3:11:51, 86.57it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00600927]\n",
      " [0.00232159]]\n",
      "[[-0.00598868]\n",
      " [-0.00231363]]\n",
      "[[0.00596817]\n",
      " [0.00230571]]\n",
      "[[-0.00594772]\n",
      " [-0.00229781]]\n",
      "[[0.00592735]\n",
      " [0.00228994]]\n",
      "[[-0.00590704]\n",
      " [-0.00228209]]\n",
      "[[0.00588681]\n",
      " [0.00227428]]\n",
      "[[-0.00586664]\n",
      " [-0.00226649]]\n",
      "[[0.00584654]\n",
      " [0.00225872]]\n",
      "Training:   0%|                      | 3472/1000000 [00:40<3:12:29, 86.28it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00582652]\n",
      " [-0.00225098]]\n",
      "[[0.00580656]\n",
      " [0.00224327]]\n",
      "[[-0.00578667]\n",
      " [-0.00223559]]\n",
      "[[0.00576684]\n",
      " [0.00222793]]\n",
      "[[-0.00574709]\n",
      " [-0.0022203 ]]\n",
      "[[0.0057274 ]\n",
      " [0.00221269]]\n",
      "[[-0.00570778]\n",
      " [-0.00220511]]\n",
      "[[0.00568823]\n",
      " [0.00219756]]\n",
      "[[-0.00566874]\n",
      " [-0.00219003]]\n",
      "Training:   0%|                      | 3481/1000000 [00:40<3:11:10, 86.87it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00564932]\n",
      " [0.00218253]]\n",
      "[[-0.00562997]\n",
      " [-0.00217505]]\n",
      "[[0.00561069]\n",
      " [0.0021676 ]]\n",
      "[[-0.00559147]\n",
      " [-0.00216018]]\n",
      "[[0.00557231]\n",
      " [0.00215278]]\n",
      "[[-0.00555322]\n",
      " [-0.0021454 ]]\n",
      "[[0.0055342 ]\n",
      " [0.00213805]]\n",
      "[[-0.00551524]\n",
      " [-0.00213073]]\n",
      "[[0.00549635]\n",
      " [0.00212343]]\n",
      "Training:   0%|                      | 3490/1000000 [00:40<3:13:01, 86.04it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00547752]\n",
      " [-0.00211615]]\n",
      "[[0.00545876]\n",
      " [0.00210891]]\n",
      "[[-0.00544006]\n",
      " [-0.00210168]]\n",
      "[[0.00542142]\n",
      " [0.00209448]]\n",
      "[[-0.00540285]\n",
      " [-0.00208731]]\n",
      "[[0.00538434]\n",
      " [0.00208016]]\n",
      "[[-0.0053659 ]\n",
      " [-0.00207303]]\n",
      "[[0.00534751]\n",
      " [0.00206593]]\n",
      "[[-0.0053292 ]\n",
      " [-0.00205885]]\n",
      "Training:   0%|                      | 3499/1000000 [00:40<3:14:18, 85.47it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00531094]\n",
      " [0.0020518 ]]\n",
      "[[-0.00529275]\n",
      " [-0.00204477]]\n",
      "Training:   0%|                      | 3499/1000000 [00:40<3:14:18, 85.47it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00527462]\n",
      " [0.00203777]]\n",
      "[[-0.00525655]\n",
      " [-0.00203079]]\n",
      "[[0.00523854]\n",
      " [0.00202383]]\n",
      "[[-0.0052206]\n",
      " [-0.0020169]]\n",
      "[[0.00520271]\n",
      " [0.00200999]]\n",
      "[[-0.00518489]\n",
      " [-0.0020031 ]]\n",
      "[[0.00516713]\n",
      " [0.00199624]]\n",
      "Training:   0%|                      | 3508/1000000 [00:40<3:17:41, 84.01it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00514943]\n",
      " [-0.0019894 ]]\n",
      "[[0.00513179]\n",
      " [0.00198259]]\n",
      "[[-0.00511421]\n",
      " [-0.00197579]]\n",
      "[[0.00509669]\n",
      " [0.00196903]]\n",
      "[[-0.00507923]\n",
      " [-0.00196228]]\n",
      "[[0.00506183]\n",
      " [0.00195556]]\n",
      "[[-0.00504449]\n",
      " [-0.00194886]]\n",
      "[[0.00502721]\n",
      " [0.00194218]]\n",
      "[[-0.00500999]\n",
      " [-0.00193553]]\n",
      "Training:   0%|                      | 3517/1000000 [00:41<3:16:28, 84.53it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00499283]\n",
      " [0.0019289 ]]\n",
      "[[-0.00497572]\n",
      " [-0.00192229]]\n",
      "[[0.00495868]\n",
      " [0.00191571]]\n",
      "[[-0.00494169]\n",
      " [-0.00190915]]\n",
      "[[0.00492476]\n",
      " [0.00190261]]\n",
      "[[-0.00490789]\n",
      " [-0.00189609]]\n",
      "[[0.00489108]\n",
      " [0.00188959]]\n",
      "[[-0.00487432]\n",
      " [-0.00188312]]\n",
      "[[0.00485763]\n",
      " [0.00187667]]\n",
      "Training:   0%|                      | 3526/1000000 [00:41<3:15:37, 84.90it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00484099]\n",
      " [-0.00187024]]\n",
      "[[0.0048244 ]\n",
      " [0.00186383]]\n",
      "[[-0.00480788]\n",
      " [-0.00185745]]\n",
      "[[0.00479141]\n",
      " [0.00185109]]\n",
      "[[-0.00477499]\n",
      " [-0.00184474]]\n",
      "[[0.00475864]\n",
      " [0.00183843]]\n",
      "[[-0.00474233]\n",
      " [-0.00183213]]\n",
      "[[0.00472609]\n",
      " [0.00182585]]\n",
      "[[-0.0047099]\n",
      " [-0.0018196]]\n",
      "Training:   0%|                      | 3535/1000000 [00:41<3:15:34, 84.92it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00469377]\n",
      " [0.00181336]]\n",
      "[[-0.00467769]\n",
      " [-0.00180715]]\n",
      "[[0.00466166]\n",
      " [0.00180096]]\n",
      "[[-0.00464569]\n",
      " [-0.00179479]]\n",
      "[[0.00462978]\n",
      " [0.00178864]]\n",
      "[[-0.00461392]\n",
      " [-0.00178252]]\n",
      "[[0.00459811]\n",
      " [0.00177641]]\n",
      "[[-0.00458236]\n",
      " [-0.00177032]]\n",
      "[[0.00456666]\n",
      " [0.00176426]]\n",
      "Training:   0%|                      | 3544/1000000 [00:41<3:14:26, 85.41it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00455102]\n",
      " [-0.00175822]]\n",
      "[[0.00453543]\n",
      " [0.00175219]]\n",
      "[[-0.00451989]\n",
      " [-0.00174619]]\n",
      "[[0.00450441]\n",
      " [0.00174021]]\n",
      "[[-0.00448898]\n",
      " [-0.00173425]]\n",
      "[[0.0044736 ]\n",
      " [0.00172831]]\n",
      "[[-0.00445828]\n",
      " [-0.00172239]]\n",
      "[[0.00444301]\n",
      " [0.00171649]]\n",
      "[[-0.00442779]\n",
      " [-0.00171061]]\n",
      "Training:   0%|                      | 3553/1000000 [00:41<3:11:59, 86.50it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00441262]\n",
      " [0.00170475]]\n",
      "[[-0.0043975 ]\n",
      " [-0.00169891]]\n",
      "[[0.00438244]\n",
      " [0.00169309]]\n",
      "[[-0.00436743]\n",
      " [-0.00168729]]\n",
      "[[0.00435246]\n",
      " [0.00168151]]\n",
      "[[-0.00433755]\n",
      " [-0.00167575]]\n",
      "[[0.0043227 ]\n",
      " [0.00167001]]\n",
      "[[-0.00430789]\n",
      " [-0.00166429]]\n",
      "[[0.00429313]\n",
      " [0.00165858]]\n",
      "Training:   0%|                      | 3562/1000000 [00:41<3:14:41, 85.30it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00427842]\n",
      " [-0.0016529 ]]\n",
      "[[0.00426377]\n",
      " [0.00164724]]\n",
      "[[-0.00424916]\n",
      " [-0.0016416 ]]\n",
      "[[0.00423461]\n",
      " [0.00163597]]\n",
      "[[-0.0042201 ]\n",
      " [-0.00163037]]\n",
      "[[0.00420564]\n",
      " [0.00162478]]\n",
      "[[-0.00419124]\n",
      " [-0.00161922]]\n",
      "[[0.00417688]\n",
      " [0.00161367]]\n",
      "[[-0.00416257]\n",
      " [-0.00160814]]\n",
      "Training:   0%|                      | 3571/1000000 [00:41<3:14:55, 85.20it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00414831]\n",
      " [0.00160264]]\n",
      "[[-0.0041341 ]\n",
      " [-0.00159715]]\n",
      "[[0.00411994]\n",
      " [0.00159167]]\n",
      "[[-0.00410583]\n",
      " [-0.00158622]]\n",
      "[[0.00409176]\n",
      " [0.00158079]]\n",
      "[[-0.00407774]\n",
      " [-0.00157537]]\n",
      "[[0.00406377]\n",
      " [0.00156998]]\n",
      "[[-0.00404985]\n",
      " [-0.0015646 ]]\n",
      "[[0.00403598]\n",
      " [0.00155924]]\n",
      "Training:   0%|                      | 3580/1000000 [00:41<3:14:32, 85.37it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00402215]\n",
      " [-0.0015539 ]]\n",
      "[[0.00400838]\n",
      " [0.00154857]]\n",
      "[[-0.00399465]\n",
      " [-0.00154327]]\n",
      "[[0.00398096]\n",
      " [0.00153798]]\n",
      "[[-0.00396732]\n",
      " [-0.00153271]]\n",
      "[[0.00395373]\n",
      " [0.00152746]]\n",
      "[[-0.00394019]\n",
      " [-0.00152223]]\n",
      "[[0.00392669]\n",
      " [0.00151702]]\n",
      "[[-0.00391324]\n",
      " [-0.00151182]]\n",
      "Training:   0%|                      | 3589/1000000 [00:41<3:13:09, 85.98it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00389984]\n",
      " [0.00150664]]\n",
      "[[-0.00388648]\n",
      " [-0.00150148]]\n",
      "[[0.00387316]\n",
      " [0.00149634]]\n",
      "[[-0.00385989]\n",
      " [-0.00149121]]\n",
      "[[0.00384667]\n",
      " [0.0014861 ]]\n",
      "[[-0.00383349]\n",
      " [-0.00148101]]\n",
      "[[0.00382036]\n",
      " [0.00147594]]\n",
      "[[-0.00380728]\n",
      " [-0.00147088]]\n",
      "[[0.00379423]\n",
      " [0.00146584]]\n",
      "Training:   0%|                      | 3598/1000000 [00:42<3:13:17, 85.91it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00378124]\n",
      " [-0.00146082]]\n",
      "[[0.00376828]\n",
      " [0.00145582]]\n",
      "[[-0.00375537]\n",
      " [-0.00145083]]\n",
      "Training:   0%|                      | 3598/1000000 [00:42<3:13:17, 85.91it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00374251]\n",
      " [0.00144586]]\n",
      "[[-0.00372969]\n",
      " [-0.00144091]]\n",
      "[[0.00371691]\n",
      " [0.00143597]]\n",
      "[[-0.00370418]\n",
      " [-0.00143105]]\n",
      "[[0.00369149]\n",
      " [0.00142615]]\n",
      "[[-0.00367885]\n",
      " [-0.00142126]]\n",
      "Training:   0%|                      | 3607/1000000 [00:42<3:16:09, 84.66it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00366624]\n",
      " [0.0014164 ]]\n",
      "[[-0.00365368]\n",
      " [-0.00141154]]\n",
      "[[0.00364117]\n",
      " [0.00140671]]\n",
      "[[-0.00362869]\n",
      " [-0.00140189]]\n",
      "[[0.00361626]\n",
      " [0.00139709]]\n",
      "[[-0.00360388]\n",
      " [-0.0013923 ]]\n",
      "[[0.00359153]\n",
      " [0.00138753]]\n",
      "[[-0.00357923]\n",
      " [-0.00138278]]\n",
      "[[0.00356697]\n",
      " [0.00137804]]\n",
      "Training:   0%|                      | 3616/1000000 [00:42<3:15:23, 84.99it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00355475]\n",
      " [-0.00137332]]\n",
      "[[0.00354257]\n",
      " [0.00136862]]\n",
      "[[-0.00353043]\n",
      " [-0.00136393]]\n",
      "[[0.00351834]\n",
      " [0.00135926]]\n",
      "[[-0.00350629]\n",
      " [-0.0013546 ]]\n",
      "[[0.00349428]\n",
      " [0.00134996]]\n",
      "[[-0.00348231]\n",
      " [-0.00134534]]\n",
      "[[0.00347038]\n",
      " [0.00134073]]\n",
      "[[-0.00345849]\n",
      " [-0.00133613]]\n",
      "Training:   0%|                      | 3625/1000000 [00:42<3:14:18, 85.46it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00344664]\n",
      " [0.00133156]]\n",
      "[[-0.00343484]\n",
      " [-0.001327  ]]\n",
      "[[0.00342307]\n",
      " [0.00132245]]\n",
      "[[-0.00341134]\n",
      " [-0.00131792]]\n",
      "[[0.00339966]\n",
      " [0.0013134 ]]\n",
      "[[-0.00338801]\n",
      " [-0.00130891]]\n",
      "[[0.0033764 ]\n",
      " [0.00130442]]\n",
      "[[-0.00336484]\n",
      " [-0.00129995]]\n",
      "[[0.00335331]\n",
      " [0.0012955 ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:   0%|                      | 3634/1000000 [00:42<3:11:53, 86.54it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00334182]\n",
      " [-0.00129106]]\n",
      "[[0.00333038]\n",
      " [0.00128664]]\n",
      "[[-0.00331897]\n",
      " [-0.00128223]]\n",
      "[[0.0033076 ]\n",
      " [0.00127784]]\n",
      "[[-0.00329627]\n",
      " [-0.00127346]]\n",
      "[[0.00328498]\n",
      " [0.0012691 ]]\n",
      "[[-0.00327372]\n",
      " [-0.00126475]]\n",
      "[[0.00326251]\n",
      " [0.00126042]]\n",
      "[[-0.00325133]\n",
      " [-0.0012561 ]]\n",
      "Training:   0%|                      | 3643/1000000 [00:42<3:12:24, 86.31it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.0032402]\n",
      " [0.0012518]]\n",
      "[[-0.0032291 ]\n",
      " [-0.00124751]]\n",
      "[[0.00321803]\n",
      " [0.00124324]]\n",
      "[[-0.00320701]\n",
      " [-0.00123898]]\n",
      "[[0.00319602]\n",
      " [0.00123473]]\n",
      "[[-0.00318508]\n",
      " [-0.0012305 ]]\n",
      "[[0.00317416]\n",
      " [0.00122629]]\n",
      "[[-0.00316329]\n",
      " [-0.00122209]]\n",
      "[[0.00315246]\n",
      " [0.0012179 ]]\n",
      "Training:   0%|                      | 3652/1000000 [00:42<3:12:12, 86.39it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00314166]\n",
      " [-0.00121373]]\n",
      "[[0.00313089]\n",
      " [0.00120957]]\n",
      "[[-0.00312017]\n",
      " [-0.00120543]]\n",
      "[[0.00310948]\n",
      " [0.0012013 ]]\n",
      "[[-0.00309883]\n",
      " [-0.00119718]]\n",
      "[[0.00308821]\n",
      " [0.00119308]]\n",
      "[[-0.00307763]\n",
      " [-0.001189  ]]\n",
      "[[0.00306709]\n",
      " [0.00118492]]\n",
      "[[-0.00305658]\n",
      " [-0.00118086]]\n",
      "Training:   0%|                      | 3661/1000000 [00:42<3:13:44, 85.71it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00304611]\n",
      " [0.00117682]]\n",
      "[[-0.00303568]\n",
      " [-0.00117279]]\n",
      "[[0.00302528]\n",
      " [0.00116877]]\n",
      "[[-0.00301492]\n",
      " [-0.00116477]]\n",
      "[[0.00300459]\n",
      " [0.00116078]]\n",
      "[[-0.0029943]\n",
      " [-0.0011568]]\n",
      "[[0.00298404]\n",
      " [0.00115284]]\n",
      "[[-0.00297382]\n",
      " [-0.00114889]]\n",
      "[[0.00296363]\n",
      " [0.00114495]]\n",
      "Training:   0%|                      | 3670/1000000 [00:42<3:14:48, 85.24it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00295348]\n",
      " [-0.00114103]]\n",
      "[[0.00294336]\n",
      " [0.00113712]]\n",
      "[[-0.00293328]\n",
      " [-0.00113323]]\n",
      "[[0.00292323]\n",
      " [0.00112934]]\n",
      "[[-0.00291321]\n",
      " [-0.00112548]]\n",
      "[[0.00290324]\n",
      " [0.00112162]]\n",
      "[[-0.00289329]\n",
      " [-0.00111778]]\n",
      "[[0.00288338]\n",
      " [0.00111395]]\n",
      "[[-0.0028735 ]\n",
      " [-0.00111013]]\n",
      "Training:   0%|                      | 3679/1000000 [00:42<3:15:33, 84.92it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00286366]\n",
      " [0.00110633]]\n",
      "[[-0.00285385]\n",
      " [-0.00110254]]\n",
      "[[0.00284407]\n",
      " [0.00109876]]\n",
      "[[-0.00283433]\n",
      " [-0.001095  ]]\n",
      "[[0.00282462]\n",
      " [0.00109125]]\n",
      "[[-0.00281494]\n",
      " [-0.00108751]]\n",
      "[[0.0028053 ]\n",
      " [0.00108378]]\n",
      "[[-0.00279569]\n",
      " [-0.00108007]]\n",
      "[[0.00278611]\n",
      " [0.00107637]]\n",
      "Training:   0%|                      | 3688/1000000 [00:43<3:16:04, 84.69it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00277657]\n",
      " [-0.00107268]]\n",
      "[[0.00276706]\n",
      " [0.00106901]]\n",
      "[[-0.00275758]\n",
      " [-0.00106535]]\n",
      "[[0.00274813]\n",
      " [0.0010617 ]]\n",
      "[[-0.00273872]\n",
      " [-0.00105806]]\n",
      "[[0.00272934]\n",
      " [0.00105444]]\n",
      "[[-0.00271999]\n",
      " [-0.00105082]]\n",
      "[[0.00271067]\n",
      " [0.00104723]]\n",
      "[[-0.00270138]\n",
      " [-0.00104364]]\n",
      "Training:   0%|                      | 3697/1000000 [00:43<3:14:13, 85.49it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00269213]\n",
      " [0.00104006]]\n",
      "[[-0.00268291]\n",
      " [-0.0010365 ]]\n",
      "[[0.00267372]\n",
      " [0.00103295]]\n",
      "[[-0.00266456]\n",
      " [-0.00102941]]\n",
      "Training:   0%|                      | 3697/1000000 [00:43<3:14:13, 85.49it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00265543]\n",
      " [0.00102588]]\n",
      "[[-0.00264633]\n",
      " [-0.00102237]]\n",
      "[[0.00263727]\n",
      " [0.00101887]]\n",
      "[[-0.00262823]\n",
      " [-0.00101538]]\n",
      "[[0.00261923]\n",
      " [0.0010119 ]]\n",
      "Training:   0%|                      | 3706/1000000 [00:43<3:17:21, 84.14it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00261026]\n",
      " [-0.00100843]]\n",
      "[[0.00260132]\n",
      " [0.00100498]]\n",
      "[[-0.00259241]\n",
      " [-0.00100154]]\n",
      "[[0.00258353]\n",
      " [0.0009981 ]]\n",
      "[[-0.00257468]\n",
      " [-0.00099469]]\n",
      "[[0.00256586]\n",
      " [0.00099128]]\n",
      "[[-0.00255707]\n",
      " [-0.00098788]]\n",
      "[[0.00254831]\n",
      " [0.0009845 ]]\n",
      "[[-0.00253958]\n",
      " [-0.00098113]]\n",
      "Training:   0%|                      | 3715/1000000 [00:43<3:17:53, 83.91it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00253088]\n",
      " [0.00097777]]\n",
      "[[-0.00252221]\n",
      " [-0.00097442]]\n",
      "[[0.00251357]\n",
      " [0.00097108]]\n",
      "[[-0.00250496]\n",
      " [-0.00096775]]\n",
      "[[0.00249638]\n",
      " [0.00096444]]\n",
      "[[-0.00248782]\n",
      " [-0.00096113]]\n",
      "[[0.0024793 ]\n",
      " [0.00095784]]\n",
      "[[-0.00247081]\n",
      " [-0.00095456]]\n",
      "[[0.00246234]\n",
      " [0.00095129]]\n",
      "Training:   0%|                      | 3724/1000000 [00:43<3:17:42, 83.98it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00245391]\n",
      " [-0.00094803]]\n",
      "[[0.0024455 ]\n",
      " [0.00094478]]\n",
      "[[-0.00243713]\n",
      " [-0.00094155]]\n",
      "[[0.00242878]\n",
      " [0.00093832]]\n",
      "[[-0.00242046]\n",
      " [-0.00093511]]\n",
      "[[0.00241217]\n",
      " [0.0009319 ]]\n",
      "[[-0.0024039 ]\n",
      " [-0.00092871]]\n",
      "[[0.00239567]\n",
      " [0.00092553]]\n",
      "[[-0.00238746]\n",
      " [-0.00092236]]\n",
      "Training:   0%|                      | 3733/1000000 [00:43<3:17:01, 84.28it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00237928]\n",
      " [0.0009192 ]]\n",
      "[[-0.00237113]\n",
      " [-0.00091605]]\n",
      "[[0.00236301]\n",
      " [0.00091291]]\n",
      "[[-0.00235491]\n",
      " [-0.00090978]]\n",
      "[[0.00234685]\n",
      " [0.00090667]]\n",
      "[[-0.00233881]\n",
      " [-0.00090356]]\n",
      "[[0.0023308 ]\n",
      " [0.00090047]]\n",
      "[[-0.00232281]\n",
      " [-0.00089738]]\n",
      "[[0.00231485]\n",
      " [0.00089431]]\n",
      "Training:   0%|                      | 3742/1000000 [00:43<3:19:18, 83.31it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00230693]\n",
      " [-0.00089124]]\n",
      "[[0.00229902]\n",
      " [0.00088819]]\n",
      "[[-0.00229115]\n",
      " [-0.00088515]]\n",
      "[[0.0022833 ]\n",
      " [0.00088212]]\n",
      "[[-0.00227548]\n",
      " [-0.0008791 ]]\n",
      "[[0.00226768]\n",
      " [0.00087608]]\n",
      "[[-0.00225991]\n",
      " [-0.00087308]]\n",
      "[[0.00225217]\n",
      " [0.00087009]]\n",
      "[[-0.00224446]\n",
      " [-0.00086711]]\n",
      "Training:   0%|                      | 3751/1000000 [00:43<3:17:35, 84.03it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00223677]\n",
      " [0.00086414]]\n",
      "[[-0.00222911]\n",
      " [-0.00086118]]\n",
      "[[0.00222147]\n",
      " [0.00085823]]\n",
      "[[-0.00221386]\n",
      " [-0.00085529]]\n",
      "[[0.00220628]\n",
      " [0.00085236]]\n",
      "[[-0.00219872]\n",
      " [-0.00084944]]\n",
      "[[0.00219119]\n",
      " [0.00084653]]\n",
      "[[-0.00218368]\n",
      " [-0.00084363]]\n",
      "[[0.0021762 ]\n",
      " [0.00084074]]\n",
      "Training:   0%|                      | 3760/1000000 [00:43<3:16:56, 84.31it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00216874]\n",
      " [-0.00083786]]\n",
      "[[0.00216132]\n",
      " [0.00083499]]\n",
      "[[-0.00215391]\n",
      " [-0.00083213]]\n",
      "[[0.00214653]\n",
      " [0.00082928]]\n",
      "[[-0.00213918]\n",
      " [-0.00082644]]\n",
      "[[0.00213185]\n",
      " [0.00082361]]\n",
      "[[-0.00212455]\n",
      " [-0.00082079]]\n",
      "[[0.00211727]\n",
      " [0.00081797]]\n",
      "[[-0.00211002]\n",
      " [-0.00081517]]\n",
      "Training:   0%|                      | 3769/1000000 [00:44<3:15:23, 84.98it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00210279]\n",
      " [0.00081238]]\n",
      "[[-0.00209559]\n",
      " [-0.0008096 ]]\n",
      "[[0.00208841]\n",
      " [0.00080682]]\n",
      "[[-0.00208125]\n",
      " [-0.00080406]]\n",
      "[[0.00207412]\n",
      " [0.00080131]]\n",
      "[[-0.00206702]\n",
      " [-0.00079856]]\n",
      "[[0.00205994]\n",
      " [0.00079583]]\n",
      "[[-0.00205288]\n",
      " [-0.0007931 ]]\n",
      "[[0.00204585]\n",
      " [0.00079038]]\n",
      "Training:   0%|                      | 3778/1000000 [00:44<3:15:57, 84.73it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00203884]\n",
      " [-0.00078767]]\n",
      "[[0.00203186]\n",
      " [0.00078498]]\n",
      "[[-0.0020249 ]\n",
      " [-0.00078229]]\n",
      "[[0.00201796]\n",
      " [0.00077961]]\n",
      "[[-0.00201105]\n",
      " [-0.00077694]]\n",
      "[[0.00200416]\n",
      " [0.00077428]]\n",
      "[[-0.00199729]\n",
      " [-0.00077162]]\n",
      "[[0.00199045]\n",
      " [0.00076898]]\n",
      "[[-0.00198363]\n",
      " [-0.00076635]]\n",
      "Training:   0%|                      | 3787/1000000 [00:44<3:14:08, 85.53it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00197684]\n",
      " [0.00076372]]\n",
      "[[-0.00197007]\n",
      " [-0.0007611 ]]\n",
      "[[0.00196332]\n",
      " [0.0007585 ]]\n",
      "[[-0.00195659]\n",
      " [-0.0007559 ]]\n",
      "[[0.00194989]\n",
      " [0.00075331]]\n",
      "[[-0.00194321]\n",
      " [-0.00075073]]\n",
      "[[0.00193655]\n",
      " [0.00074816]]\n",
      "[[-0.00192992]\n",
      " [-0.00074559]]\n",
      "[[0.00192331]\n",
      " [0.00074304]]\n",
      "Training:   0%|                      | 3796/1000000 [00:44<3:14:06, 85.54it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00191672]\n",
      " [-0.00074049]]\n",
      "[[0.00191015]\n",
      " [0.00073796]]\n",
      "[[-0.00190361]\n",
      " [-0.00073543]]\n",
      "[[0.00189709]\n",
      " [0.00073291]]\n",
      "[[-0.00189059]\n",
      " [-0.0007304 ]]\n",
      "Training:   0%|                      | 3796/1000000 [00:44<3:14:06, 85.54it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00188411]\n",
      " [0.0007279 ]]\n",
      "[[-0.00187766]\n",
      " [-0.0007254 ]]\n",
      "[[0.00187123]\n",
      " [0.00072292]]\n",
      "[[-0.00186482]\n",
      " [-0.00072044]]\n",
      "Training:   0%|                      | 3805/1000000 [00:44<3:17:15, 84.17it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00185843]\n",
      " [0.00071798]]\n",
      "[[-0.00185206]\n",
      " [-0.00071552]]\n",
      "[[0.00184572]\n",
      " [0.00071306]]\n",
      "[[-0.0018394 ]\n",
      " [-0.00071062]]\n",
      "[[0.00183309]\n",
      " [0.00070819]]\n",
      "[[-0.00182681]\n",
      " [-0.00070576]]\n",
      "[[0.00182056]\n",
      " [0.00070334]]\n",
      "[[-0.00181432]\n",
      " [-0.00070093]]\n",
      "[[0.0018081 ]\n",
      " [0.00069853]]\n",
      "Training:   0%|                      | 3814/1000000 [00:44<3:16:09, 84.64it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00180191]\n",
      " [-0.00069614]]\n",
      "[[0.00179574]\n",
      " [0.00069376]]\n",
      "[[-0.00178959]\n",
      " [-0.00069138]]\n",
      "[[0.00178346]\n",
      " [0.00068901]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00177735]\n",
      " [-0.00068665]]\n",
      "[[0.00177126]\n",
      " [0.0006843 ]]\n",
      "[[-0.00176519]\n",
      " [-0.00068195]]\n",
      "[[0.00175914]\n",
      " [0.00067962]]\n",
      "[[-0.00175312]\n",
      " [-0.00067729]]\n",
      "Training:   0%|                      | 3823/1000000 [00:44<3:14:49, 85.22it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00174711]\n",
      " [0.00067497]]\n",
      "[[-0.00174113]\n",
      " [-0.00067266]]\n",
      "[[0.00173516]\n",
      " [0.00067035]]\n",
      "[[-0.00172922]\n",
      " [-0.00066806]]\n",
      "[[0.0017233 ]\n",
      " [0.00066577]]\n",
      "[[-0.00171739]\n",
      " [-0.00066349]]\n",
      "[[0.00171151]\n",
      " [0.00066121]]\n",
      "[[-0.00170565]\n",
      " [-0.00065895]]\n",
      "[[0.0016998 ]\n",
      " [0.00065669]]\n",
      "Training:   0%|                      | 3832/1000000 [00:44<3:15:00, 85.14it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00169398]\n",
      " [-0.00065444]]\n",
      "[[0.00168818]\n",
      " [0.0006522 ]]\n",
      "[[-0.00168239]\n",
      " [-0.00064997]]\n",
      "[[0.00167663]\n",
      " [0.00064774]]\n",
      "[[-0.00167089]\n",
      " [-0.00064552]]\n",
      "[[0.00166516]\n",
      " [0.00064331]]\n",
      "[[-0.00165946]\n",
      " [-0.00064111]]\n",
      "[[0.00165377]\n",
      " [0.00063891]]\n",
      "[[-0.00164811]\n",
      " [-0.00063672]]\n",
      "Training:   0%|                      | 3841/1000000 [00:44<3:14:01, 85.57it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00164246]\n",
      " [0.00063454]]\n",
      "[[-0.00163684]\n",
      " [-0.00063237]]\n",
      "[[0.00163123]\n",
      " [0.0006302 ]]\n",
      "[[-0.00162564]\n",
      " [-0.00062804]]\n",
      "[[0.00162007]\n",
      " [0.00062589]]\n",
      "[[-0.00161452]\n",
      " [-0.00062375]]\n",
      "[[0.00160899]\n",
      " [0.00062161]]\n",
      "[[-0.00160348]\n",
      " [-0.00061948]]\n",
      "[[0.00159799]\n",
      " [0.00061736]]\n",
      "Training:   0%|                      | 3850/1000000 [00:44<3:14:02, 85.56it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00159251]\n",
      " [-0.00061524]]\n",
      "[[0.00158706]\n",
      " [0.00061314]]\n",
      "[[-0.00158162]\n",
      " [-0.00061104]]\n",
      "[[0.0015762 ]\n",
      " [0.00060894]]\n",
      "[[-0.0015708 ]\n",
      " [-0.00060686]]\n",
      "[[0.00156542]\n",
      " [0.00060478]]\n",
      "[[-0.00156006]\n",
      " [-0.00060271]]\n",
      "[[0.00155472]\n",
      " [0.00060064]]\n",
      "[[-0.00154939]\n",
      " [-0.00059858]]\n",
      "Training:   0%|                      | 3859/1000000 [00:45<3:13:20, 85.87it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00154408]\n",
      " [0.00059653]]\n",
      "[[-0.00153879]\n",
      " [-0.00059449]]\n",
      "[[0.00153352]\n",
      " [0.00059245]]\n",
      "[[-0.00152827]\n",
      " [-0.00059042]]\n",
      "[[0.00152303]\n",
      " [0.0005884 ]]\n",
      "[[-0.00151782]\n",
      " [-0.00058638]]\n",
      "[[0.00151262]\n",
      " [0.00058438]]\n",
      "[[-0.00150744]\n",
      " [-0.00058237]]\n",
      "[[0.00150227]\n",
      " [0.00058038]]\n",
      "Training:   0%|                      | 3868/1000000 [00:45<3:13:58, 85.59it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00149713]\n",
      " [-0.00057839]]\n",
      "[[0.001492  ]\n",
      " [0.00057641]]\n",
      "[[-0.00148689]\n",
      " [-0.00057444]]\n",
      "[[0.00148179]\n",
      " [0.00057247]]\n",
      "[[-0.00147672]\n",
      " [-0.00057051]]\n",
      "[[0.00147166]\n",
      " [0.00056855]]\n",
      "[[-0.00146662]\n",
      " [-0.0005666 ]]\n",
      "[[0.00146159]\n",
      " [0.00056466]]\n",
      "[[-0.00145659]\n",
      " [-0.00056273]]\n",
      "Training:   0%|                      | 3877/1000000 [00:45<3:14:39, 85.29it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.0014516]\n",
      " [0.0005608]]\n",
      "[[-0.00144662]\n",
      " [-0.00055888]]\n",
      "[[0.00144167]\n",
      " [0.00055697]]\n",
      "[[-0.00143673]\n",
      " [-0.00055506]]\n",
      "[[0.00143181]\n",
      " [0.00055316]]\n",
      "[[-0.0014269 ]\n",
      " [-0.00055126]]\n",
      "[[0.00142201]\n",
      " [0.00054937]]\n",
      "[[-0.00141714]\n",
      " [-0.00054749]]\n",
      "[[0.00141229]\n",
      " [0.00054562]]\n",
      "Training:   0%|                      | 3886/1000000 [00:45<3:12:40, 86.17it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00140745]\n",
      " [-0.00054375]]\n",
      "[[0.00140263]\n",
      " [0.00054188]]\n",
      "[[-0.00139782]\n",
      " [-0.00054003]]\n",
      "[[0.00139304]\n",
      " [0.00053818]]\n",
      "[[-0.00138826]\n",
      " [-0.00053633]]\n",
      "[[0.00138351]\n",
      " [0.0005345 ]]\n",
      "[[-0.00137877]\n",
      " [-0.00053267]]\n",
      "[[0.00137405]\n",
      " [0.00053084]]\n",
      "[[-0.00136934]\n",
      " [-0.00052902]]\n",
      "Training:   0%|                      | 3895/1000000 [00:45<3:12:56, 86.05it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00136465]\n",
      " [0.00052721]]\n",
      "[[-0.00135997]\n",
      " [-0.0005254 ]]\n",
      "[[0.00135531]\n",
      " [0.0005236 ]]\n",
      "[[-0.00135067]\n",
      " [-0.00052181]]\n",
      "[[0.00134605]\n",
      " [0.00052002]]\n",
      "[[-0.00134143]\n",
      " [-0.00051824]]\n",
      "Training:   0%|                      | 3895/1000000 [00:45<3:12:56, 86.05it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00133684]\n",
      " [0.00051647]]\n",
      "[[-0.00133226]\n",
      " [-0.0005147 ]]\n",
      "[[0.0013277 ]\n",
      " [0.00051293]]\n",
      "Training:   0%|                      | 3904/1000000 [00:45<3:15:20, 84.99it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00132315]\n",
      " [-0.00051118]]\n",
      "[[0.00131861]\n",
      " [0.00050943]]\n",
      "[[-0.0013141 ]\n",
      " [-0.00050768]]\n",
      "[[0.0013096 ]\n",
      " [0.00050594]]\n",
      "[[-0.00130511]\n",
      " [-0.00050421]]\n",
      "[[0.00130064]\n",
      " [0.00050248]]\n",
      "[[-0.00129618]\n",
      " [-0.00050076]]\n",
      "[[0.00129174]\n",
      " [0.00049904]]\n",
      "[[-0.00128732]\n",
      " [-0.00049734]]\n",
      "Training:   0%|                      | 3913/1000000 [00:45<3:13:08, 85.95it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00128291]\n",
      " [0.00049563]]\n",
      "[[-0.00127851]\n",
      " [-0.00049393]]\n",
      "[[0.00127413]\n",
      " [0.00049224]]\n",
      "[[-0.00126977]\n",
      " [-0.00049056]]\n",
      "[[0.00126542]\n",
      " [0.00048888]]\n",
      "[[-0.00126108]\n",
      " [-0.0004872 ]]\n",
      "[[0.00125676]\n",
      " [0.00048553]]\n",
      "[[-0.00125246]\n",
      " [-0.00048387]]\n",
      "[[0.00124817]\n",
      " [0.00048221]]\n",
      "Training:   0%|                      | 3922/1000000 [00:45<3:13:16, 85.90it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00124389]\n",
      " [-0.00048056]]\n",
      "[[0.00123963]\n",
      " [0.00047891]]\n",
      "[[-0.00123539]\n",
      " [-0.00047727]]\n",
      "[[0.00123115]\n",
      " [0.00047564]]\n",
      "[[-0.00122694]\n",
      " [-0.00047401]]\n",
      "[[0.00122273]\n",
      " [0.00047238]]\n",
      "[[-0.00121854]\n",
      " [-0.00047077]]\n",
      "[[0.00121437]\n",
      " [0.00046915]]\n",
      "[[-0.00121021]\n",
      " [-0.00046755]]\n",
      "Training:   0%|                      | 3931/1000000 [00:45<3:15:34, 84.89it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00120606]\n",
      " [0.00046594]]\n",
      "[[-0.00120193]\n",
      " [-0.00046435]]\n",
      "[[0.00119782]\n",
      " [0.00046276]]\n",
      "[[-0.00119371]\n",
      " [-0.00046117]]\n",
      "[[0.00118962]\n",
      " [0.00045959]]\n",
      "[[-0.00118555]\n",
      " [-0.00045802]]\n",
      "[[0.00118149]\n",
      " [0.00045645]]\n",
      "[[-0.00117744]\n",
      " [-0.00045489]]\n",
      "[[0.00117341]\n",
      " [0.00045333]]\n",
      "Training:   0%|                      | 3940/1000000 [00:46<3:17:10, 84.19it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00116939]\n",
      " [-0.00045177]]\n",
      "[[0.00116538]\n",
      " [0.00045023]]\n",
      "[[-0.00116139]\n",
      " [-0.00044868]]\n",
      "[[0.00115741]\n",
      " [0.00044715]]\n",
      "[[-0.00115345]\n",
      " [-0.00044562]]\n",
      "[[0.00114949]\n",
      " [0.00044409]]\n",
      "[[-0.00114556]\n",
      " [-0.00044257]]\n",
      "[[0.00114163]\n",
      " [0.00044105]]\n",
      "[[-0.00113772]\n",
      " [-0.00043954]]\n",
      "Training:   0%|                      | 3949/1000000 [00:46<3:17:11, 84.19it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00113382]\n",
      " [0.00043804]]\n",
      "[[-0.00112994]\n",
      " [-0.00043653]]\n",
      "[[0.00112607]\n",
      " [0.00043504]]\n",
      "[[-0.00112221]\n",
      " [-0.00043355]]\n",
      "[[0.00111837]\n",
      " [0.00043206]]\n",
      "[[-0.00111454]\n",
      " [-0.00043058]]\n",
      "[[0.00111072]\n",
      " [0.00042911]]\n",
      "[[-0.00110691]\n",
      " [-0.00042764]]\n",
      "[[0.00110312]\n",
      " [0.00042617]]\n",
      "Training:   0%|                      | 3958/1000000 [00:46<3:16:39, 84.42it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00109934]\n",
      " [-0.00042471]]\n",
      "[[0.00109558]\n",
      " [0.00042326]]\n",
      "[[-0.00109182]\n",
      " [-0.00042181]]\n",
      "[[0.00108808]\n",
      " [0.00042036]]\n",
      "[[-0.00108436]\n",
      " [-0.00041892]]\n",
      "[[0.00108064]\n",
      " [0.00041749]]\n",
      "[[-0.00107694]\n",
      " [-0.00041606]]\n",
      "[[0.00107325]\n",
      " [0.00041463]]\n",
      "[[-0.00106957]\n",
      " [-0.00041321]]\n",
      "Training:   0%|                      | 3967/1000000 [00:46<3:15:10, 85.06it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00106591]\n",
      " [0.0004118 ]]\n",
      "[[-0.00106226]\n",
      " [-0.00041039]]\n",
      "[[0.00105862]\n",
      " [0.00040898]]\n",
      "[[-0.00105499]\n",
      " [-0.00040758]]\n",
      "[[0.00105138]\n",
      " [0.00040618]]\n",
      "[[-0.00104778]\n",
      " [-0.00040479]]\n",
      "[[0.00104419]\n",
      " [0.00040341]]\n",
      "[[-0.00104061]\n",
      " [-0.00040202]]\n",
      "[[0.00103705]\n",
      " [0.00040065]]\n",
      "Training:   0%|                      | 3976/1000000 [00:46<3:14:07, 85.51it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00103349]\n",
      " [-0.00039927]]\n",
      "[[0.00102995]\n",
      " [0.00039791]]\n",
      "[[-0.00102643]\n",
      " [-0.00039654]]\n",
      "[[0.00102291]\n",
      " [0.00039519]]\n",
      "[[-0.00101941]\n",
      " [-0.00039383]]\n",
      "[[0.00101591]\n",
      " [0.00039248]]\n",
      "[[-0.00101243]\n",
      " [-0.00039114]]\n",
      "[[0.00100897]\n",
      " [0.0003898 ]]\n",
      "[[-0.00100551]\n",
      " [-0.00038846]]\n",
      "Training:   0%|                      | 3985/1000000 [00:46<3:14:30, 85.34it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00100206]\n",
      " [0.00038713]]\n",
      "[[-0.00099863]\n",
      " [-0.00038581]]\n",
      "[[0.00099521]\n",
      " [0.00038448]]\n",
      "[[-0.0009918 ]\n",
      " [-0.00038317]]\n",
      "[[0.0009884 ]\n",
      " [0.00038185]]\n",
      "[[-0.00098502]\n",
      " [-0.00038055]]\n",
      "[[0.00098164]\n",
      " [0.00037924]]\n",
      "[[-0.00097828]\n",
      " [-0.00037794]]\n",
      "[[0.00097493]\n",
      " [0.00037665]]\n",
      "Training:   0%|                      | 3994/1000000 [00:46<3:14:46, 85.23it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00097159]\n",
      " [-0.00037536]]\n",
      "[[0.00096826]\n",
      " [0.00037407]]\n",
      "[[-0.00096494]\n",
      " [-0.00037279]]\n",
      "[[0.00096164]\n",
      " [0.00037151]]\n",
      "[[-0.00095835]\n",
      " [-0.00037024]]\n",
      "[[0.00095506]\n",
      " [0.00036897]]\n",
      "[[-0.00095179]\n",
      " [-0.00036771]]\n",
      "Training:   0%|                      | 3994/1000000 [00:46<3:14:46, 85.23it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00094853]\n",
      " [0.00036645]]\n",
      "[[-0.00094528]\n",
      " [-0.00036519]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:   0%|                      | 4003/1000000 [00:46<3:16:03, 84.67it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00094204]\n",
      " [0.00036394]]\n",
      "[[-0.00093882]\n",
      " [-0.0003627 ]]\n",
      "[[0.0009356 ]\n",
      " [0.00036145]]\n",
      "[[-0.00093239]\n",
      " [-0.00036022]]\n",
      "[[0.0009292 ]\n",
      " [0.00035898]]\n",
      "[[-0.00092602]\n",
      " [-0.00035775]]\n",
      "[[0.00092285]\n",
      " [0.00035653]]\n",
      "[[-0.00091968]\n",
      " [-0.00035531]]\n",
      "[[0.00091653]\n",
      " [0.00035409]]\n",
      "Training:   0%|                      | 4012/1000000 [00:46<3:14:45, 85.24it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00091339]\n",
      " [-0.00035288]]\n",
      "[[0.00091026]\n",
      " [0.00035167]]\n",
      "[[-0.00090715]\n",
      " [-0.00035046]]\n",
      "[[0.00090404]\n",
      " [0.00034926]]\n",
      "[[-0.00090094]\n",
      " [-0.00034806]]\n",
      "[[0.00089786]\n",
      " [0.00034687]]\n",
      "[[-0.00089478]\n",
      " [-0.00034568]]\n",
      "[[0.00089171]\n",
      " [0.0003445 ]]\n",
      "[[-0.00088866]\n",
      " [-0.00034332]]\n",
      "Training:   0%|                      | 4021/1000000 [00:47<3:15:07, 85.07it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00088562]\n",
      " [0.00034214]]\n",
      "[[-0.00088258]\n",
      " [-0.00034097]]\n",
      "[[0.00087956]\n",
      " [0.0003398 ]]\n",
      "[[-0.00087655]\n",
      " [-0.00033864]]\n",
      "[[0.00087354]\n",
      " [0.00033748]]\n",
      "[[-0.00087055]\n",
      " [-0.00033632]]\n",
      "[[0.00086757]\n",
      " [0.00033517]]\n",
      "[[-0.0008646 ]\n",
      " [-0.00033402]]\n",
      "[[0.00086163]\n",
      " [0.00033288]]\n",
      "Training:   0%|                      | 4030/1000000 [00:47<3:14:38, 85.28it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00085868]\n",
      " [-0.00033174]]\n",
      "[[0.00085574]\n",
      " [0.0003306 ]]\n",
      "[[-0.00085281]\n",
      " [-0.00032947]]\n",
      "[[0.00084989]\n",
      " [0.00032834]]\n",
      "[[-0.00084698]\n",
      " [-0.00032722]]\n",
      "[[0.00084408]\n",
      " [0.0003261 ]]\n",
      "[[-0.00084118]\n",
      " [-0.00032498]]\n",
      "[[0.0008383 ]\n",
      " [0.00032387]]\n",
      "[[-0.00083543]\n",
      " [-0.00032276]]\n",
      "Training:   0%|                      | 4039/1000000 [00:47<3:12:39, 86.16it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00083257]\n",
      " [0.00032165]]\n",
      "[[-0.00082972]\n",
      " [-0.00032055]]\n",
      "[[0.00082688]\n",
      " [0.00031945]]\n",
      "[[-0.00082404]\n",
      " [-0.00031836]]\n",
      "[[0.00082122]\n",
      " [0.00031727]]\n",
      "[[-0.00081841]\n",
      " [-0.00031618]]\n",
      "[[0.0008156]\n",
      " [0.0003151]]\n",
      "[[-0.00081281]\n",
      " [-0.00031402]]\n",
      "[[0.00081002]\n",
      " [0.00031294]]\n",
      "Training:   0%|                      | 4048/1000000 [00:47<3:10:42, 87.04it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00080725]\n",
      " [-0.00031187]]\n",
      "[[0.00080448]\n",
      " [0.0003108 ]]\n",
      "[[-0.00080173]\n",
      " [-0.00030974]]\n",
      "[[0.00079898]\n",
      " [0.00030867]]\n",
      "[[-0.00079625]\n",
      " [-0.00030762]]\n",
      "[[0.00079352]\n",
      " [0.00030656]]\n",
      "[[-0.0007908 ]\n",
      " [-0.00030551]]\n",
      "[[0.00078809]\n",
      " [0.00030447]]\n",
      "[[-0.00078539]\n",
      " [-0.00030342]]\n",
      "Training:   0%|                      | 4057/1000000 [00:47<3:11:00, 86.91it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.0007827 ]\n",
      " [0.00030238]]\n",
      "[[-0.00078002]\n",
      " [-0.00030135]]\n",
      "[[0.00077735]\n",
      " [0.00030032]]\n",
      "[[-0.00077468]\n",
      " [-0.00029929]]\n",
      "[[0.00077203]\n",
      " [0.00029826]]\n",
      "[[-0.00076939]\n",
      " [-0.00029724]]\n",
      "[[0.00076675]\n",
      " [0.00029622]]\n",
      "[[-0.00076412]\n",
      " [-0.00029521]]\n",
      "[[0.00076151]\n",
      " [0.0002942 ]]\n",
      "Training:   0%|                      | 4066/1000000 [00:47<3:11:12, 86.81it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.0007589 ]\n",
      " [-0.00029319]]\n",
      "[[0.0007563 ]\n",
      " [0.00029218]]\n",
      "[[-0.00075371]\n",
      " [-0.00029118]]\n",
      "[[0.00075112]\n",
      " [0.00029019]]\n",
      "[[-0.00074855]\n",
      " [-0.00028919]]\n",
      "[[0.00074599]\n",
      " [0.0002882 ]]\n",
      "[[-0.00074343]\n",
      " [-0.00028721]]\n",
      "[[0.00074089]\n",
      " [0.00028623]]\n",
      "[[-0.00073835]\n",
      " [-0.00028525]]\n",
      "Training:   0%|                      | 4075/1000000 [00:47<3:12:27, 86.25it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00073582]\n",
      " [0.00028427]]\n",
      "[[-0.0007333]\n",
      " [-0.0002833]]\n",
      "[[0.00073079]\n",
      " [0.00028233]]\n",
      "[[-0.00072828]\n",
      " [-0.00028136]]\n",
      "[[0.00072579]\n",
      " [0.0002804 ]]\n",
      "[[-0.0007233 ]\n",
      " [-0.00027944]]\n",
      "[[0.00072082]\n",
      " [0.00027848]]\n",
      "[[-0.00071835]\n",
      " [-0.00027752]]\n",
      "[[0.00071589]\n",
      " [0.00027657]]\n",
      "Training:   0%|                      | 4084/1000000 [00:47<3:11:40, 86.60it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00071344]\n",
      " [-0.00027563]]\n",
      "[[0.000711  ]\n",
      " [0.00027468]]\n",
      "[[-0.00070856]\n",
      " [-0.00027374]]\n",
      "[[0.00070613]\n",
      " [0.0002728 ]]\n",
      "[[-0.00070371]\n",
      " [-0.00027187]]\n",
      "[[0.0007013 ]\n",
      " [0.00027094]]\n",
      "[[-0.0006989 ]\n",
      " [-0.00027001]]\n",
      "[[0.00069651]\n",
      " [0.00026908]]\n",
      "[[-0.00069412]\n",
      " [-0.00026816]]\n",
      "Training:   0%|                      | 4093/1000000 [00:47<3:11:07, 86.85it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00069174]\n",
      " [0.00026724]]\n",
      "[[-0.00068937]\n",
      " [-0.00026633]]\n",
      "[[0.00068701]\n",
      " [0.00026542]]\n",
      "[[-0.00068466]\n",
      " [-0.00026451]]\n",
      "[[0.00068231]\n",
      " [0.0002636 ]]\n",
      "[[-0.00067998]\n",
      " [-0.0002627 ]]\n",
      "[[0.00067765]\n",
      " [0.0002618 ]]\n",
      "[[-0.00067533]\n",
      " [-0.0002609 ]]\n",
      "Training:   0%|                      | 4093/1000000 [00:47<3:11:07, 86.85it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00067301]\n",
      " [0.00026001]]\n",
      "Training:   0%|                      | 4102/1000000 [00:47<3:13:30, 85.78it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00067071]\n",
      " [-0.00025912]]\n",
      "[[0.00066841]\n",
      " [0.00025823]]\n",
      "[[-0.00066612]\n",
      " [-0.00025735]]\n",
      "[[0.00066384]\n",
      " [0.00025646]]\n",
      "[[-0.00066156]\n",
      " [-0.00025558]]\n",
      "[[0.0006593 ]\n",
      " [0.00025471]]\n",
      "[[-0.00065704]\n",
      " [-0.00025384]]\n",
      "[[0.00065479]\n",
      " [0.00025297]]\n",
      "[[-0.00065255]\n",
      " [-0.0002521 ]]\n",
      "Training:   0%|                      | 4111/1000000 [00:48<3:12:24, 86.27it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00065031]\n",
      " [0.00025124]]\n",
      "[[-0.00064808]\n",
      " [-0.00025038]]\n",
      "[[0.00064586]\n",
      " [0.00024952]]\n",
      "[[-0.00064365]\n",
      " [-0.00024866]]\n",
      "[[0.00064144]\n",
      " [0.00024781]]\n",
      "[[-0.00063925]\n",
      " [-0.00024696]]\n",
      "[[0.00063706]\n",
      " [0.00024612]]\n",
      "[[-0.00063488]\n",
      " [-0.00024527]]\n",
      "[[0.0006327 ]\n",
      " [0.00024443]]\n",
      "Training:   0%|                      | 4120/1000000 [00:48<3:14:23, 85.38it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00063053]\n",
      " [-0.0002436 ]]\n",
      "[[0.00062837]\n",
      " [0.00024276]]\n",
      "[[-0.00062622]\n",
      " [-0.00024193]]\n",
      "[[0.00062408]\n",
      " [0.0002411 ]]\n",
      "[[-0.00062194]\n",
      " [-0.00024028]]\n",
      "[[0.00061981]\n",
      " [0.00023945]]\n",
      "[[-0.00061768]\n",
      " [-0.00023863]]\n",
      "[[0.00061557]\n",
      " [0.00023782]]\n",
      "[[-0.00061346]\n",
      " [-0.000237  ]]\n",
      "Training:   0%|                      | 4129/1000000 [00:48<3:13:16, 85.88it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00061136]\n",
      " [0.00023619]]\n",
      "[[-0.00060926]\n",
      " [-0.00023538]]\n",
      "[[0.00060718]\n",
      " [0.00023457]]\n",
      "[[-0.0006051 ]\n",
      " [-0.00023377]]\n",
      "[[0.00060302]\n",
      " [0.00023297]]\n",
      "[[-0.00060096]\n",
      " [-0.00023217]]\n",
      "[[0.0005989 ]\n",
      " [0.00023138]]\n",
      "[[-0.00059685]\n",
      " [-0.00023058]]\n",
      "[[0.0005948 ]\n",
      " [0.00022979]]\n",
      "[[-0.00059277]\n",
      " [-0.00022901]]\n",
      "Training:   0%|                      | 4139/1000000 [00:48<3:10:01, 87.34it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00059073]\n",
      " [0.00022822]]\n",
      "[[-0.00058871]\n",
      " [-0.00022744]]\n",
      "[[0.00058669]\n",
      " [0.00022666]]\n",
      "[[-0.00058468]\n",
      " [-0.00022588]]\n",
      "[[0.00058268]\n",
      " [0.00022511]]\n",
      "[[-0.00058069]\n",
      " [-0.00022434]]\n",
      "[[0.0005787 ]\n",
      " [0.00022357]]\n",
      "[[-0.00057671]\n",
      " [-0.0002228 ]]\n",
      "[[0.00057474]\n",
      " [0.00022204]]\n",
      "Training:   0%|                      | 4148/1000000 [00:48<3:10:31, 87.12it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00057277]\n",
      " [-0.00022128]]\n",
      "[[0.00057081]\n",
      " [0.00022052]]\n",
      "[[-0.00056885]\n",
      " [-0.00021977]]\n",
      "[[0.0005669 ]\n",
      " [0.00021901]]\n",
      "[[-0.00056496]\n",
      " [-0.00021826]]\n",
      "[[0.00056303]\n",
      " [0.00021752]]\n",
      "[[-0.0005611 ]\n",
      " [-0.00021677]]\n",
      "[[0.00055918]\n",
      " [0.00021603]]\n",
      "[[-0.00055726]\n",
      " [-0.00021529]]\n",
      "Training:   0%|                      | 4157/1000000 [00:48<3:11:34, 86.63it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00055535]\n",
      " [0.00021455]]\n",
      "[[-0.00055345]\n",
      " [-0.00021382]]\n",
      "[[0.00055155]\n",
      " [0.00021308]]\n",
      "[[-0.00054966]\n",
      " [-0.00021235]]\n",
      "[[0.00054778]\n",
      " [0.00021163]]\n",
      "[[-0.0005459]\n",
      " [-0.0002109]]\n",
      "[[0.00054403]\n",
      " [0.00021018]]\n",
      "[[-0.00054217]\n",
      " [-0.00020946]]\n",
      "[[0.00054031]\n",
      " [0.00020874]]\n",
      "Training:   0%|                      | 4166/1000000 [00:48<3:11:36, 86.62it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00053846]\n",
      " [-0.00020803]]\n",
      "[[0.00053662]\n",
      " [0.00020731]]\n",
      "[[-0.00053478]\n",
      " [-0.0002066 ]]\n",
      "[[0.00053295]\n",
      " [0.0002059 ]]\n",
      "[[-0.00053112]\n",
      " [-0.00020519]]\n",
      "[[0.0005293 ]\n",
      " [0.00020449]]\n",
      "[[-0.00052749]\n",
      " [-0.00020379]]\n",
      "[[0.00052568]\n",
      " [0.00020309]]\n",
      "[[-0.00052388]\n",
      " [-0.00020239]]\n",
      "Training:   0%|                      | 4175/1000000 [00:48<3:11:41, 86.58it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00052209]\n",
      " [0.0002017 ]]\n",
      "[[-0.0005203 ]\n",
      " [-0.00020101]]\n",
      "[[0.00051852]\n",
      " [0.00020032]]\n",
      "[[-0.00051674]\n",
      " [-0.00019963]]\n",
      "[[0.00051497]\n",
      " [0.00019895]]\n",
      "[[-0.00051321]\n",
      " [-0.00019827]]\n",
      "[[0.00051145]\n",
      " [0.00019759]]\n",
      "[[-0.0005097 ]\n",
      " [-0.00019691]]\n",
      "[[0.00050795]\n",
      " [0.00019624]]\n",
      "Training:   0%|                      | 4184/1000000 [00:48<3:12:13, 86.34it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00050621]\n",
      " [-0.00019557]]\n",
      "[[0.00050447]\n",
      " [0.0001949 ]]\n",
      "[[-0.00050275]\n",
      " [-0.00019423]]\n",
      "[[0.00050102]\n",
      " [0.00019356]]\n",
      "[[-0.00049931]\n",
      " [-0.0001929 ]]\n",
      "[[0.0004976 ]\n",
      " [0.00019224]]\n",
      "[[-0.00049589]\n",
      " [-0.00019158]]\n",
      "[[0.00049419]\n",
      " [0.00019092]]\n",
      "[[-0.0004925 ]\n",
      " [-0.00019027]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:   0%|                      | 4193/1000000 [00:48<3:12:03, 86.41it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00049081]\n",
      " [0.00018962]]\n",
      "[[-0.00048913]\n",
      " [-0.00018897]]\n",
      "[[0.00048746]\n",
      " [0.00018832]]\n",
      "[[-0.00048579]\n",
      " [-0.00018768]]\n",
      "[[0.00048412]\n",
      " [0.00018703]]\n",
      "[[-0.00048247]\n",
      " [-0.00018639]]\n",
      "[[0.00048081]\n",
      " [0.00018575]]\n",
      "[[-0.00047917]\n",
      " [-0.00018512]]\n",
      "Training:   0%|                      | 4193/1000000 [00:49<3:12:03, 86.41it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00047752]\n",
      " [0.00018448]]\n",
      "Training:   0%|                      | 4202/1000000 [00:49<3:15:48, 84.76it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00047589]\n",
      " [-0.00018385]]\n",
      "[[0.00047426]\n",
      " [0.00018322]]\n",
      "[[-0.00047263]\n",
      " [-0.00018259]]\n",
      "[[0.00047101]\n",
      " [0.00018197]]\n",
      "[[-0.0004694 ]\n",
      " [-0.00018135]]\n",
      "[[0.00046779]\n",
      " [0.00018072]]\n",
      "[[-0.00046619]\n",
      " [-0.00018011]]\n",
      "[[0.00046459]\n",
      " [0.00017949]]\n",
      "[[-0.000463  ]\n",
      " [-0.00017887]]\n",
      "Training:   0%|                      | 4211/1000000 [00:49<3:14:13, 85.45it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00046142]\n",
      " [0.00017826]]\n",
      "[[-0.00045984]\n",
      " [-0.00017765]]\n",
      "[[0.00045826]\n",
      " [0.00017704]]\n",
      "[[-0.00045669]\n",
      " [-0.00017644]]\n",
      "[[0.00045513]\n",
      " [0.00017583]]\n",
      "[[-0.00045357]\n",
      " [-0.00017523]]\n",
      "[[0.00045201]\n",
      " [0.00017463]]\n",
      "[[-0.00045046]\n",
      " [-0.00017403]]\n",
      "[[0.00044892]\n",
      " [0.00017343]]\n",
      "Training:   0%|                      | 4220/1000000 [00:49<3:12:54, 86.03it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00044738]\n",
      " [-0.00017284]]\n",
      "[[0.00044585]\n",
      " [0.00017225]]\n",
      "[[-0.00044432]\n",
      " [-0.00017166]]\n",
      "[[0.0004428 ]\n",
      " [0.00017107]]\n",
      "[[-0.00044128]\n",
      " [-0.00017048]]\n",
      "[[0.00043977]\n",
      " [0.0001699 ]]\n",
      "[[-0.00043827]\n",
      " [-0.00016932]]\n",
      "[[0.00043677]\n",
      " [0.00016874]]\n",
      "[[-0.00043527]\n",
      " [-0.00016816]]\n",
      "Training:   0%|                      | 4229/1000000 [00:49<3:13:10, 85.91it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00043378]\n",
      " [0.00016758]]\n",
      "[[-0.00043229]\n",
      " [-0.00016701]]\n",
      "[[0.00043081]\n",
      " [0.00016644]]\n",
      "[[-0.00042934]\n",
      " [-0.00016587]]\n",
      "[[0.00042786]\n",
      " [0.0001653 ]]\n",
      "[[-0.0004264 ]\n",
      " [-0.00016473]]\n",
      "[[0.00042494]\n",
      " [0.00016417]]\n",
      "[[-0.00042348]\n",
      " [-0.00016361]]\n",
      "[[0.00042203]\n",
      " [0.00016305]]\n",
      "Training:   0%|                      | 4238/1000000 [00:49<3:14:22, 85.38it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00042059]\n",
      " [-0.00016249]]\n",
      "[[0.00041915]\n",
      " [0.00016193]]\n",
      "[[-0.00041771]\n",
      " [-0.00016138]]\n",
      "[[0.00041628]\n",
      " [0.00016082]]\n",
      "[[-0.00041485]\n",
      " [-0.00016027]]\n",
      "[[0.00041343]\n",
      " [0.00015972]]\n",
      "[[-0.00041202]\n",
      " [-0.00015918]]\n",
      "[[0.0004106 ]\n",
      " [0.00015863]]\n",
      "[[-0.0004092 ]\n",
      " [-0.00015809]]\n",
      "Training:   0%|                      | 4247/1000000 [00:49<3:14:40, 85.25it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.0004078 ]\n",
      " [0.00015755]]\n",
      "[[-0.0004064 ]\n",
      " [-0.00015701]]\n",
      "[[0.00040501]\n",
      " [0.00015647]]\n",
      "[[-0.00040362]\n",
      " [-0.00015593]]\n",
      "[[0.00040224]\n",
      " [0.0001554 ]]\n",
      "[[-0.00040086]\n",
      " [-0.00015487]]\n",
      "[[0.00039949]\n",
      " [0.00015433]]\n",
      "[[-0.00039812]\n",
      " [-0.00015381]]\n",
      "[[0.00039675]\n",
      " [0.00015328]]\n",
      "Training:   0%|                      | 4256/1000000 [00:49<3:16:31, 84.44it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00039539]\n",
      " [-0.00015275]]\n",
      "[[0.00039404]\n",
      " [0.00015223]]\n",
      "[[-0.00039269]\n",
      " [-0.00015171]]\n",
      "[[0.00039134]\n",
      " [0.00015119]]\n",
      "[[-0.00039   ]\n",
      " [-0.00015067]]\n",
      "[[0.00038867]\n",
      " [0.00015016]]\n",
      "[[-0.00038734]\n",
      " [-0.00014964]]\n",
      "[[0.00038601]\n",
      " [0.00014913]]\n",
      "[[-0.00038469]\n",
      " [-0.00014862]]\n",
      "Training:   0%|                      | 4265/1000000 [00:49<3:17:16, 84.12it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00038337]\n",
      " [0.00014811]]\n",
      "[[-0.00038206]\n",
      " [-0.0001476 ]]\n",
      "[[0.00038075]\n",
      " [0.0001471 ]]\n",
      "[[-0.00037944]\n",
      " [-0.00014659]]\n",
      "[[0.00037814]\n",
      " [0.00014609]]\n",
      "[[-0.00037685]\n",
      " [-0.00014559]]\n",
      "[[0.00037556]\n",
      " [0.00014509]]\n",
      "[[-0.00037427]\n",
      " [-0.00014459]]\n",
      "[[0.00037299]\n",
      " [0.0001441 ]]\n",
      "Training:   0%|                      | 4274/1000000 [00:49<3:18:54, 83.43it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00037171]\n",
      " [-0.0001436 ]]\n",
      "[[0.00037044]\n",
      " [0.00014311]]\n",
      "[[-0.00036917]\n",
      " [-0.00014262]]\n",
      "[[0.0003679 ]\n",
      " [0.00014213]]\n",
      "[[-0.00036664]\n",
      " [-0.00014165]]\n",
      "[[0.00036539]\n",
      " [0.00014116]]\n",
      "[[-0.00036414]\n",
      " [-0.00014068]]\n",
      "[[0.00036289]\n",
      " [0.0001402 ]]\n",
      "[[-0.00036165]\n",
      " [-0.00013972]]\n",
      "Training:   0%|                      | 4283/1000000 [00:50<3:19:29, 83.19it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00036041]\n",
      " [0.00013924]]\n",
      "[[-0.00035917]\n",
      " [-0.00013876]]\n",
      "[[0.00035794]\n",
      " [0.00013829]]\n",
      "[[-0.00035672]\n",
      " [-0.00013781]]\n",
      "[[0.00035549]\n",
      " [0.00013734]]\n",
      "[[-0.00035428]\n",
      " [-0.00013687]]\n",
      "[[0.00035306]\n",
      " [0.0001364 ]]\n",
      "[[-0.00035185]\n",
      " [-0.00013593]]\n",
      "[[0.00035065]\n",
      " [0.00013547]]\n",
      "Training:   0%|                      | 4292/1000000 [00:50<3:17:41, 83.95it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00034945]\n",
      " [-0.000135  ]]\n",
      "[[0.00034825]\n",
      " [0.00013454]]\n",
      "[[-0.00034706]\n",
      " [-0.00013408]]\n",
      "[[0.00034587]\n",
      " [0.00013362]]\n",
      "[[-0.00034468]\n",
      " [-0.00013316]]\n",
      "[[0.0003435 ]\n",
      " [0.00013271]]\n",
      "[[-0.00034232]\n",
      " [-0.00013225]]\n",
      "[[0.00034115]\n",
      " [0.0001318 ]]\n",
      "[[-0.00033998]\n",
      " [-0.00013135]]\n",
      "Training:   0%|                      | 4301/1000000 [00:50<3:17:32, 84.01it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00033882]\n",
      " [0.0001309 ]]\n",
      "[[-0.00033766]\n",
      " [-0.00013045]]\n",
      "[[0.0003365]\n",
      " [0.00013  ]]\n",
      "[[-0.00033535]\n",
      " [-0.00012956]]\n",
      "[[0.0003342 ]\n",
      " [0.00012911]]\n",
      "[[-0.00033305]\n",
      " [-0.00012867]]\n",
      "[[0.00033191]\n",
      " [0.00012823]]\n",
      "[[-0.00033078]\n",
      " [-0.00012779]]\n",
      "[[0.00032964]\n",
      " [0.00012735]]\n",
      "Training:   0%|                      | 4310/1000000 [00:50<3:15:45, 84.77it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00032851]\n",
      " [-0.00012692]]\n",
      "[[0.00032739]\n",
      " [0.00012648]]\n",
      "[[-0.00032627]\n",
      " [-0.00012605]]\n",
      "[[0.00032515]\n",
      " [0.00012562]]\n",
      "[[-0.00032404]\n",
      " [-0.00012519]]\n",
      "[[0.00032293]\n",
      " [0.00012476]]\n",
      "[[-0.00032182]\n",
      " [-0.00012433]]\n",
      "[[0.00032072]\n",
      " [0.0001239 ]]\n",
      "[[-0.00031962]\n",
      " [-0.00012348]]\n",
      "Training:   0%|                      | 4319/1000000 [00:50<3:13:25, 85.80it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00031852]\n",
      " [0.00012306]]\n",
      "[[-0.00031743]\n",
      " [-0.00012264]]\n",
      "[[0.00031635]\n",
      " [0.00012222]]\n",
      "[[-0.00031526]\n",
      " [-0.0001218 ]]\n",
      "[[0.00031418]\n",
      " [0.00012138]]\n",
      "[[-0.00031311]\n",
      " [-0.00012096]]\n",
      "[[0.00031203]\n",
      " [0.00012055]]\n",
      "[[-0.00031096]\n",
      " [-0.00012014]]\n",
      "[[0.0003099 ]\n",
      " [0.00011972]]\n",
      "Training:   0%|                      | 4328/1000000 [00:50<3:11:46, 86.53it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00030884]\n",
      " [-0.00011931]]\n",
      "[[0.00030778]\n",
      " [0.00011891]]\n",
      "[[-0.00030672]\n",
      " [-0.0001185 ]]\n",
      "[[0.00030567]\n",
      " [0.00011809]]\n",
      "[[-0.00030463]\n",
      " [-0.00011769]]\n",
      "[[0.00030358]\n",
      " [0.00011728]]\n",
      "[[-0.00030254]\n",
      " [-0.00011688]]\n",
      "[[0.00030151]\n",
      " [0.00011648]]\n",
      "[[-0.00030047]\n",
      " [-0.00011608]]\n",
      "Training:   0%|                      | 4337/1000000 [00:50<3:11:44, 86.55it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00029945]\n",
      " [0.00011569]]\n",
      "[[-0.00029842]\n",
      " [-0.00011529]]\n",
      "[[0.0002974 ]\n",
      " [0.00011489]]\n",
      "[[-0.00029638]\n",
      " [-0.0001145 ]]\n",
      "[[0.00029536]\n",
      " [0.00011411]]\n",
      "[[-0.00029435]\n",
      " [-0.00011372]]\n",
      "[[0.00029334]\n",
      " [0.00011333]]\n",
      "[[-0.00029234]\n",
      " [-0.00011294]]\n",
      "[[0.00029134]\n",
      " [0.00011255]]\n",
      "Training:   0%|                      | 4346/1000000 [00:50<3:11:42, 86.56it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00029034]\n",
      " [-0.00011217]]\n",
      "[[0.00028934]\n",
      " [0.00011178]]\n",
      "[[-0.00028835]\n",
      " [-0.0001114 ]]\n",
      "[[0.00028736]\n",
      " [0.00011102]]\n",
      "[[-0.00028638]\n",
      " [-0.00011064]]\n",
      "[[0.0002854 ]\n",
      " [0.00011026]]\n",
      "[[-0.00028442]\n",
      " [-0.00010988]]\n",
      "[[0.00028345]\n",
      " [0.00010951]]\n",
      "[[-0.00028248]\n",
      " [-0.00010913]]\n",
      "Training:   0%|                      | 4355/1000000 [00:50<3:12:47, 86.07it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00028151]\n",
      " [0.00010876]]\n",
      "[[-0.00028054]\n",
      " [-0.00010838]]\n",
      "[[0.00027958]\n",
      " [0.00010801]]\n",
      "[[-0.00027863]\n",
      " [-0.00010764]]\n",
      "[[0.00027767]\n",
      " [0.00010727]]\n",
      "[[-0.00027672]\n",
      " [-0.00010691]]\n",
      "[[0.00027577]\n",
      " [0.00010654]]\n",
      "[[-0.00027483]\n",
      " [-0.00010618]]\n",
      "[[0.00027389]\n",
      " [0.00010581]]\n",
      "Training:   0%|                      | 4364/1000000 [00:51<3:12:26, 86.23it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-0.00027295]\n",
      " [-0.00010545]]\n",
      "[[0.00027201]\n",
      " [0.00010509]]\n",
      "[[-0.00027108]\n",
      " [-0.00010473]]\n",
      "[[0.00027015]\n",
      " [0.00010437]]\n",
      "[[-0.00026923]\n",
      " [-0.00010401]]\n",
      "[[0.0002683 ]\n",
      " [0.00010366]]\n",
      "[[-0.00026739]\n",
      " [-0.0001033 ]]\n",
      "[[0.00026647]\n",
      " [0.00010295]]\n",
      "[[-0.00026556]\n",
      " [-0.00010259]]\n",
      "Training:   0%|                      | 4373/1000000 [00:51<3:12:45, 86.09it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[0.00026465]\n",
      " [0.00010224]]\n",
      "[[-0.00026374]\n",
      " [-0.00010189]]\n",
      "[[0.00026284]\n",
      " [0.00010154]]\n",
      "[[-0.00026194]\n",
      " [-0.0001012 ]]\n",
      "[[0.00026104]\n",
      " [0.00010085]]\n",
      "[[-0.00026015]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [-0.0001005 ]]\n",
      "[[0.00025925]\n",
      " [0.00010016]]\n",
      "[[-2.58365856e-04]\n",
      " [-9.98156356e-05]]\n",
      "[[2.57480794e-04]\n",
      " [9.94737056e-05]]\n",
      "Training:   0%|                      | 4382/1000000 [00:51<3:12:57, 85.99it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-2.56598764e-04]\n",
      " [-9.91329470e-05]]\n",
      "[[2.55719755e-04]\n",
      " [9.87933557e-05]]\n",
      "[[-2.54843758e-04]\n",
      " [-9.84549278e-05]]\n",
      "[[2.53970761e-04]\n",
      " [9.81176591e-05]]\n",
      "[[-2.53100755e-04]\n",
      " [-9.77815459e-05]]\n",
      "[[2.5223373e-04]\n",
      " [9.7446584e-05]]\n",
      "[[-2.51369674e-04]\n",
      " [-9.71127695e-05]]\n",
      "[[2.50508579e-04]\n",
      " [9.67800986e-05]]\n",
      "[[-2.49650433e-04]\n",
      " [-9.64485673e-05]]\n",
      "Training:   0%|                      | 4391/1000000 [00:51<3:11:27, 86.67it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[2.48795227e-04]\n",
      " [9.61181716e-05]]\n",
      "[[-2.47942950e-04]\n",
      " [-9.57889078e-05]]\n",
      "[[2.47093593e-04]\n",
      " [9.54607720e-05]]\n",
      "[[-2.46247145e-04]\n",
      " [-9.51337601e-05]]\n",
      "[[2.45403598e-04]\n",
      " [9.48078685e-05]]\n",
      "[[-2.44562940e-04]\n",
      " [-9.44830933e-05]]\n",
      "[[2.43725161e-04]\n",
      " [9.41594306e-05]]\n",
      "[[-2.42890253e-04]\n",
      " [-9.38368767e-05]]\n",
      "[[2.42058204e-04]\n",
      " [9.35154277e-05]]\n",
      "Training:   0%|                      | 4400/1000000 [00:51<3:12:00, 86.42it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-2.41229006e-04]\n",
      " [-9.31950799e-05]]\n",
      "Training:   0%|                      | 4400/1000000 [00:51<3:12:00, 86.42it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[2.40402649e-04]\n",
      " [9.28758295e-05]]\n",
      "[[-2.39579122e-04]\n",
      " [-9.25576726e-05]]\n",
      "[[2.38758416e-04]\n",
      " [9.22406057e-05]]\n",
      "[[-2.37940521e-04]\n",
      " [-9.19246249e-05]]\n",
      "[[2.37125429e-04]\n",
      " [9.16097266e-05]]\n",
      "[[-2.36313129e-04]\n",
      " [-9.12959070e-05]]\n",
      "[[2.35503611e-04]\n",
      " [9.09831624e-05]]\n",
      "[[-2.34696866e-04]\n",
      " [-9.06714891e-05]]\n",
      "Training:   0%|                      | 4409/1000000 [00:51<3:13:32, 85.73it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[2.33892885e-04]\n",
      " [9.03608835e-05]]\n",
      "[[-2.33091658e-04]\n",
      " [-9.00513420e-05]]\n",
      "[[2.32293176e-04]\n",
      " [8.97428608e-05]]\n",
      "[[-2.31497429e-04]\n",
      " [-8.94354364e-05]]\n",
      "[[2.30704408e-04]\n",
      " [8.91290650e-05]]\n",
      "[[-2.29914104e-04]\n",
      " [-8.88237432e-05]]\n",
      "[[2.29126507e-04]\n",
      " [8.85194672e-05]]\n",
      "[[-2.28341608e-04]\n",
      " [-8.82162337e-05]]\n",
      "[[2.27559397e-04]\n",
      " [8.79140388e-05]]\n",
      "Training:   0%|                      | 4418/1000000 [00:51<3:14:04, 85.50it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-2.26779867e-04]\n",
      " [-8.76128792e-05]]\n",
      "[[2.26003006e-04]\n",
      " [8.73127512e-05]]\n",
      "[[-2.25228807e-04]\n",
      " [-8.70136514e-05]]\n",
      "[[2.24457260e-04]\n",
      " [8.67155762e-05]]\n",
      "[[-2.23688356e-04]\n",
      " [-8.64185221e-05]]\n",
      "[[2.22922086e-04]\n",
      " [8.61224855e-05]]\n",
      "[[-2.2215844e-04]\n",
      " [-8.5827463e-05]]\n",
      "[[2.21397411e-04]\n",
      " [8.55334512e-05]]\n",
      "[[-2.20638989e-04]\n",
      " [-8.52404466e-05]]\n",
      "Training:   0%|                      | 4427/1000000 [00:51<3:13:43, 85.65it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[2.19883165e-04]\n",
      " [8.49484456e-05]]\n",
      "[[-2.19129930e-04]\n",
      " [-8.46574451e-05]]\n",
      "[[2.18379275e-04]\n",
      " [8.43674412e-05]]\n",
      "[[-2.17631192e-04]\n",
      " [-8.40784309e-05]]\n",
      "[[2.16885672e-04]\n",
      " [8.37904106e-05]]\n",
      "[[-2.16142705e-04]\n",
      " [-8.35033770e-05]]\n",
      "[[2.15402283e-04]\n",
      " [8.32173266e-05]]\n",
      "[[-2.14664398e-04]\n",
      " [-8.29322562e-05]]\n",
      "[[2.13929040e-04]\n",
      " [8.26481621e-05]]\n",
      "Training:   0%|                      | 4436/1000000 [00:51<3:14:44, 85.20it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-2.13196202e-04]\n",
      " [-8.23650414e-05]]\n",
      "[[2.12465874e-04]\n",
      " [8.20828905e-05]]\n",
      "[[-2.11738048e-04]\n",
      " [-8.18017062e-05]]\n",
      "[[2.11012715e-04]\n",
      " [8.15214850e-05]]\n",
      "[[-2.10289867e-04]\n",
      " [-8.12422239e-05]]\n",
      "[[2.09569495e-04]\n",
      " [8.09639193e-05]]\n",
      "[[-2.08851590e-04]\n",
      " [-8.06865681e-05]]\n",
      "[[2.08136145e-04]\n",
      " [8.04101670e-05]]\n",
      "[[-2.07423151e-04]\n",
      " [-8.01347128e-05]]\n",
      "Training:   0%|                      | 4445/1000000 [00:51<3:14:21, 85.37it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[2.06712599e-04]\n",
      " [7.98602021e-05]]\n",
      "[[-2.06004481e-04]\n",
      " [-7.95866318e-05]]\n",
      "[[2.05298789e-04]\n",
      " [7.93139986e-05]]\n",
      "[[-2.04595515e-04]\n",
      " [-7.90422995e-05]]\n",
      "[[2.03894649e-04]\n",
      " [7.87715309e-05]]\n",
      "[[-2.03196185e-04]\n",
      " [-7.85016901e-05]]\n",
      "[[2.02500113e-04]\n",
      " [7.82327735e-05]]\n",
      "[[-2.01806425e-04]\n",
      " [-7.79647782e-05]]\n",
      "[[2.01115114e-04]\n",
      " [7.76977009e-05]]\n",
      "Training:   0%|                      | 4454/1000000 [00:52<3:14:38, 85.25it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-2.00426172e-04]\n",
      " [-7.74315385e-05]]\n",
      "[[1.99739589e-04]\n",
      " [7.71662878e-05]]\n",
      "[[-1.99055358e-04]\n",
      " [-7.69019459e-05]]\n",
      "[[1.98373471e-04]\n",
      " [7.66385094e-05]]\n",
      "[[-1.97693920e-04]\n",
      " [-7.63759754e-05]]\n",
      "[[1.97016696e-04]\n",
      " [7.61143407e-05]]\n",
      "[[-1.96341793e-04]\n",
      " [-7.58536023e-05]]\n",
      "[[1.95669202e-04]\n",
      " [7.55937571e-05]]\n",
      "[[-1.94998914e-04]\n",
      " [-7.53348020e-05]]\n",
      "Training:   0%|                      | 4463/1000000 [00:52<3:11:46, 86.52it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[1.94330923e-04]\n",
      " [7.50767340e-05]]\n",
      "[[-1.9366522e-04]\n",
      " [-7.4819550e-05]]\n",
      "[[1.93001798e-04]\n",
      " [7.45632470e-05]]\n",
      "[[-1.92340648e-04]\n",
      " [-7.43078221e-05]]\n",
      "[[1.91681763e-04]\n",
      " [7.40532721e-05]]\n",
      "[[-1.91025135e-04]\n",
      " [-7.37995941e-05]]\n",
      "[[1.90370757e-04]\n",
      " [7.35467852e-05]]\n",
      "[[-1.89718620e-04]\n",
      " [-7.32948422e-05]]\n",
      "[[1.89068717e-04]\n",
      " [7.30437623e-05]]\n",
      "Training:   0%|                      | 4472/1000000 [00:52<3:11:43, 86.54it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-1.88421040e-04]\n",
      " [-7.27935425e-05]]\n",
      "[[1.87775582e-04]\n",
      " [7.25441798e-05]]\n",
      "[[-1.87132336e-04]\n",
      " [-7.22956714e-05]]\n",
      "[[1.86491292e-04]\n",
      " [7.20480143e-05]]\n",
      "[[-1.85852445e-04]\n",
      " [-7.18012056e-05]]\n",
      "[[1.85215786e-04]\n",
      " [7.15552423e-05]]\n",
      "[[-1.84581308e-04]\n",
      " [-7.13101217e-05]]\n",
      "[[1.83949004e-04]\n",
      " [7.10658406e-05]]\n",
      "[[-1.83318866e-04]\n",
      " [-7.08223965e-05]]\n",
      "Training:   0%|                      | 4481/1000000 [00:52<3:12:14, 86.31it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[1.82690886e-04]\n",
      " [7.05797862e-05]]\n",
      "[[-1.82065057e-04]\n",
      " [-7.03380071e-05]]\n",
      "[[1.81441372e-04]\n",
      " [7.00970562e-05]]\n",
      "[[-1.80819824e-04]\n",
      " [-6.98569307e-05]]\n",
      "[[1.80200405e-04]\n",
      " [6.96176278e-05]]\n",
      "[[-1.79583108e-04]\n",
      " [-6.93791446e-05]]\n",
      "[[1.78967925e-04]\n",
      " [6.91414784e-05]]\n",
      "[[-1.78354850e-04]\n",
      " [-6.89046263e-05]]\n",
      "[[1.77743875e-04]\n",
      " [6.86685856e-05]]\n",
      "Training:   0%|                      | 4490/1000000 [00:52<3:12:36, 86.15it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-1.77134993e-04]\n",
      " [-6.84333535e-05]]\n",
      "[[1.76528197e-04]\n",
      " [6.81989272e-05]]\n",
      "[[-1.7592348e-04]\n",
      " [-6.7965304e-05]]\n",
      "[[1.75320833e-04]\n",
      " [6.77324810e-05]]\n",
      "[[-1.74720252e-04]\n",
      " [-6.75004556e-05]]\n",
      "[[1.74121728e-04]\n",
      " [6.72692251e-05]]\n",
      "[[-1.73525254e-04]\n",
      " [-6.70387866e-05]]\n",
      "[[1.72930823e-04]\n",
      " [6.68091375e-05]]\n",
      "[[-1.72338428e-04]\n",
      " [-6.65802752e-05]]\n",
      "Training:   0%|                      | 4499/1000000 [00:52<3:13:24, 85.79it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[1.71748063e-04]\n",
      " [6.63521968e-05]]\n",
      "[[-1.71159721e-04]\n",
      " [-6.61248998e-05]]\n",
      "Training:   0%|                      | 4499/1000000 [00:52<3:13:24, 85.79it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[1.70573394e-04]\n",
      " [6.58983813e-05]]\n",
      "[[-1.69989075e-04]\n",
      " [-6.56726389e-05]]\n",
      "[[1.69406758e-04]\n",
      " [6.54476697e-05]]\n",
      "[[-1.68826436e-04]\n",
      " [-6.52234713e-05]]\n",
      "[[1.68248101e-04]\n",
      " [6.50000408e-05]]\n",
      "[[-1.67671748e-04]\n",
      " [-6.47773757e-05]]\n",
      "[[1.67097369e-04]\n",
      " [6.45554733e-05]]\n",
      "Training:   0%|                      | 4508/1000000 [00:52<3:16:11, 84.57it/s, loss_val=27.9984, thetas=-0.6559 4.8854][[-1.66524958e-04]\n",
      " [-6.43343312e-05]]\n",
      "[[1.65954508e-04]\n",
      " [6.41139465e-05]]\n",
      "[[-1.65386012e-04]\n",
      " [-6.38943169e-05]]\n",
      "[[1.64819463e-04]\n",
      " [6.36754396e-05]]\n",
      "[[-1.64254855e-04]\n",
      " [-6.34573121e-05]]\n",
      "[[1.63692181e-04]\n",
      " [6.32399318e-05]]"
     ]
    }
   ],
   "source": [
    "# Step 4. Gradient descent.\n",
    "\n",
    "# now let's find optimal parameters using gradient descent\n",
    "MAX_ITER = 1000000\n",
    "thetas = np.random.randn(2, 1)\n",
    "alpha = 4.22e-3\n",
    "\n",
    "progress = tqdm.tqdm(range(MAX_ITER), \"Training\", file=sys.stdout)\n",
    "loss_val = loss_fn(x_train, y_train, thetas)\n",
    "progress.set_postfix(loss_val=loss_val)\n",
    "\n",
    "for iter in progress:\n",
    "    gradient = gradient_fn(x_train, y_train, thetas)\n",
    "    print(gradient)\n",
    "    thetas_2 = thetas - alpha * gradient\n",
    "    \n",
    "    # TODO: add stop conditions\n",
    "    if (abs(thetas_2[0] - thetas[0]) < 0.00000001) or (abs(thetas_2[1] -thetas[1]) < 0.00000001):\n",
    "        progress.close()\n",
    "        loss_val = loss_fn(x_train, y_train, thetas)\n",
    "        print(\"Stop condition detected\")\n",
    "        print(\"Final loss:\", loss_val)\n",
    "        break\n",
    "    \n",
    "    if iter % 100 == 0:\n",
    "        loss_val = loss_fn(x_train, y_train, thetas_2)\n",
    "        progress.set_postfix(loss_val=f\"{loss_val:8.4f}\", thetas=f\"{thetas_2[0][0]:5.4f} {thetas_2[1][0]:5.4f}\")\n",
    "    thetas = thetas_2\n",
    "    \n",
    "progress.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target:  11.8 , predicted: 15.825663061797137\n",
      "Target:  11.0 , predicted: 16.139711609970796\n",
      "Target:  23.7 , predicted: 27.899383727052204\n",
      "Target:  35.4 , predicted: 32.259012900433305\n",
      "Target:  15.2 , predicted: 14.798901476444952\n",
      "Target:  24.4 , predicted: 27.821420233616394\n",
      "Target:  33.4 , predicted: 32.259351209667344\n",
      "Target:  31.6 , predicted: 30.822201690957264\n",
      "Target:  13.4 , predicted: 21.53211004080499\n",
      "Target:  34.9 , predicted: 31.084403500872533\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    y_hat = predict_fn(x_train, thetas)\n",
    "    print(\"Target: \", y_train[i][0], \", predicted:\", y_hat[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
